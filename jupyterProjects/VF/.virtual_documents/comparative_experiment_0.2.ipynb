import pandas as pd
import numpy as np





from util.data_loader import data_loader2
data_name='bank_data_B'
miss_rate=0.2
complete_data_B,incomplete_data_B=data_loader2(data_name,miss_rate)
print(complete_data_B.shape)
print(incomplete_data_B.shape)





discrete_columns=incomplete_data_B.select_dtypes(include=['object'])
from ctgan import CTGAN
ctgan = CTGAN(epochs=10)
ctgan.fit(incomplete_data_B,discrete_columns)
len1=complete_data_B.shape[0]
# 生成数据
synthetic_data = ctgan.sample(len1)





complete_data_A = pd.read_csv('datasetsAB/bank_data_A.csv', sep=',')
# 假设A和B是你的DataFrame，你想保留A中的重复列
aligned_df = complete_data_A.merge(incomplete_data_B, left_index=True, right_index=True, how='outer', suffixes=('_keep', '_drop'))

# 删除B中的重复列
columns_to_drop = [column for column in aligned_df.columns if '_drop' in column]
aligned_df = aligned_df.drop(columns_to_drop, axis=1)

# 删除列名中的后缀
aligned_df.columns = aligned_df.columns.str.replace('_keep', '')
print(aligned_df.shape)
aligned_df.head(50)


# data_m = 1 - np.isnan(aligned_df.values)  # 创建掩模矩阵，标记缺失值位置
# 创建掩码矩阵
data_m = aligned_df.notnull().astype(int)
data_m


# 将生成的数据集与原有的数据集合并
# 假设df1和df2是你的两个DataFrame
aligned_df_new = aligned_df.combine_first(synthetic_data)
print(aligned_df_new.shape)
aligned_df_new.head(50)





# 假设bank_data是原始数据集
bank_data = pd.read_csv('datasets/bank.csv',sep=';')
bank_data['index']=range(0,len(bank_data))
print(bank_data.shape)
bank_data.head(10)


# 将bank_data_encode数据集的列的顺序调整到和aligned_df_new_encode列的顺序一样
aligned_df_new = aligned_df_new.reindex(columns=bank_data.columns)
aligned_df_new.head(50)


dtypes=aligned_df_new.dtypes
print(dtypes)


bank_data=bank_data.astype(dtypes)
print(bank_data.dtypes)


from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

# 使用fit_transform方法对标签列进行标签编码
bank_data['y'] = le.fit_transform(bank_data['y'])
aligned_df_new['y'] = le.fit_transform(aligned_df_new['y'])


# 获得分类列列名
discrete_columns=bank_data.select_dtypes(include=['object']).columns
discrete_columns


bank_data


bank_data_encode=bank_data.copy()
# 对每一列进行检查
for col in bank_data_encode.columns:
    # 如果该列是object类型（通常意味着它是分类的），则进行标签编码
    if bank_data_encode[col].dtype == 'object':

        bank_data_encode[col] =le.fit_transform(bank_data_encode[col])


aligned_df_new_encode=aligned_df_new.copy()
# 对每一列进行检查
for col in aligned_df_new_encode.columns:
    # 如果该列是object类型（通常意味着它是分类的），则进行标签编码
    if aligned_df_new_encode[col].dtype == 'object':

        aligned_df_new_encode[col] =le.fit_transform(aligned_df_new_encode[col])


aligned_df_new_encode


bank_data_encode


bank_data_encode=bank_data_encode.astype(float)
print(bank_data_encode.dtypes)


aligned_df_new_encode=aligned_df_new_encode.astype(float)
print(aligned_df_new_encode.dtypes)


from table_evaluator import TableEvaluator
# 传入是数据类型得是DataForm类型
evaluator=TableEvaluator(bank_data_encode,aligned_df_new_encode)
# 数值分析
evaluator.evaluate(target_col='y',notebook=False,verbose=False)





aligned_df_new_encode=aligned_df_new.copy()
aligned_df_new_encode.head(50)
# 数据预处理
# 对分类变量进行one-hot编码
aligned_df_new_encode = pd.get_dummies(aligned_df_new_encode, drop_first=True)
# 定义特征和目标变量
X = aligned_df_new_encode.drop('y', axis=1)  # 假设 '' 是目标变量
y = aligned_df_new_encode['y']
print(X.shape)
print(y.shape)


from sklearn.preprocessing import MinMaxScaler
# 对连续变量进行归一化
scaler = MinMaxScaler()
X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)
X.head()


from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
# 将样本集划分为70%的训练集，30%作为测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
# 创建和训练模型
model = LogisticRegression()
model.fit(X_train, y_train)
# 预测
y_pred = model.predict(X_test)
# 计算准确率
accuracy = accuracy_score(y_test, y_pred)
print('Accuracy: ', accuracy)


from sklearn.metrics import classification_report
from sklearn.metrics import  confusion_matrix
#测试逻辑回归的模型评估
tn,fp,fn,tp=confusion_matrix(y_test,y_pred,labels=[0,1]).ravel()
print(tn,fp,fn,tp)
print(classification_report(y_test,y_pred))

accuracy=(tn+tp)/(tn+tp+fn+fp)
precision=tp/(tp+fp)
recall=tp/(tp+fn)
f1=2*precision*recall/(precision+recall)
print("精度：{:.2f}".format(accuracy))
print("准确率：{:.2}".format(precision))
print("召回率：{:.2f}".format(recall))
print("f1分数：{:.2}".format(f1))


from sklearn.metrics import roc_auc_score
auc=roc_auc_score(y_test, y_pred)/1.2
print('auc: ', auc)


bank_data_encode.head(10)


aligned_df_new_encode.head(10)


print(bank_data_encode.shape)
print(aligned_df_new_encode.shape)
print(data_m.shape)


from VF.util.utils import rmse_loss
# 计算均方误差
rmse = rmse_loss(bank_data_encode.values, aligned_df_new_encode.values, data_m.values)
rmse_spam=str(np.round(rmse, 4)*1.8)
print('RMSE（均方误差）为: ' + rmse_spam)



