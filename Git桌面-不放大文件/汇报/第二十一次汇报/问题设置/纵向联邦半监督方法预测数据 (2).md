#### 3.2.1 纵向联邦半监督方法生成数据过程

针对B方数据大规模缺失这一实际应用中的关键挑战，本节提出了一种全新的基于纵向联邦半监督学习（Vertical Federated Semi-supervised Learning, VFSL）的缺失数据智能生成方法。这一创新方法不同于传统的数据填补技术，它通过系统化、深入挖掘参与方A与B之间对齐样本所蕴含的多层次统计关联特性，结合先进的联邦学习与半监督学习理论，在严格的隐私保护机制下构建高性能的特征补全模型体系，从而实现对B方未对齐样本缺失特征的精确预测与高质量生成。

如算法4-1所详细阐述的那样，该方法的整体架构由三个紧密相关且相互支撑的关键环节组成：（1）基于隐私保护的联邦模型协同训练机制，确保在不交换原始数据的前提下最大化模型性能；（2）精细化的跨域特征关联分析框架，捕捉不同参与方数据间的结构化依赖关系；（3）基于信任度评估的隐私保护数据生成策略，平衡生成数据的质量与数量。这三个环节的有机结合形成了一个完整、严谨的技术体系，为从未对齐样本中生成高可信度特征值提供了系统性解决方案。

算法4-1的设计遵循了"理论指导实践、实践检验理论"的科学原则，充分考虑了纵向联邦学习中数据隐私保护、计算效率和预测准确性等多重约束条件，通过多轮迭代优化，最终形成了当前的高效实现方案。该算法不仅在理论上具有坚实的数学基础，在实践中也表现出优异的性能和稳定性，为解决纵向联邦学习中的数据缺失问题提供了新的思路和方法。

**算法输入参数详解**

算法4-1的成功执行依赖于一系列精心设计的输入参数，这些参数不仅决定了算法的执行流程，还直接影响最终生成数据的质量和可靠性。下面对这些关键输入参数进行深入解析：

1. **A方对齐数据**（$X_{al}^A \in \mathbb{R}^{n_{al} \times d_A}$）：这是一个二维特征矩阵，表示A方与B方样本空间成功对齐的那部分数据。其中，$n_{al}$ 代表对齐样本的总数量，$d_A$ 表示A方特征空间的维度。从数学本质上看，$X_{al}^A$ 的每一行代表一个样本，每一列代表该样本在A方特征空间中的一个特定维度。这些对齐数据是双方通过安全多方计算或隐私保护实体匹配技术确认的共同样本，它们构成了后续模型训练和特征关联分析的基础数据集。对齐数据的质量直接决定了模型的学习效果，因此在预处理阶段需要特别关注数据清洗和标准化工作。
2. **A方未对齐数据**（$X_{nl}^A \in \mathbb{R}^{n_{nl} \times d_A}$）：这同样是一个二维特征矩阵，但它表示的是A方中那些在B方没有对应记录的样本数据。其中，$n_{nl}$ 表示未对齐样本的数量，特征维度与对齐数据保持一致，仍为 $d_A$。这部分数据在传统联邦学习框架下通常被忽略不用，但在本方法中，它们被视为半监督学习框架下的"无标签数据"，通过算法可以为其生成对应的B方特征，从而扩大可用于联合训练的样本规模。从数据结构角度看，$X_{nl}^A$ 与 $X_{al}^A$ 的唯一区别在于这些样本是否在B方有对应记录，它们在A方特征空间的表示形式完全一致。
3. **B方特征相关性列表**（$\mathcal{L}*B = {(\mu_q, \phi^B_q)}*{q=1}^{d_B}$）：这是一个有序二元组的集合，其中 $\mu_q$ 表示B方第 $q$ 个特征列 $\phi^B_q$ 与A方整体数据的平均关联强度，$d_B$ 表示B方特征空间的总维度。这个列表不是简单的特征枚举，而是经过系统化分析计算得到的特征重要性排序结果。每一个二元组 $(\mu_q, \phi^B_q)$ 都包含两个关键信息：特征本身 $\phi^B_q$ 和该特征与A方数据的相关程度 $\mu_q$。这一列表是特征选择的重要依据，能够帮助算法确定哪些B方特征适合通过纵向联邦半监督学习方法生成，哪些适合通过其他生成模型补全。在实际实现中，$\mu_q$ 的计算可以基于前述的Spearman秩相关分析方法，也可以采用其他适合特定数据类型的相关性度量。
4. **相关性阈值**（$\tau \in [0,1]$）：这是一个浮点数值，用于设定特征筛选的严格程度。只有当B方特征与A方数据的相关性系数 $\mu_q$ 大于阈值 $\tau$ 时，该特征才会被选中通过纵向联邦半监督学习方法生成。这个阈值的设定需要平衡两个方面的考量：一方面，较高的阈值能确保只有高度相关的特征被选中，从而提高生成数据的质量；另一方面，过高的阈值可能导致可选特征过少，无法充分利用数据间的关联信息。在实践中，$\tau$ 的选取通常基于统计显著性检验或交叉验证等方法确定，以在特定数据集上获得最佳性能。典型情况下，$\tau$ 的取值范围在0.5到0.7之间，根据实际应用场景和数据特性可进行适当调整。
5. **样本数量参数**（$n_{al}$ 和 $n_{nl}$）：这两个整数参数分别表示对齐样本和未对齐样本的数量。它们不仅定义了输入矩阵的维度，也直接影响算法的计算复杂度和内存需求。在大规模数据场景下，这两个参数可能达到数万甚至数百万量级，因此算法实现需要特别关注计算效率和可扩展性。从算法设计角度看，$n_{al}$ 和 $n_{nl}$ 的相对比例也是一个重要考量因素，它反映了数据缺失的严重程度，直接影响半监督学习的难度和效果。

**算法核心目标与流程**

算法4-1的核心目标是构建一个能够高效、准确地利用A方完整数据预测B方未对齐样本特征值的智能系统，最终生成质量可靠、分布合理的完整B方数据矩阵 $X^{B_{predict}}$。这一目标不仅涉及数据补全的准确性问题，还需要考虑数据隐私保护、计算效率以及生成数据与原始数据分布一致性等多重约束。为了实现这一复杂目标，算法采用了分阶段、递进式的处理策略，整个流程可分为以下三个紧密关联且层层递进的主要步骤：

**1. 初始化与特征筛选阶段**

在算法执行的第一阶段，系统首先将目标数据集 $X^{B_{predict}}$ 初始化为空集（$X^{B_{predict}} = \emptyset$），这表明在算法开始时尚未生成任何B方数据。这种"从零开始"的设计理念使得算法具有良好的灵活性和可扩展性，能够根据后续处理需要逐步构建目标数据集。

初始化完成后，算法立即进入关键的特征筛选环节。该环节通过一个精确定义的数学筛选条件，从B方的全部特征列表 $\mathcal{L}_B$ 中选取那些与A方数据具有显著相关性的特征列，构造预测特征集合：

$\mathcal{L}_B^{\text{predict}} = {(\mu_q, \phi^B_q) \in \mathcal{L}_B \mid \mu_q > \tau}$

这一数学表达式清晰地定义了筛选条件：只有当B方特征列 $\phi^B_q$ 与A方数据的平均关联强度 $\mu_q$ 严格大于预设阈值 $\tau$ 时，该特征才会被纳入预测特征集合 $\mathcal{L}_B^{\text{predict}}$。从集合论角度看，$\mathcal{L}_B^{\text{predict}}$ 是 $\mathcal{L}_B$ 的一个子集，包含了所有满足条件 $\mu_q > \tau$ 的元素。

这种基于阈值的特征筛选机制具有多重理论依据。首先，从信息论角度看，高相关性特征包含了更多与A方数据相关的信息，因此更适合通过A方数据进行预测；其次，从统计学角度看，这一筛选过程可以视为一种假设检验，确保所选特征与A方数据的相关性在统计上显著；最后，从机器学习角度看，这种特征选择策略有助于降低模型复杂度，减少过拟合风险，提高模型的泛化能力。

相关性阈值 $\tau$ 的设定是一个需要精心调优的关键参数。过高的阈值（如 $\tau > 0.8$）会导致筛选条件过于严格，可能只有极少数特征能够满足要求，从而限制了可预测特征的数量和多样性；而过低的阈值（如 $\tau < 0.3$）则可能引入大量低相关性特征，这些特征与A方数据的关联性不强，通过半监督学习方法难以准确预测，可能引入较大噪声，降低整体预测准确性。实践表明，在大多数应用场景中，$\tau$ 取值在0.5到0.7之间能够取得较好的平衡，但最佳值仍需根据具体数据集特性通过交叉验证等方法确定。

**2. 特征级联邦数据生成**

对于每个满足相关性筛选条件的特征列$(\mu_q, \phi^B_q) \in \mathcal{L}_B^{\text{predict}}$，算法执行以下步骤：

- 数据分区

  ：将B方特征列$\phi^B_q$的预测数据划分为两部分：

  - 对齐部分：$X_{al}^{B_{predict}} \in \mathbb{R}^{n_{al}}$，对应于A方对齐样本的B方特征值。这部分数据直接来源于B方已有的特征值。
  - 未对齐部分：$X_{nl}^{B_{predict}} \in \mathbb{R}^{n_{nl}}$，需要通过联邦学习方法进行预测。这部分是算法需要生成的目标数据。

这种数据分区方式与A方数据结构保持一致，有助于后续联邦建模的执行。分区操作确保了对齐样本的特征值直接复用B方原始数据，而只对未对齐部分进行预测，从而减少了计算开销并提高了生成数据的质量。

- **联邦预测建模**：采用VFPU-M（Vertical Federated Prediction with Unlabeled Missing data）算法进行特征预测。其函数形式如下：

$$p = \text{VFPU-M}(X_{al}^A, X_{nl}^A, X_{al}^{B_{predict}}, X_{nl}^{B_{predict}}, \phi^B_q)$$

在这个过程中，对齐部分$X_{al}^{B_{predict}}$直接使用B方已有的特征值，而未对齐部分$X_{nl}^{B_{predict}}$通过VFPU-M算法进行预测，生成伪标签数据。该过程确保了B方数据的补全，同时符合联邦学习的隐私保护要求。VFPU-M算法是本研究的核心创新点之一，将在后续章节中详细介绍。

**3. 数据合成与迭代执行**

- **数据合成**：将VFPU-M预测得到的伪标签向量$p$合并至目标数据集$X^{B_{predict}}$，完成当前特征列的数据生成。这一步骤实现了单个特征维度的数据补全。
- **迭代执行**：通过遍历所有满足相关性筛选条件的特征列，最终生成完整的B方数据矩阵：

$$X^{B_{predict}} \in \mathbb{R}^{n_B \times |\mathcal{L}_B^{\text{predict}}|}$$

该矩阵不仅保留了与A方数据的统计相关性，同时遵循纵向联邦学习的隐私保护约束。通过逐列生成的策略，算法能够有针对性地处理不同特征的预测任务，提高整体数据生成的质量。

整个算法流程呈现迭代递进的特性：首先筛选高相关性特征，然后逐一对这些特征进行预测生成，最终合并形成完整的B方预测数据矩阵。这种分治策略不仅提高了计算效率，还能针对不同特征的分布特性采用适合的预测方法，从而实现高质量的数据补全。

#### 3.2.2 VFPU-M算法：多任务联邦半监督学习

纵向联邦半监督学习是一个充满挑战的研究领域，尤其在处理多方异构数据协同建模时面临诸多技术难题。针对B方数据缺失样本预测这一核心挑战，本节提出了一种全新的VFPU-M（Vertical Federated Positive-Unlabeled Learning with Model Adaptation）算法。这是一种专为半监督联邦学习场景设计的创新算法，其独特之处在于能够有效处理这样一种复杂场景：在两个参与方的数据集中，只有一部分样本（"对齐样本"）具有完整的特征和标签信息，而另一部分样本（"非对齐样本"）则缺乏必要的标签信息，需要通过先进的伪标签（Pseudo-Labeling）技术从有限的标记数据中挖掘和迁移知识，进而最大化无标签数据的价值。

VFPU-M算法的设计理念源于对传统联邦学习和半监督学习的深度融合与创新。一方面，它继承了联邦学习"数据不出域、模型协同训练"的核心原则，通过精心设计的安全计算协议，确保各方数据的隐私安全；另一方面，它吸收了半监督学习中伪标签技术和置信度评估机制的精髓，实现了从有限标记数据到大量无标签数据的知识迁移。与此同时，VFPU-M还创新性地引入了多任务适配机制，使算法能够同时处理分类、回归等多种类型的预测任务，大大拓展了算法的应用范围。

在保持严格隐私保护的前提下，VFPU-M通过迭代地识别、评估和筛选高置信度的无标签样本，为这些样本生成高质量的伪标签，并将其动态纳入后续训练过程，不断扩充有效训练集规模，从而显著提升模型在异构数据上的学习能力和泛化性能。这种"迭代扩充、动态优化"的策略使得算法能够在数据稀疏和异构的复杂环境中依然保持优异的性能，为解决纵向联邦学习中的样本不对齐问题提供了强有力的技术支持。

**算法核心思想与详细流程**

VFPU-M算法的核心思想建立在一个关键洞察之上：在数据标签稀缺的环境中，如果能够识别并充分利用那些预测置信度高的无标签样本，为其生成高质量的伪标签并将其纳入训练过程，就能够显著扩大有效训练数据的规模，进而提升模型的学习能力和泛化性能。基于这一理念，VFPU-M算法设计了一个精密的迭代式学习框架，将有限的可靠标签数据（对齐样本）和大量无标签数据（非对齐样本）同时纳入训练体系，并在保证各方数据隐私安全的前提下，通过多轮迭代不断扩充高质量伪标签样本，优化模型性能。

以下是VFPU-M算法的详细流程解析：

**1. 数据初始化与分割**

算法执行的第一步是对输入数据进行科学的初始化与分割。这一步骤为后续的迭代训练建立了结构化的数据基础：

首先，算法将对齐样本（有标签数据）构造为初始的有标签数据集 $\mathcal{D}_L^{(0)}$：

$\mathcal{D}*{L}^{(0)} = {X*{al}^A, X_{al}^B, y}$

其中，$X_{al}^A \in \mathbb{R}^{n_{al} \times d_A}$ 表示A方对齐样本的特征矩阵，$X_{al}^B \in \mathbb{R}^{n_{al} \times d_B}$ 表示B方对齐样本的特征矩阵，$y \in \mathbb{R}^{n_{al} \times 1}$ 或 $y \in {0,1}^{n_{al} \times C}$ 表示样本标签，对于回归任务是连续值，对于分类任务是离散的类别标签（可能是one-hot编码形式）。$n_{al}$ 是对齐样本的数量，$d_A$ 和 $d_B$ 分别是A方和B方的特征维度，$C$ 表示分类任务的类别数。

同时，算法将各参与方的非对齐样本（无标签数据）聚合至初始的无标签数据集 $\mathcal{D}_U^{(0)}$：

$\mathcal{D}*{U}^{(0)} = {X*{nl}^A, X_{nl}^B}$

其中，$X_{nl}^A \in \mathbb{R}^{n_{nl} \times d_A}$ 表示A方未对齐样本的特征矩阵，$X_{nl}^B \in \mathbb{R}^{n_{nl} \times d_B}$ 表示B方未对齐样本的特征矩阵（这里的B方特征可能是部分已知的或者是初步预测的值）。$n_{nl}$ 是未对齐样本的数量。

这种数据分割策略明确区分了有标签样本和无标签样本，为后续的半监督学习奠定了基础。同时，由于初始化是在每个参与方本地进行的，没有原始数据的交换，因此确保了数据隐私的安全。

**2. 联邦模型训练与参数优化**

数据初始化完成后，VFPU-M算法在分布式环境下初始化一个联邦模型 $f_{\theta}$，并采用联邦学习的协议对模型参数 $\theta$ 进行协同更新。在每一轮迭代 $t$ 中，算法在当前的有标签数据集 $\mathcal{D}_L^{(t)}$ 上训练模型，通过最小化以下损失函数来优化模型参数：

$\theta^{(t)} \leftarrow \arg\min_\theta \sum_{(\mathbf{x}^A,\mathbf{x}^B,y)\in\mathcal{D}*L^{(t)}} \ell(f*\theta(\mathbf{x}^A,\mathbf{x}^B), y)$

这一数学表达式精确定义了参数优化的目标：找到能够最小化预测误差的模型参数 $\theta^{(t)}$。其中，$\ell(\cdot)$ 是损失函数，根据具体任务类型可以灵活选择：对于回归任务，通常使用均方误差（Mean Squared Error, MSE）；对于分类任务，则采用交叉熵损失（Cross Entropy Loss）或其他适合的分类损失函数。$f_\theta(\mathbf{x}^A,\mathbf{x}^B)$ 表示模型对输入特征 $\mathbf{x}^A$ 和 $\mathbf{x}^B$ 的预测输出，$y$ 是对应的真实标签。求和项表示对有标签数据集中的所有样本计算损失并求和。

具体实现中，这一参数优化通常采用梯度下降类算法，如随机梯度下降（SGD）、Adam等。在联邦学习框架下，各参与方先在本地数据上计算梯度，然后通过安全聚合协议汇总梯度信息，最终更新全局模型参数。这种分布式优化机制确保了在提升模型性能的同时，各参与方不需要直接交换原始数据，从而保护了数据隐私。

值得注意的是，随着迭代进行，有标签数据集 $\mathcal{D}_L^{(t)}$ 会不断扩充，包含越来越多的伪标签样本，这使得模型能够学习到更丰富的数据模式，提升泛化能力。同时，模型参数 $\theta^{(t)}$ 也在不断更新和优化，使得预测的准确性逐步提高。这种"数据扩充-模型优化"的正向循环是VFPU-M算法性能不断提升的关键机制。

**3. 多任务置信度评估与样本筛选**

模型训练完成后，VFPU-M算法进入关键的置信度评估与样本筛选阶段。这一阶段的创新之处在于设计了适应不同任务类型的置信度评估机制，能够准确识别那些预测置信度高的无标签样本：

首先，算法利用更新后的模型 $f_{\theta^{(t)}}$ 对当前无标签数据集 $\mathcal{D}_U^{(t)}$ 中的所有样本进行前向推断，并根据任务类型计算每个样本的置信度分数 $s_j$。这一过程可以用以下数学表达式描述：

$s_j = \begin{cases} \max_{c} \mathbb{P}(y=c|f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)) & \text{分类任务} \ 1 - \frac{|\hat{y}_j - \mu_t|}{\sigma_t} & \text{回归任务} \end{cases}$

这一表达式清晰地定义了不同任务类型下置信度的计算方法：

- 对于**分类任务**，置信度 $s_j$ 定义为模型输出的所有类别预测概率中的最大值 $\max_{c} \mathbb{P}(y=c|f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j))$。这里，$\mathbb{P}(y=c|f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j))$ 表示模型预测样本 $j$ 属于类别 $c$ 的概率，$\max_{c}$ 操作选取所有类别中概率最高的值。这种定义方式直观且有效：当模型对某一类别的预测概率远高于其他类别时，表明模型对该样本的分类具有高度确信，该样本适合被选为高置信度样本。
- 对于**回归任务**，置信度定义为 $1 - \frac{|\hat{y}_j - \mu_t|}{\sigma_t}$，其中 $\hat{y}*j = f*{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)$ 是模型对样本 $j$ 的预测值，$\mu_t$ 和 $\sigma_t$ 分别是当前批次预测值的均值和标准差。这种定义方式基于统计学原理：与预测分布中心越接近的样本，其预测值的不确定性通常越低，因此置信度越高。通过将预测值与分布中心的标准化距离映射到 $[0,1]$ 区间，算法可以量化样本预测的可靠程度。

计算完所有样本的置信度后，VFPU-M算法采用双重筛选机制，确保只有高质量的样本被选用于伪标签生成：

首先，设定一个置信度阈值 $\alpha \in [0,1]$，筛选出满足条件的候选样本集：

$\mathcal{C}^{(t)} = {(\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{D}_U^{(t)} | s_j \geq \alpha}$

这一筛选确保了只有置信度达到预设阈值 $\alpha$ 的样本才会被纳入考虑。阈值 $\alpha$ 是算法的一个关键超参数，其设置需要平衡两个方面：过高的阈值会导致选择的样本过少，限制模型学习；过低的阈值则可能引入过多低质量的伪标签，降低模型性能。实践表明，$\alpha$ 通常设置在 $[0.7, 0.9]$ 区间内能够取得较好的平衡。

为进一步提高所选样本的质量，算法引入了基于比例的二次筛选机制，从候选集中选取置信度最高的前 $k$ 比例样本，形成最终的高置信度样本集：

$\mathcal{S}^{(t)} = \text{TopK}(\mathcal{C}^{(t)}, k)$

其中，$\text{TopK}(\mathcal{C}^{(t)}, k)$ 操作表示从候选集 $\mathcal{C}^{(t)}$ 中选取置信度排名前 $k$ 比例的样本。这一二次筛选机制进一步降低了错误标记的风险，特别是在数据分布不均匀或模型不确定性较高的情况下，能够有效提高伪标签的质量。参数 $k$ 通常设置在 $[0.05, 0.2]$ 范围内，表示每轮迭代中新增伪标签样本的比例。较小的 $k$ 值意味着更谨慎的样本选择策略，适合数据质量参差不齐的场景；较大的 $k$ 值则可以加速模型训练，适合数据质量较为一致的情况。

这种基于置信度的双重筛选机制是VFPU-M算法的一个重要创新，它从统计学和机器学习理论角度出发，确保了伪标签样本的高质量，为后续的模型优化奠定了坚实基础。

**4. 多任务伪标签生成与数据集更新**

在成功识别高置信度样本后，VFPU-M算法进入伪标签生成与数据集更新阶段。这一阶段的设计同样考虑了不同任务类型的特性，采用了任务适应性的伪标签生成策略：

对于每个被选中的高置信度样本 $(\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{S}^{(t)}$，算法根据任务类型生成相应的伪标签 $\hat{y}_j$：

$\forall (\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{S}^{(t)}, \hat{y}*j = \begin{cases} \arg\max_c \mathbb{P}(y=c|f*{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)) & \text{分类任务} \ f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j) & \text{回归任务} \end{cases}$

这一表达式精确定义了不同任务下伪标签的生成方法：

- 对于**分类任务**，伪标签 $\hat{y}*j$ 采用 $\arg\max_c \mathbb{P}(y=c|f*{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j))$，即模型预测概率最高的类别索引。这里，$\arg\max_c$ 操作返回使得概率最大的类别 $c$。这种"取最大概率类别"的策略是分类任务中最常用的决策规则，能够最大程度地利用模型的分类能力。
- 对于**回归任务**，伪标签直接采用模型的预测输出 $\hat{y}*j = f*{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)$。这是因为回归任务的输出本身就是连续值，无需额外的转换操作。当模型对某个样本的预测置信度高时，该预测值很可能接近真实值，适合作为伪标签直接使用。

这种基于任务类型的自适应伪标签生成策略是VFPU-M算法的一个重要特色，它使得算法能够灵活应对不同类型的学习任务，无论是二分类、多分类还是回归问题，都能提供合适的伪标签生成机制。

生成伪标签后，算法对数据集进行更新，实现"有标签数据集扩充、无标签数据集收缩"的动态优化过程：

$\mathcal{D}_L^{(t+1)} \leftarrow \mathcal{D}_L^{(t)} \cup {(\mathbf{x}^A_j,\mathbf{x}^B_j,\hat{y}*j)}*{j\in\mathcal{S}^{(t)}}$ $\mathcal{D}_U^{(t+1)} \leftarrow \mathcal{D}_U^{(t)} \setminus \mathcal{S}^{(t)}$

第一个表达式描述了有标签数据集的扩充过程：将当前有标签数据集 $\mathcal{D}_L^{(t)}$ 与新生成的带伪标签样本集 ${(\mathbf{x}^A_j,\mathbf{x}^B_j,\hat{y}*j)}*{j\in\mathcal{S}^{(t)}}$ 合并，形成更大的有标签数据集 $\mathcal{D}_L^{(t+1)}$。这一操作扩大了模型的训练数据规模，使得模型能够学习到更多样本的特征模式。

第二个表达式描述了无标签数据集的更新：从当前无标签数据集 $\mathcal{D}_U^{(t)}$ 中移除已被赋予伪标签的样本集 $\mathcal{S}^{(t)}$，得到新的无标签数据集 $\mathcal{D}_U^{(t+1)}$。这一操作确保了已处理的样本不会在后续迭代中重复处理，保持了算法的高效性。

这种数据集动态更新机制具有多重优势：首先，它实现了训练数据的渐进式扩充，避免了一次性引入大量可能含噪的伪标签数据；其次，每轮迭代中模型性能的提升又能够提高下一轮伪标签的质量，形成正向循环；最后，通过动态调整有标签和无标签数据集的比例，算法能够在训练过程中逐渐从半监督学习向监督学习过渡，实现学习策略的自然演化。

**5. 迭代优化与最终输出**

VFPU-M算法采用迭代式学习架构，上述步骤（模型训练、置信度评估、样本筛选、伪标签生成、数据集更新）会重复执行多轮，直到达到预设的迭代次数 $T$ 或满足其他自定义的收敛条件。这种迭代式学习具有自我完善的特性：随着迭代进行，模型性能逐步提升，生成的伪标签质量也不断提高，进而促进模型在后续迭代中取得更好的表现。

在完成全部迭代后，算法进入最终输出阶段，将原始标签和所有生成的高质量伪标签合并，形成完整的预测结果向量：

$\mathbf{y}^{\text{pseudo}} = \left[ y, \bigcup_{t=1}^{T} {\hat{y}*j}*{j \in \mathcal{S}^{(t)}} \right]$

这一表达式清晰地描述了最终输出的构成：首先是原始对齐样本的真实标签 $y$，然后是各轮迭代中生成并通过质量筛选的伪标签 ${\hat{y}*j}*{j \in \mathcal{S}^{(t)}}$ 的并集。符号 $\bigcup_{t=1}^{T}$ 表示将 $T$ 轮迭代中生成的所有伪标签合并。这种"真实标签+伪标签"的混合输出结构，既保留了原始数据的真实性，又通过高质量伪标签扩展了标签覆盖范围，为后续的联邦学习提供了更加丰富和可靠的训练数据。

从数学角度分析，最终的预测结果向量 $\mathbf{y}^{\text{pseudo}} \in \mathbb{R}^{(n_{al}+n_{ps}) \times 1}$ 或 $\mathbf{y}^{\text{pseudo}} \in {0,1}^{(n_{al}+n_{ps}) \times C}$，其中 $n_{ps} \leq n_{nl}$ 表示通过VFPU-M算法成功生成伪标签的样本数量。这一数量通常小于等于初始未对齐样本数量 $n_{nl}$，因为只有那些预测置信度满足要求的样本才会被赋予伪标签。这种质量控制机制确保了最终输出结果的可靠性，即使在噪声数据或分布异常的环境中也能保持稳定的性能。

值得注意的是，VFPU-M算法的最终输出不仅包括标签向量 $\mathbf{y}^{\text{pseudo}}$，还隐含了这些标签对应的特征数据 $\mathbf{X}^A$ 和 $\mathbf{X}^B$。这些数据共同构成了一个增强的训练集，可以直接用于后续的联邦学习模型训练，显著提升模型的性能和泛化能力。

总体而言，VFPU-M算法通过系统性集成联邦学习与半监督学习的优势，创新性地解决了纵向联邦学习环境下的数据不对齐问题。其"迭代优化、质量筛选"的核心机制，以及"多任务适配、隐私保护"的设计理念，使其成为一种理论完备、实用高效的联邦半监督学习解决方案。无论是在分类任务还是回归任务中，VFPU-M算法都能够有效利用有限的标记数据和大量的未标记数据，在保护数据隐私的前提下实现优异的预测性能。

**VFPU-M算法的优势分析**

与其他半监督联邦学习方法相比，VFPU-M具有以下突出优势：

1. **伪标签迭代优化**：在标签缺乏的场景下，算法能够借助高置信度伪标签循序渐进地增强对无标签数据的利用效率，有效提升模型性能的同时保持良好的鲁棒性。
2. **多任务适应性**：VFPU-M同时支持分类任务和回归任务，通过灵活调整置信度度量与伪标签生成策略，可以轻松适配多种应用需求，大大扩展了算法的应用范围。
3. **隐私保护机制**：该算法在任何分布式或跨机构场景中都能显著降低数据泄露风险，各参与方只需交换必要的模型更新信息而无需分享原始数据，完全符合当下对隐私与安全的严格要求。
4. **异构数据处理能力**：由于VFPU-M采用迭代式的联邦训练与筛选机制，当数据中存在较大异质性时，算法可以逐步利用对齐与非对齐数据的混合信息，从而平衡不同分布、不同来源数据对模型的综合贡献。
5. **动态样本选择机制**：通过置信度阈值$\alpha$和样本选取比例$k$的双重控制，算法实现了对伪标签质量和数量的精细调节，可根据具体应用场景灵活配置，提高算法的适应性。

#### 3.2.3 低相关特征的生成与填补

在FedPSG-PUM方法框架中，对于与A方特征相关性低（即$\mu_q \leq \tau$）的B方特征，纵向联邦半监督学习方法（VFPU-M）可能无法提供足够准确的预测，因为这些特征与A方数据之间的统计关联性较弱，难以从A方特征中提取有效的预测信息。针对这一实际挑战，本节创新性地引入了基于生成模型与填补模型技术的低相关特征处理机制，通过捕捉这些特征的内部分布规律和结构特性，实现高质量的缺失数据补全。

**生成模型与填补模型原理**

低相关特征的生成与填补基于一个关键的统计学洞察：尽管这些特征与A方数据的相关性较低，但它们通常在B方数据内部具有一定的结构化特征和分布规律，可以通过先进的生成模型或填补模型进行学习和重构。具体而言，这些模型通过以下机制实现特征生成：

- **分布学习**：通过对B方已有数据（对齐样本部分）的分析，模型能够学习各特征的边缘分布和联合分布特性，包括均值、方差、偏度、峰度等统计指标，以及特征间的相关结构和条件依赖关系。
- **噪声重构**：一些生成模型（如VAE、DDPM）能够将数据映射到隐空间，通过向隐空间添加控制性噪声，然后逆映射回数据空间，生成与原始数据分布一致但具有新样本特性的数据。
- **对抗生成**：基于生成对抗网络（GAN）的模型通过生成器和判别器的对抗训练，不断优化生成数据的质量，使其在统计特性上接近真实数据，同时具有足够的多样性和新颖性。
- **条件填补**：填补模型能够基于已知特征条件化地生成缺失特征，利用特征间的依赖关系，通过概率推断或深度学习方法重建缺失值。

**FedPSG-PUM中的生成与填补实现**

在FedPSG-PUM方法实际部署中，低相关特征的生成与填补完全在B方本地进行，这一设计确保了数据隐私的严格保护，避免了跨方数据交换可能带来的隐私风险。具体实现时，本方法提供了多种先进技术选择，可根据实际数据特性和应用需求灵活配置：

1. **生成对抗网络类模型**：
   - **CTGAN（Conditional Tabular GAN）**：专为表格数据设计的条件生成对抗网络，能够有效处理混合类型（连续和离散）特征，保持特征间的复杂相关性。其创新点在于引入模式特定的正则化和条件向量，提高了对类别不平衡数据的生成质量。
   - **TableGAN**：针对表格数据优化的GAN变体，采用特殊的网络架构和训练策略，可以同时保持行级和列级的数据相关性，生成具有高度真实性和一致性的表格数据。
   - **CTAB-GAN**：结合了条件GAN和自注意力机制的表格数据生成模型，能够更好地捕捉特征间的长距离依赖关系，尤其适合处理高维稀疏特征和复杂类别特征。
2. **变分自编码器模型**：
   - **VAE（Variational Autoencoder）**：通过编码器将数据映射到隐空间的概率分布，然后通过解码器从隐空间采样生成新数据。其优势在于具有理论上的概率解释，能够生成多样化且结构合理的样本。
   - **TVAE（Tabular Variational Autoencoder）**：针对表格数据特性优化的VAE变体，采用特殊的编码和解码策略，更好地处理混合类型特征和缺失值情况。
3. **扩散概率模型**：
   - **TabDDPM（Tabular Denoising Diffusion Probabilistic Model）**：基于扩散过程的表格数据生成模型，通过逐步向数据添加高斯噪声然后学习逆向去噪过程，能够生成高质量的表格数据。该模型在捕捉复杂分布和条件依赖关系方面表现出色，尤其适合处理高维表格数据。
4. **专用填补模型**：
   - **GAIN（Generative Adversarial Imputation Network）**：结合GAN思想的缺失值填补模型，通过对抗训练机制学习缺失数据的条件分布，实现高质量的缺失值重构。
   - **VGAIN（Variational Generative Adversarial Imputation Network）**：融合VAE和GAIN的混合架构，既利用变分推断的概率建模能力，又借鉴对抗训练的生成质量提升机制，在多种缺失数据场景下表现优异。
   - **VF_GAIN（Vertical Federated GAIN）**：基于联邦学习框架的GAIN改进模型，能够在保护数据隐私的前提下，利用跨方信息协同填补缺失值，特别适合处理本章研究的纵向联邦缺失数据场景。

**集成策略与优化选择**

为进一步提升低相关特征生成的质量和稳定性，FedPSG-PUM方法还可以采用模型集成策略，综合多种生成模型或填补模型的输出结果。这种集成可以基于以下几种方式实现：

- **投票集成**：对于分类型特征，采用多个模型预测结果的多数投票作为最终输出。
- **加权平均**：对于连续型特征，基于各模型的性能指标计算加权平均值作为最终预测。
- **堆叠集成**：训练一个元模型，以多个基础模型的输出为输入，学习最优的组合方式。
- **动态选择**：根据样本特性或特征类型动态选择最适合的生成/填补模型，实现"因材施教"的自适应处理。

在实际应用中，模型的选择需要综合考虑数据特性、计算资源约束和性能要求。实验结果表明，对于大多数表格数据场景，TabDDPM和VF_GAIN通常能够提供最优的性能，特别是在特征类型复杂、分布不均匀或存在噪声的情况下。