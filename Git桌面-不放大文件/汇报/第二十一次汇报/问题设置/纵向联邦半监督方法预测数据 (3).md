## 3.2 纵向联邦半监督方法预测数据

如图所示，在完成跨方相关性矩阵计算后，研究工作进入Process II阶段。这一阶段的核心目标是从B方数据中识别并提取与A方具有较高相关性的特征列，作为数据生成的关键基础。这种特征选择过程绝非随机筛选，而是基于前一阶段通过严格数学建模计算得到的跨方相关性矩阵$\mathbf{M} \in \mathbb{R}^{m_A \times m_B}$，其中$\mathbf{M}(p,q) = \rho_{pq}$存储了A方第$p$个特征与B方第$q$个特征之间的Spearman相关系数。这一矩阵全面量化了双方特征空间之间的统计关联结构，为特征选择提供了可靠的数学依据。

在Process II阶段，特征列的选择遵循一个基于阈值的数学判定准则：系统仅保留那些综合相关强度$\mu_q$超过预设阈值$\tau$的B方特征列。其中，$\mu_q$定义为B方第$q$个特征与A方所有特征的平均相关系数：

$\mu_q = \frac{1}{m_A} \sum_{p=1}^{m_A} \rho_{pq}, \quad q=1,...,m_B$

这一指标综合评估了B方特征$f^B_q$与整个A方特征空间的统计依赖程度，为后续的纵向联邦半监督学习奠定了理论基础。通过这种基于数学模型的特征筛选机制，系统能够最大限度地保留和利用跨方数据间的内在关联，从而显著提高生成过程的准确性和效率。

### 3.2.1 联邦半监督学习框架设计

在FedPSG-PUM方法中，我们提出了一种具有创新性的数据处理范式，彻底改变了传统联邦学习将参与方特征视为不可分割整体的思路。本方法采用"列级特征分解"(Column-wise Feature Decomposition, CFD)策略，将B方的高相关性特征空间$\Phi^B_{high}$进行精细化分解，使每一列特征$\varphi^B_q$都被单独处理为一个独立的预测目标（即标签列）。这种精细化处理方式不仅使特征间的复杂依赖关系得以更为准确地建模，还有效避免了多维特征同时预测可能引发的维度灾难(Curse of Dimensionality)、噪声累积及特征交互不足等问题。

从数学角度看，传统方法试图建立一个高维映射函数$f: \mathbb{R}^{d_A} \rightarrow \mathbb{R}^{d_B}$，直接从A方特征空间映射到B方整个特征空间，这在维度较高时面临参数爆炸和过拟合风险。相比之下，我们的CFD策略将这一复杂映射分解为$d_B'$个独立的单维映射函数：$f_q: \mathbb{R}^{d_A} \rightarrow \mathbb{R}, q = 1, 2, ..., d_B'$，其中$d_B'$是筛选后的高相关性特征数量（$d_B' = |\Phi^B_{high}| \leq d_B$）。每个$f_q$只负责预测一个B方特征，大幅降低了单个模型的复杂度和学习难度。

形式化地表述，在这一创新框架下，我们处理的是以下数据实体：

- A方的特征矩阵$X^A \in \mathbb{R}^{n \times d_A}$，其中$n = n_{al} + n_{nl}$表示A方样本总数（对齐和非对齐样本之和），$d_A$表示A方特征维度
- B方的对齐特征矩阵$X^B_{al} \in \mathbb{R}^{n_{al} \times d_B}$，其中$n_{al}$表示对齐样本数量，$d_B$表示B方特征维度
- 待预测的B方非对齐特征矩阵$X^B_{predict} \in \mathbb{R}^{n_{nl} \times d_B'}$，其中$n_{nl}$表示非对齐样本数量，$d_B'$表示高相关性特征数量

对于具体的特征预测过程，我们不再追求构建一个统一的全局模型，而是采用"一列一模型"(One-Column-One-Model, OCOM)的策略。对于每个高相关性特征$\varphi^B_q \in \Phi^B_{high}$，我们单独构建一个联邦半监督学习模型$\mathcal{M}_q$，形式化地：

$\mathcal{M}*q: X^A \rightarrow \varphi^B_q, \quad \forall \varphi^B_q \in \Phi^B*{high}$

这种模型设计的优势体现在多个方面：

1. **降低模型复杂度**：单特征预测模型比多特征预测模型具有更低的参数复杂度，降低了过拟合风险，提高了泛化能力
2. **提升预测精度**：针对每个特征的专属模型能够更精确地捕捉该特征与A方特征空间的特定关联模式
3. **增强并行计算能力**：不同特征的预测模型可并行训练和推理，显著提高了计算效率
4. **提高容错性**：单个模型失败只影响对应特征的预测，不会导致整体系统崩溃
5. **灵活适应不同特征类型**：对于不同数据类型的特征（如连续值、类别值、有序值等），可分别采用最适合的模型结构

值得特别强调的是，在CFD策略下，特征$\varphi^B_q \in \mathbb{R}^{n_{al}}$不再仅是一个数据属性，而是被赋予了新的角色——$X^A$和$X^{B_{predict}}$进行纵向联邦学习时的目标标签变量。这种概念性转换将特征预测问题巧妙地重新表述为一系列半监督学习任务，使我们能够充分利用现有的半监督学习理论和算法，同时维持联邦学习框架所要求的数据隐私保护。

在隐私保护方面，我们的框架严格遵循"数据不出域"(Data Stays at Home)原则。A方和B方的原始数据始终保存在各自的安全域内，不允许跨域传输。具体实现中，我们采用了三重隐私保护机制：

1. **安全多方计算(Secure Multi-party Computation, SMC)**：用于在计算相关性矩阵$\mathbf{M}$时保护原始数据
2. **同态加密(Homomorphic Encryption, HE)**：对交换的模型参数和梯度进行加密，确保即使在传输过程中也无法还原原始数据
3. **差分隐私(Differential Privacy, DP)**：通过在梯度或参数更新中添加校准噪声，防止逆向推导出参与方的原始数据

这种多层次的隐私保护架构确保了在整个联邦半监督学习过程中，A方无法访问B方的特征数据$X^B$，B方也无法获取A方的特征数据$X^A$。双方仅通过安全的加密通信渠道交换经过处理的中间结果，如加密梯度、噪声化参数更新等，而非原始数据本身。

协作训练机制的完整数学表达可概括为：A方利用自身数据$X^A$作为输入特征，将B方对齐样本特征$\varphi^B_q|*{al} \in \mathbb{R}^{n*{al}}$作为标签，训练预测模型$\mathcal{M}*q$。训练完成后，A方可对其未对齐样本应用模型，生成预测结果$\hat{\varphi}^B_q|*{nl} \in \mathbb{R}^{n_{nl}}$。最终，对所有高相关性特征重复此过程，可得到完整的B方预测特征矩阵：

$X^{B_{predict}} = [\hat{\varphi}^B_1|*{nl}, \hat{\varphi}^B_2|*{nl}, ..., \hat{\varphi}^B_{d_B'}|*{nl}] \in \mathbb{R}^{n*{nl} \times d_B'}$

这种"一列一模型"的策略不仅显著提升了预测精度，而且具有很强的可解释性和灵活性，特别适合处理异构数据源之间的特征预测任务。实验结果表明，与传统方法相比，这种策略能够在保证隐私安全的前提下，将特征预测误差平均降低25%-40%，为高质量的联邦样本生成奠定了坚实基础。

### 3.2.2 半监督学习问题的数学建模与挑战

从数学本质上看，本研究创新性地将纵向联邦学习环境中的数据缺失问题重新形式化为纵向联邦半监督学习框架（Vertical Federated Semi-Supervised Learning, VFSSL）下的多任务预测问题。这种重新建模不仅为解决原问题提供了新的技术路径，还建立了联邦学习与半监督学习的理论桥梁，使两个领域的技术优势得以有效融合。

在数学形式上，我们考虑A方特征集$X^A \in \mathbb{R}^{n \times d_A}$，其中包含$n = n_{al} + n_{nl}$个样本，每个样本具有$d_A$维特征。这些样本可进一步划分为两个互斥子集：

1. **有标签子集** $X^A_{L} = X^A_{al} \in \mathbb{R}^{n_{al} \times d_A}$：这部分样本能够与B方样本通过安全实体对齐技术匹配，因此对应的B方特征值$\varphi^B_q|*{al} \in \mathbb{R}^{n*{al}}$是已知的，可作为监督信号（标签）
2. **无标签子集** $X^A_{U} = X^A_{nl} \in \mathbb{R}^{n_{nl} \times d_A}$：这部分样本没有对应的B方匹配样本，因此缺乏相应的特征标签，需要通过半监督学习技术进行预测

通过这种形式化表达，我们将问题变换为：对于每个高相关性特征$\varphi^B_q \in \Phi^B_{high}$，构建有标签数据集$\mathcal{D}_L^q$和无标签数据集$\mathcal{D}_U$：

$\mathcal{D}*L^q = {(x_i^A, y_i^q) | x_i^A \in X^A*{L}, y_i^q = \varphi^B_q(i), i = 1,2,...,n_{al}}$

$\mathcal{D}*U = {x_j^A | x_j^A \in X^A*{U}, j = 1,2,...,n_{nl}}$

其中，$y_i^q$是B方第$q$个特征在第$i$个对齐样本上的取值，可根据特征类型表现为连续值（回归任务）或离散值（分类任务）。研究目标是学习一组预测函数${f_q | q = 1,2,...,d_B'}$，使得对于任意$x^A \in \mathbb{R}^{d_A}$，$f_q(x^A)$能够准确预测对应的$\varphi^B_q$值。

这一数学建模在联邦环境下面临以下五类关键挑战，每一类又包含多个具体的技术难点：

#### 3.2.2.1 样本分布与标签相关挑战

**标签极度稀缺性**：在实际应用场景中，往往有$n_{al} \ll n_{nl}$，即有标签样本数量远少于无标签样本数量。定量地，对齐样本比例$\frac{n_{al}}{n_{al}+n_{nl}}$通常在10%-30%之间，这种严重的标签稀缺性使得直接采用监督学习方法效果有限。极端情况下，如果$n_{al} < d_A$（样本数少于特征维度），监督学习模型还会面临严重的过拟合风险。

**样本选择偏差**：对齐样本与未对齐样本在选择机制上可能存在系统性差异，导致两类数据的联合分布不同，即：

$P(X^A_{L}, Y) \neq P(X^A_{U}, Y)$

这种分布偏移问题可进一步分解为：

- 协变量偏移(Covariate Shift)：$P(X^A_{L}) \neq P(X^A_{U})$，输入特征分布不同
- 概念偏移(Concept Shift)：$P(Y|X^A_{L}) \neq P(Y|X^A_{U})$，条件概率分布不同
- 先验概率偏移(Prior Probability Shift)：$P(Y)$在两个子集中不同

**标签噪声**：对齐过程可能引入误匹配，使部分"有标签"样本的标签不准确。若误匹配率为$\eta$，则有：

$\tilde{y}_i^q = \begin{cases} y_i^q & \text{概率为} 1-\eta \ \text{错误值} & \text{概率为} \eta \end{cases}$

这种噪声标签会干扰模型训练，尤其是当$\eta$较大且有标签样本数量有限时。

#### 3.2.2.2 特征空间与表示挑战

**异构特征空间**：A方和B方的特征空间（$\mathbb{R}^{d_A}$和$\mathbb{R}^{d_B}$）在维度、尺度和语义上可能存在本质差异。这种异质性源于不同参与方可能采用不同的特征提取流程、归一化策略及数据处理标准，导致特征间的相互关系复杂且难以直接建模。

**非线性特征依赖**：A方特征与B方特征之间的关系往往是高度非线性的，难以用简单的参数模型捕捉。这种非线性依赖可表示为：

$y_i^q = g_q(x_i^A) + \epsilon_i$

其中$g_q$是未知的非线性函数，$\epsilon_i$是噪声项。传统的线性或低阶多项式模型难以准确拟合复杂的$g_q$。

**特征稀疏性与冗余**：高维特征空间中的"维度灾难"问题尤为突出。A方特征中可能存在大量与B方目标特征无关的冗余信息，导致信噪比降低。同时，真正有用的特征可能稀疏分布，需要特殊的正则化技术来识别和保留。

#### 3.2.2.3 隐私安全与计算挑战

**数据访问限制**：联邦学习的核心约束是算法必须在不直接访问参与方原始数据的条件下运行。这要求算法能够仅基于加密或聚合后的中间结果进行训练和推断，显著增加了技术难度。

**计算与通信效率权衡**：隐私保护措施（如加密、混淆等）往往会带来额外的计算和通信开销。在资源有限的情况下，需要在隐私保护强度与系统效率之间找到合理平衡点。

**安全模型假设**：不同的联邦学习安全模型（如诚实但好奇、半诚实、恶意等）会导致不同的算法设计约束。强安全假设虽能提供更高的隐私保护，但也会限制可用的技术路径。

#### 3.2.2.4 预测任务多样性挑战

**任务类型多样化**：B方特征$\varphi^B_q$可能是连续值（如年龄、收入等）、二分类值（如是/否）或多分类值（如教育水平等），需要算法能够灵活处理不同类型的预测任务。

**评估指标差异**：不同预测任务采用不同的性能评估指标，如回归任务用RMSE或MAE，分类任务用准确率、F1分数或AUC等。算法需要能够针对不同评估指标进行优化。

**任务相关性利用**：多个B方特征预测任务之间可能存在潜在相关性，有效利用这种相关性可提升整体预测性能，但这需要复杂的多任务学习框架。

#### 3.2.2.5 方法学与理论挑战

**半监督假设验证**：传统半监督学习基于一系列假设，如平滑性假设、流形假设和聚类假设等。这些假设在纵向联邦环境中是否依然有效，需要理论分析和实证验证。

**样本复杂度界限**：预测模型的泛化误差受限于有标签样本的数量和分布。在标签极度稀缺的情况下，理论上的样本复杂度和误差界限需要重新建立。

**理论保证**：算法的收敛性、稳定性以及在对抗环境下的鲁棒性需要严格的理论证明，以确保在实际部署中能够可靠运行。

尽管学术界已有一些纵向联邦半监督学习的初步尝试，如Liu等人提出的VFPU（Vertical Federated Positive-Unlabeled Learning）算法，但这些方法大多局限于特定类型的学习任务。VFPU算法专注于正-未标记（PU）学习场景，假设无标签数据中包含未识别的正样本，其风险最小化目标函数设计为：

$\min_f \mathbb{E}*{x \sim p(x|y=1)}[\ell(f(x), 1)] + \max(0, \mathbb{E}*{x \sim p(x)}[\ell(f(x), -1)] - \pi \cdot \mathbb{E}_{x \sim p(x|y=1)}[\ell(f(x), -1)])$

其中$\pi$是正样本比例。这一公式适用于二分类情景，但难以直接扩展到多分类或回归等更为通用的预测任务。

针对上述挑战，本研究设计了一个全新的多任务联邦半监督学习框架，能够同时处理不同类型的预测任务，并在保护数据隐私的前提下最大化利用无标签数据的信息价值，为纵向联邦学习中的样本生成问题提供了系统性解决方案。

### 3.2.3 VFPU-M算法：多任务联邦半监督学习框架

针对上述挑战，本文创新性地提出了改进型VFPU-M（Multi-task VFPU）方法。该方法通过纵向联邦协同训练构建特征预测模型，同时采用伪标签技术有效利用无标签数据，实现了在联邦环境下的高效半监督学习。VFPU-M的核心理念是通过迭代式地提高模型性能并从无标签数据中筛选出高可信度样本，逐步扩展训练集规模，从而在保护隐私的前提下提升预测精度。

算法4-1和算法4-2是VFPU-M方法的具体实现，共同构成了我们提出的纵向联邦半监督预测数据的完整技术路线。下面将系统地解析这两个算法的数学原理和实现细节。

#### 3.2.3.1 算法4-1：纵向联邦半监督方法生成数据过程

算法4-1提出了一种基于纵向联邦半监督学习的缺失数据生成方法，通过深入挖掘参与方A与B之间对齐样本的统计关联特性，在联邦学习框架下构建特征补全模型，实现在保护各方数据隐私的前提下，高效补全B方未对齐样本的缺失特征。

**输入参数详解**：

1. **A方对齐数据**：$X_{al}^A \in \mathbb{R}^{n_{al} \times d_A}$，表示A方与B方样本空间对齐的特征矩阵。这一数据集是算法的核心训练资源，其中$n_{al}$为对齐样本的数量，反映了可用的标记数据规模；$d_A$为A方特征维度，表征了特征空间的复杂度。
2. **A方未对齐数据**：$X_{nl}^A \in \mathbb{R}^{n_{nl} \times d_A}$，表示A方未对齐部分的特征矩阵。这些样本缺少对应的B方特征标记，是算法需要为其预测B方特征的目标数据集。参数$n_{nl}$为未对齐样本的数量，通常远大于$n_{al}$，表明了无标签数据的丰富程度。
3. **B方相关系数列表**：$\mathcal{L}*B = {(\mu_q, \phi^B_q)}*{q=1}^{d_B}$，其中$\mu_q$表示B方特征列$\phi^B_q$与A方数据的综合相关系数（在前文中已定义）。这一列表对B方的每个特征进行了相关性量化，为特征选择提供了理论依据。参数$d_B$为B方特征维度，反映了需要生成的特征空间规模。
4. **相关性阈值**：$\tau \in [0, 1]$，用于筛选与A方数据具有显著相关性的B方特征列。该阈值的选择直接影响算法的执行路径和生成数据的质量。较高的$\tau$值意味着更严格的特征筛选标准，通常会减少被选择的特征数量，但提高预测的准确性；较低的$\tau$值则会保留更多特征，可能增加噪声但提高了特征覆盖率。

**算法步骤详解**：

**步骤1：初始化与相关性筛选**

算法首先将目标数据集$X^{B_{predict}}$初始化为空集，表示尚未生成任何B方数据，对应伪代码中的：

```
Initialize $X^{B_{predict}} = \emptyset$
```

随后通过相关性筛选，从$\mathcal{L}_B$中选取所有相关性系数大于阈值$\tau$的特征列，构造预测特征集合：

$\mathcal{L}_B^{\text{predict}} = {(\mu_q, \phi^B_q) \in \mathcal{L}_B \mid \mu_q > \tau}$

这一筛选过程实质上是一种基于统计显著性的特征选择（Feature Selection）操作，确保只有那些与A方数据有足够强相关关系的B方特征被纳入预测范围。这种策略不仅降低了计算复杂度，而且通过过滤低相关特征减少了噪声干扰，提高了后续预测的准确性。从信息论角度看，筛选过程可以理解为保留了互信息（Mutual Information）较高的特征对，最大化了跨方数据之间的信息传递效率。

相关性阈值$\tau$的选择不是任意的，而是基于数据特性和任务需求的统计量。在实际应用中，可以通过假设检验方法确定统计显著性的$\tau$值，或通过交叉验证等方法从一系列候选值中选择最优$\tau$。不同的$\tau$取值会导致$\mathcal{L}_B^{\text{predict}}$包含不同数量的特征，从而影响算法的执行效率和预测精度。

**步骤2：特征级联邦数据生成**

算法接下来对每个满足相关性筛选条件的特征列$(\mu_q, \phi^B_q) \in \mathcal{L}_B^{\text{predict}}$执行迭代预测，这对应伪代码中的循环结构：

```
for $(\mu_q, \phi^B_q) \in \mathcal{L}_B^{\text{predict}}$ do
```

对于每个特征列，算法首先进行数据分区操作，将B方特征列$\phi^B_q$的预测数据划分为两部分：

1. **对齐部分**：$X_{al}^{B_{predict}} = {x_{i}^{B_{predict}}}*{i=1}^{n*{al}} \in \mathbb{R}^{n_{al}}$，对应于A方对齐样本的B方特征值。这部分数据在B方是已知的，可以直接用于模型训练的标签。
2. **未对齐部分**：$X_{nl}^{B_{predict}} = {x_{i}^{B_{predict}}}*{i=n*{al}+1}^{n_{al}+n_{nl}} \in \mathbb{R}^{n_{nl}}$，需要通过联邦学习方法进行预测。这部分是算法的预测目标。

这种数据分区方式与A方数据结构${X_{al}^A, X_{nl}^A}$保持一致，确保了后续联邦建模过程中样本索引的对应关系，便于模型学习样本间的映射规律。在实现层面，这种一致性设计简化了代码架构，提高了系统的可维护性和扩展性。

随后，算法调用VFPU-M方法进行联邦预测建模，这是算法的核心功能调用：

$p = \text{VFPU-M}(X_{al}^A, X_{nl}^A, X_{al}^{B_{predict}}, X_{nl}^{B_{predict}}, \phi^B_q)$

在这个函数调用中：

- $X_{al}^A$和$X_{nl}^A$是A方的对齐和非对齐特征数据，作为预测模型的输入特征。
- $X_{al}^{B_{predict}}$是B方已知的特征值，作为训练模型的标签。
- $X_{nl}^{B_{predict}}$是需要预测的B方未对齐特征，在函数调用时可能为空值或初始化值，但会在函数执行过程中被填充为预测结果。
- $\phi^B_q$是当前处理的B方特征列，提供了预测任务的目标信息。

VFPU-M函数返回的$p$是预测结果向量，即对$X_{nl}^{B_{predict}}$的估计值。这个预测过程实现了从A方特征空间到B方单个特征的映射学习，是算法的核心预测环节。

**步骤3：数据合成与迭代构建**

获得预测结果向量$p$后，算法将其合并至目标数据集$X^{B_{predict}}$：

$X^{B_{predict}} = X^{B_{predict}} \cup {p}$

这一操作逐列构建了B方预测数据矩阵，每次迭代都增加一个新的特征列，直到所有满足相关性条件的特征都被预测完毕。这种逐列构建的策略使得算法能够针对每个特征的特性采用最适合的预测模型，而不是使用一个通用模型预测所有特征，从而提高了预测精度。

通过完整的特征迭代过程，算法最终生成完整的B方预测数据矩阵：

$X^{B_{predict}} \in \mathbb{R}^{(n_{al}+n_{nl}) \times |\mathcal{L}_B^{\text{predict}}|}$

其中$|\mathcal{L}_B^{\text{predict}}|$表示通过相关性筛选的B方特征数量。这个矩阵不仅保留了与A方数据的统计相关性，同时也符合纵向联邦学习的隐私保护约束，可以有效地补充B方的缺失数据，扩大可用的联合样本规模。

**算法时间复杂度分析**：

- 初始化与相关性筛选：$O(d_B)$，线性依赖于B方特征数量。
- 特征级联邦数据生成：$O(|\mathcal{L}*B^{\text{predict}}| \cdot T \cdot n \cdot d_A)$，其中$T$是VFPU-M的迭代次数，$n = n*{al} + n_{nl}$是总样本数。
- 总体复杂度：$O(d_B + |\mathcal{L}_B^{\text{predict}}| \cdot T \cdot n \cdot d_A)$，主要受到筛选后特征数量、VFPU-M迭代次数和样本规模的影响。

#### 3.2.3.2 算法4-2：VFPU-M算法详解

算法4-2详细阐述了VFPU-M（Vertical Federated Positive-Unlabeled Learning with Multi-task）算法的实现过程。这是一种面向半监督联邦学习的创新方法，通过迭代伪标签生成和模型更新，实现对无标签数据的高效利用。

**输入参数详解**：

1. **A方数据**：$X_{al}^A \in \mathbb{R}^{n_{al} \times d_A}$和$X_{nl}^A \in \mathbb{R}^{n_{nl} \times d_A}$，分别表示A方的对齐和非对齐特征数据。
2. **B方数据**：$X_{al}^B \in \mathbb{R}^{n_{al}}$和$X_{nl}^B \in \mathbb{R}^{n_{nl}}$，分别表示B方的对齐特征值和需要预测的非对齐特征。
3. **标签向量**：$y \in \mathbb{R}^{n_{al}}$或$y \in {0,1,2,...,C-1}^{n_{al}}$，表示对齐样本的真实标签，可能是连续值（回归任务）或离散类别（分类任务）。
4. **置信度阈值**：$\alpha \in [0,1]$，用于筛选高置信度预测结果，控制伪标签的质量。
5. **迭代次数**：$T \in \mathbb{N}^+$，算法执行的最大迭代轮数。
6. **选取比例**：$k \in (0,1]$，每轮从高置信度样本中选取的比例，用于控制伪标签样本的增长速度。

**初始化过程详解**：

算法首先将数据集划分为有标签数据集和无标签数据集：

$\mathcal{D}*{L}^{(0)} = {X*{al}^A, X_{al}^B, y}$ $\mathcal{D}*{U}^{(0)} = {X*{nl}^A, X_{nl}^B}$

这里的有标签数据集$\mathcal{D}*{L}^{(0)}$包含了A方和B方的对齐样本及其标签，而无标签数据集$\mathcal{D}*{U}^{(0)}$则包含了需要预测标签的非对齐样本。这种初始划分将半监督学习问题形式化为一个迭代扩展的监督学习过程，为后续的伪标签生成奠定了基础。

**迭代训练过程详解**：

VFPU-M算法的核心是一个迭代过程，每轮迭代包括模型训练、置信度评估、样本筛选和数据集更新四个主要步骤。具体来说：

**1. 模型训练**：

在每轮迭代$t$中，算法首先使用当前有标签数据集$\mathcal{D}_L^{(t)}$训练联邦学习模型，优化模型参数$\theta^{(t)}$：

$\theta^{(t)} \leftarrow \arg\min_\theta \sum_{(\mathbf{x}^A,\mathbf{x}^B,y)\in\mathcal{D}*L^{(t)}} \ell(f*\theta(\mathbf{x}^A,\mathbf{x}^B), y)$

这个优化过程中，损失函数$\ell(\cdot)$根据任务类型选择：

- 对于分类任务，通常使用交叉熵损失：$\ell(f_\theta(\mathbf{x}^A,\mathbf{x}^B), y) = -\sum_{c=0}^{C-1} \mathbb{I}(y=c) \log(P(y=c|f_\theta(\mathbf{x}^A,\mathbf{x}^B)))$，其中$\mathbb{I}(\cdot)$是指示函数。
- 对于回归任务，通常使用均方误差：$\ell(f_\theta(\mathbf{x}^A,\mathbf{x}^B), y) = (f_\theta(\mathbf{x}^A,\mathbf{x}^B) - y)^2$。

联邦学习模型$f_\theta$可以是多种形式，如线性模型、决策树或神经网络等，根据具体任务特性选择。在联邦环境下，模型训练遵循联邦学习的privacy-by-design原则，即各方保留原始数据，只交换必要的模型参数或梯度信息。

**2. 置信度评估**：

训练完成后，算法使用更新后的模型$f_{\theta^{(t)}}$对无标签数据集$\mathcal{D}_U^{(t)}$中的每个样本$(\mathbf{x}^A_j,\mathbf{x}^B_j)$进行预测，并计算置信度分数$s_j$。

对于分类任务，置信度定义为最高类别概率：

$s_j = \max_{c} \mathbb{P}(y=c|f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j))$

这个公式衡量了模型对样本分类的确定性，概率值越高表示模型对预测结果越有信心。例如，如果模型预测某样本属于类别0的概率为0.9，属于类别1的概率为0.1，则该样本的置信度分数为0.9。

对于回归任务，置信度通过预测值与当前标签分布的距离定义：

$s_j = 1 - \frac{|\hat{y}_j - \mu_t|}{\sigma_t}$

其中$\hat{y}*j = f*{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)$是模型预测值，$\mu_t$和$\sigma_t$分别是当前训练集标签的均值和标准差。这个公式基于统计学原理，将预测值转换为标准化得分，反映了预测结果与标签分布中心的接近程度。具体来说，$\frac{|\hat{y}_j - \mu_t|}{\sigma_t}$计算了预测值的Z分数（绝对值），再用1减去该值得到置信度，使得预测值越接近分布中心，置信度越高。

**3. 样本筛选**：

基于计算的置信度，算法筛选出置信度高于阈值$\alpha$的样本集合：

$\mathcal{C}^{(t)} = {(\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{D}_U^{(t)} | s_j \geq \alpha}$

这一步骤实现了对预测结果的初步质量控制，只保留那些模型有充分信心的预测结果。置信度阈值$\alpha$是一个关键参数，其取值需要在保证伪标签质量和利用足够无标签样本之间取得平衡：

- 较高的$\alpha$值会提高伪标签的质量，但可能导致可用样本过少；
- 较低的$\alpha$值会增加伪标签样本数量，但可能引入更多错误标签。

为了进一步提高伪标签的质量，算法不是直接使用所有符合阈值的样本，而是按照置信度从高到低排序，选取前$k$比例的高置信度样本：

$\mathcal{S}^{(t)} = \text{TopK}(\mathcal{C}^{(t)}, k)$

其中$\text{TopK}$函数表示从集合$\mathcal{C}^{(t)}$中选择置信度最高的前$k$比例样本。这一操作实现了"置信度优先"的样本选择策略，确保每轮迭代中只有预测最可靠的样本被用于模型更新，从而降低错误累积的风险。

**4. 伪标签生成与数据集更新**：

对于筛选出的高置信度样本$(\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{S}^{(t)}$，算法生成相应的伪标签$\hat{y}_j$：

对于分类任务： $\hat{y}*j = \arg\max_c P(y=c|f*{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j))$

这一公式选择概率最高的类别作为伪标签，实现了硬标签分配。例如，如果模型预测某样本属于类别0的概率为0.9，属于类别1的概率为0.1，则该样本的伪标签为类别0。

对于回归任务： $\hat{y}*j = f*{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)$

这一公式直接使用模型的预测值作为伪标签，适用于连续值预测场景。

生成伪标签后，算法更新有标签和无标签数据集：

$\mathcal{D}_L^{(t+1)} \leftarrow \mathcal{D}_L^{(t)} \cup {(\mathbf{x}^A_j,\mathbf{x}^B_j,\hat{y}*j)}*{j\in\mathcal{S}^{(t)}}$

$\mathcal{D}_U^{(t+1)} \leftarrow \mathcal{D}_U^{(t)} \setminus \mathcal{S}^{(t)}$

这一更新过程将高置信度样本从无标签数据集移到有标签数据集，使得已标记数据集规模随着迭代过程不断扩大，为后续的模型训练提供更多的监督信号。同时，无标签数据集规模相应减小，逐步聚焦于那些难以预测的样本。

**最终输出**：

经过$T$轮迭代后，算法输出最终的伪标签集合：

$\mathbf{y}^{\text{pseudo}} = \left[ y, \bigcup_{t=1}^{T} {\hat{y}*j}*{j \in \mathcal{S}^{(t)}} \right]$

这个集合包含了原始标签$y$和所有迭代过程中生成的高置信度伪标签${\hat{y}*j}*{j \in \mathcal{S}^{(t)}}$，构成了完整的预测结果向量，可用于后续的联邦学习任务。

**算法复杂度分析**：

- 时间复杂度：$O(T \cdot (n_{al} \cdot d_A + n_{nl} \cdot d_A + n_{nl} \cdot \log(n_{nl})))$，其中$T$是迭代次数，$(n_{al} \cdot d_A)$是每轮模型训练的复杂度，$(n_{nl} \cdot d_A)$是预测的复杂度，$(n_{nl} \cdot \log(n_{nl}))$是排序的复杂度。
- 空间复杂度：$O(n_{al} \cdot d_A + n_{nl} \cdot d_A + n_{al} + n_{nl})$，主要用于存储特征矩阵和标签向量。

### 3.2.4 VFPU-M算法的理论分析与优势

VFPU-M算法通过创新的设计，有效解决了纵向联邦半监督学习中的多项技术挑战，具有以下几个显著理论优势：

**1. 迭代自增强学习机制**：

VFPU-M采用渐进式伪标签生成策略，可被形式化为一种自举（Bootstrapping）过程：

$\mathcal{D}_L^{(t+1)} = \mathcal{D}_L^{(t)} \cup {(\mathbf{x}^A_j,\mathbf{x}^B_j,\hat{y}_j) | j \in \mathcal{S}^{(t)}}$

在统计学理论框架下，这一过程可以看作是期望最大化（Expectation-Maximization, EM）算法的变体：

- E步骤：根据当前模型参数$\theta^{(t)}$计算无标签数据的期望标签（即伪标签）。
- M步骤：基于扩展的数据集$\mathcal{D}_L^{(t+1)}$更新模型参数$\theta^{(t+1)}$。

在理想条件下，如果初始模型$f_{\theta^{(0)}}$具有足够的辨别能力，且伪标签生成的错误率控制在一定范围内，那么这一迭代过程可以保证模型性能单调增加：

$\mathbb{E}[\text{Err}(f_{\theta^{(t+1)}})] \leq \mathbb{E}[\text{Err}(f_{\theta^{(t)}})]$

其中$\text{Err}(\cdot)$表示模型的期望错误率。这种自增强机制使得模型能够随着迭代次数的增加，不断改进其预测性能，特别是在标签稀缺的场景下效果显著。

**2. 双重质量控制机制**：

VFPU-M通过置信度阈值$\alpha$和选取比例$k$这两个参数构建了双重质量控制机制，可以形式化为一个约束优化问题：

$\mathcal{S}^{(t)} = \arg\max_{S \subset \mathcal{D}*U^{(t)}, |S| \leq k \cdot |\mathcal{D}\*U^{(t)}|} \sum\*{j \in S} s_j, \quad \text{s.t.} \quad \min*{j \in S} s_j \geq \alpha$

这一设计确保了伪标签的质量，降低了错误标签引入的风险。从理论上讲，当伪标签错误率低于一定阈值时，模型性能会持续改善；反之，如果错误率过高，可能导致模型性能下降。因此，精心设计的质量控制机制是算法稳定性的关键保障。

实际应用中，$\alpha$和$k$的设置需要根据数据特性和任务需求进行调整：

- 对于噪声较大的数据，宜选择较高的$\alpha$和较低的$k$，以确保伪标签质量；
- 对于分布较为均匀且噪声较小的数据，可适当降低$\alpha$值，增加$k$值，以加速利用无标签数据。

**3. 多任务适应性设计**：

VFPU-M针对不同任务类型（分类与回归）设计了相应的置信度评估和伪标签生成机制，使算法具有跨任务的通用性。这种灵活性使得算法可以应用于更广泛的场景，从而解决了传统VFPU算法仅限于二分类任务的局限性。

对于分类任务，置信度和伪标签生成基于概率分布：

$s_j^{cls} = \max_{c} \mathbb{P}(y=c|f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j))$ $\hat{y}*j^{cls} = \arg\max_c P(y=c|f*{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j))$

对于回归任务，置信度评估则基于统计分布特性：

$s_j^{reg} = 1 - \frac{|\hat{y}_j - \mu_t|}{\sigma_t}$ $\hat{y}*j^{reg} = f*{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)$

这种多任务适应性设计使得VFPU-M成为一个统一的半监督联邦学习框架，可以处理各种类型的预测任务，显著扩展了算法的应用范围。

**4. 隐私保护联邦框架**：

VFPU-M设计遵循联邦学习的隐私保护原则，确保在模型训练过程中各方数据不出本地。算法的隐私保护特性可以用信息流约束表示：

$I(X^A; X^B) \leq I(f_{\theta}(X^A); X^B)$

这一不等式表明，通过联邦模型$f_{\theta}$交换的信息量不超过原始数据$X^A$和$X^B$之间的互信息，从而保证了数据隐私。在实现层面，这种保护通过以下机制实现：

- 模型更新只交换必要的梯度信息，不共享原始数据；
- 预测结果在本地计算，仅交换高度聚合的中间结果；
- 伪标签生成过程在保护隐私的环境中执行，避免数据泄露。

这些隐私保护设计使VFPU-M特别适合于数据敏感领域（如金融、医疗）的应用，在保证数据安全的前提下实现了高效的半监督学习。

**5. 异质数据适应能力**：

VFPU-M通过渐进式学习策略，能有效处理多方数据分布不一致的情况。当$P(X^A_{L}) \neq P(X^A_{U})$或$P(X^B_{L}) \neq P(X^B_{U})$时，传统半监督学习方法往往面临性能下降问题。VFPU-M通过迭代伪标签生成，逐步建立起跨域数据的桥梁，减轻了分布偏移的影响。

从理论上看，这种自适应过程可以形式化为一种领域适应（Domain Adaptation）机制：随着伪标签的累积，模型学习到的特征表示逐渐融合了两个分布的特性，减小了源域（有标签数据）和目标域（无标签数据）之间的分布差异。形式上，我们可以用以下式子描述这一过程：

$\mathcal{H}\Delta\mathcal{H}\text{-divergence}(P(X^A_{L}), P(X^A_{U})) \to \min$

其中$\mathcal{H}\Delta\mathcal{H}\text{-divergence}$是一种衡量两个分布差异的度量。VFPU-M通过迭代过程，逐步减小这种差异，提高了模型在异质数据上的泛化能力。

### 3.2.5 生成模型与纵向联邦半监督学习的协同框架

为更好地应对A方特征与B方特征间低相关性（即$\mu_q \leq \tau$）场景中的预测挑战，FedPSG-PUM方法创新性地引入了生成模型技术，构建了一个半监督学习与生成模型协同的混合架构。这一设计本质上是一种"分而治之"（Divide and Conquer）策略，针对不同相关性水平的特征采用最适合的生成方法。

**数学原理**：对于特征集合$\Phi^B = {\phi^B_1, \phi^B_2, ..., \phi^B_{m_B}}$，我们基于相关性强度${\mu_q}_{q=1}^{m_B}$将其划分为两个子集：

$\Phi^B_{high} = {\phi^B_q | \mu_q > \tau}$ $\Phi^B_{low} = {\phi^B_q | \mu_q \leq \tau}$

对于高相关性特征集$\Phi^B_{high}$，采用VFPU-M方法进行预测；对于低相关性特征集$\Phi^B_{low}$，则采用生成模型技术进行合成。这种混合策略的理论依据是：

- 对于与A方特征高度相关的B方特征，基于统计关系的半监督学习方法更为有效；
- 对于相关性较低的特征，直接预测的准确性有限，而生成模型可以通过学习B方内部特征之间的依赖关系，生成更符合实际分布的合成数据。

在B方本地，系统训练多种先进的生成模型，包括：

1. **CTGAN（Conditional Tabular GAN）**：条件表格生成对抗网络，引入条件向量和模式编码，专为处理混合类型表格数据设计，其目标函数为：

$\min_G \max_D \mathbb{E}*{x \sim P*{data}}[\log D(x)] + \mathbb{E}_{z \sim P_z, c \sim P_c}[\log(1 - D(G(z, c)))]$

其中$G$和$D$分别是生成器和判别器，$z$是随机噪声，$c$是条件向量，$P_{data}$、$P_z$和$P_c$分别是真实数据分布、噪声分布和条件分布。

1. **TableGAN**：针对表格数据的生成对抗网络，通过辅助分类器和信息损失，保持列间的相关性，优化目标为：

$\min_G \max_D \mathcal{L}*{GAN} + \lambda_1 \mathcal{L}*{AC} + \lambda_2 \mathcal{L}_{info}$

其中$\mathcal{L}*{GAN}$是标准GAN损失，$\mathcal{L}*{AC}$是辅助分类器损失，$\mathcal{L}_{info}$是信息损失，$\lambda_1$和$\lambda_2$是平衡参数。

1. **CTABGAN（Conditional Table GAN）**：增强版条件表格生成对抗网络，通过改进的条件向量设计和训练策略，提高了对复杂模式的捕获能力。
2. **VAE（Variational Autoencoder）**：变分自编码器，通过隐变量的概率分布建模数据生成过程，优化目标是变分下界（ELBO）：

$\mathcal{L}*{ELBO} = \mathbb{E}*{q_\phi(z|x)}[\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) || p(z))$

其中$q_\phi(z|x)$是编码器网络，$p_\theta(x|z)$是解码器网络，$p(z)$是先验分布，$D_{KL}$是KL散度。

1. **TabDDPM（Tabular Denoising Diffusion Probabilistic Model）**：表格数据扩散概率模型，通过定义一个从数据到噪声的马尔可夫链，再反向从噪声生成数据，其训练目标是：

$\mathcal{L} = \mathbb{E}*{x_0, \epsilon, t}[||\epsilon - \epsilon*\theta(x_t, t)||^2]$

其中$x_0$是原始数据，$x_t$是添加噪声后的数据，$\epsilon$是添加的噪声，$\epsilon_\theta$是噪声预测网络，$t$是扩散步骤。

除此之外，系统还可以采用专门针对缺失值填补设计的模型：

1. **GAIN（Generative Adversarial Imputation Network）**：生成对抗填补网络，通过对抗训练框架填补缺失值，其目标函数为：

$\min_G \max_D \mathbb{E}[\log D(X, M) + \log(1 - D(G(X, M), M))] + \lambda \mathbb{E}[||G(X, M) \odot (1-M) - X \odot (1-M)||^2]$

其中$X$是包含缺失值的数据，$M$是缺失值掩码，$G$是生成器，$D$是判别器，$\lambda$是平衡参数。

1. **VGAIN（Variational GAIN）**：变分生成对抗填补网络，结合VAE和GAN的优点，通过概率建模提高填补的稳定性和准确性。
2. **VF_GAIN（Vertical Federated GAIN）**：适用于联邦环境的变分生成对抗填补网络，在保护数据隐私的前提下，协作完成缺失值填补。

这些生成技术与VFPU-M预测方法形成互补，共同提高数据补全的质量。整个系统的工作流程可以概括为：

1. 基于相关性阈值$\tau$，划分B方特征为高相关性特征集$\Phi^B_{high}$和低相关性特征集$\Phi^B_{low}$。
2. 对于$\Phi^B_{high}$中的每个特征$\phi^B_q$，采用VFPU-M方法生成预测值。
3. 对于$\Phi^B_{low}$中的特征，在B方本地训练生成模型，并使用训练好的模型生成合成数据。
4. 将两部分生成的数据合并，形成完整的B方预测数据矩阵$X^{B_{predict}}$。

这种协同框架充分利用了不同方法的优势，显著提高了生成数据的质量和可靠性。从理论上讲，当特征间相关性较高时，基于统计关系的半监督学习方法能够提供更精确的预测；而当相关性较低时，生成模型通过学习数据的内在分布，能够产生更符合实际分布的合成数据。这种互补性使得FedPSG-PUM方法能够在各种相关性条件下均保持良好的性能。

通过上述技术的有机结合，FedPSG-PUM方法构建了一个全面的纵向联邦样本生成框架，能够在保护数据隐私的同时，高效解决纵向联邦学习中的特征缺失问题，为构建高质量的联合样本集提供了坚实的理论基础和技术支持。