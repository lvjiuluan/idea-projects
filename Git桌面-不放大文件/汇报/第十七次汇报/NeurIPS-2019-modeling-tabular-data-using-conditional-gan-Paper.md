# NeurIPS 2019 modeling tabular data using conditional gan

## 摘要

对表格数据中行的概率分布进行建模并生成逼真的合成数据是一项具有挑战性的任务。表格数据通常包含离散列和连续列的混合。连续列可能具有多个模式，而离散列有时会存在不均衡的情况，使得建模变得困难。现有的统计和深度神经网络模型无法很好地对这种类型的数据进行建模。  

我们设计了 CTGAN，它使用条件生成器来应对这些挑战。为了进行公平和彻底的比较，我们设计了一个基准测试，其中包含 7 个模拟数据集和 8 个真实数据集，并采用了多个贝叶斯网络作为基线模型。CTGAN 在大多数真实数据集上优于贝叶斯方法，而其他深度学习方法则无法达到这一效果。

## 5 基准测试合成数据生成算法

目前有多种深度学习方法用于表格数据建模。我们注意到，所有方法及其对应的论文都没有使用相同的数据集，也没有在类似的度量标准下进行评估。这种情况使得方法之间的比较变得困难，并且无法识别每种方法在处理表格数据时的优劣。因此，我们开发了一个全面的基准测试套件来解决这一问题。

### 5.1 基线模型和数据集

在我们的基准测试套件中，基线模型包括贝叶斯网络（CLBN [7]、PrivBN [28]），以及当前用于合成数据生成的深度学习方法（MedGAN [6]、VeeGAN [21]、TableGAN [18]）。我们将 TVAE 和 CTGAN 与这些基线模型进行比较。

我们的基准测试包含 7 个模拟数据集 和 8 个真实数据集。

#### 模拟数据
我们手工构建了一个数据 oracle  $S  $ 来表示一个已知的联合分布，然后从  $S  $ 中抽取 T_train 和 T_test。该 oracle 可能是高斯混合模型或贝叶斯网络。  我们遵循 [21] 中的方法生成 Grid 和 Ring 高斯混合 oracle，并在 Grid 的每个模式上添加随机偏移，形成 GridR。此外，我们选择了 4 个常见的贝叶斯网络——alarm、child、asia、insurance，并构建了相应的贝叶斯网络 oracle。

#### 真实数据
我们从 UCI 机器学习库 选择了 6 个常见的机器学习数据集，其中包含表格形式的特征和标签列：
- adult、census、covertype、intrusion 和 news。  

此外，我们还从 Kaggle 选择了 credit 数据集。  我们还对 28 × 28 的 MNIST [16] 数据集 进行了二值化，将每个样本转换为 784 维的特征向量，并加上一个标签列，以模拟高维二值数据，称为 MNIST28。  然后，我们将图像调整为 12 × 12，并使用相同的处理方法生成另一个数据集，称为 MNIST12。  

综上，我们的基准测试套件共包含 8 个真实数据集。

### 5.2 评估指标与框架

由于生成模型的评估并不是一个简单的过程，不同的指标可能会产生显著不同的结果 [24]，因此我们的基准测试套件在多个数据集上使用多种指标进行评估。  

对于模拟数据，我们可以使用已知的概率分布来评估生成的合成数据，采用 似然拟合度量（likelihood fitness metric）。  

对于真实数据，合成数据的评估涉及机器学习任务，因此我们通过 机器学习有效性（machine learning efficacy） 来评估合成数据的质量。  

图 3 说明了评估框架。

### 似然拟合度量（Likelihood fitness metric）
在模拟数据上，我们利用模拟数据的 oracle  $S  $ 计算 似然拟合度量。具体而言，我们计算  $T_{\text{syn}}  $ 在  $S  $ 上的似然，并定义为  $\mathcal{L}_{\text{syn}}  $。然而， $\mathcal{L}_{\text{syn}}  $ 可能会偏向于过拟合的模型。  

为了解决这个问题，我们引入了另一个度量  $\mathcal{L}_{\text{test}}  $。  

我们使用  $T_{\text{syn}}  $ 重新训练一个新的模拟数据 oracle  $S'  $，其中  $S'  $ 具有与  $S  $ 相同的结构，但参数不同：

- 如果  $S  $ 是高斯混合模型，我们保持相同数量的高斯成分，并重新训练每个成分的均值和协方差。  
- 如果  $S  $ 是贝叶斯网络，我们保持相同的图结构，但重新学习每条边上的条件分布。  
- 然后，我们计算  $T_{\text{test}}  $ 在  $S'  $ 上的似然，定义为  $\mathcal{L}_{\text{test}}  $。  

该度量能够检测 模式崩溃（mode collapse），但它引入了对  $S'  $ 结构的先验知识，而这种知识未必完全体现在  $T_{\text{syn}}  $ 中。

### 机器学习有效性（Machine learning efficacy）
对于真实数据，我们无法计算似然拟合度量，因此我们采用机器学习任务来评估合成数据的质量。具体步骤如下：
1. 训练阶段：使用合成数据  $T_{\text{syn}}  $ 作为训练数据来训练机器学习模型。  
2. 测试阶段：使用真实数据  $T_{\text{test}}  $ 作为测试数据来评估模型的性能。  

我们使用 准确率（accuracy） 和 F1 分数 评估分类任务的表现，使用  $R^2  $ 评估回归任务的表现。  
对于每个数据集，我们选择能在该数据上取得合理性能的分类器或回归器（具体模型和超参数在补充材料和基准框架中详细说明）。  

需要注意的是，我们的目标不是选择最优的分类或回归模型，而是计算多个预测模型的平均性能，以此作为  $G  $ 的评估指标。

![image-20250209110538832](D:\Typora\images\image-20250209110538832.png)

<center>图3：模拟数据（左）和真实数据（右）的评估框架。</center>

**表 2**：基准测试结果涵盖三组实验，分别是 **高斯混合模拟数据（GM Sim.）**、**贝叶斯网络模拟数据（BN Sim.）** 和 **真实数据（real data）**。  

- 对于 **GM Sim.** 和 **BN Sim.**，我们报告每个指标的平均值。  
- 对于 **真实数据**，我们分别报告：
  - **分类任务** 的 **平均 F1 分数**  
  - **回归任务** 的 **$ R^2 $ 分数**。

![image-20250209110828005](D:\Typora\images\image-20250209110828005.png)

### **5.3 基准测试结果**

我们使用基准测试框架评估了 **CLBN、PrivBN、MedGAN、VeeGAN、TableGAN、CTGAN 和 TVAE**。  
- 每个模型的 **批量大小（batch size）为 500**，训练 **300 个 epoch**。  
- 每个 epoch 包含 **$ N / \text{batch\_size} $** 步，其中 $ N $ 是训练集中的行数。  
- 除了 $ \mathcal{L}_{\text{syn}} $ 之外，我们假设在任何数据集和指标上，最佳性能都由 **$ T_{\text{train}} $** 取得，因此我们引入 **Identity 方法**，直接输出 $ T_{\text{train}} $。

我们在 **表 2** 中总结了基准测试结果，完整的结果表可以在补充材料中找到。  

#### **高斯混合模拟数据**
- **CLBN 和 PrivBN** 表现较差，因为 **贝叶斯网络在建模之前需要对连续数值数据进行离散化**。  
- **MedGAN、VeeGAN 和 TableGAN** 全部存在 **模式崩溃（mode collapse）** 问题。  
- 通过 **模式特定归一化（mode-specific normalization）**，我们的方法在这些 **二维连续数据集** 上表现良好。

#### **贝叶斯网络模拟数据**
- **CLBN 和 PrivBN** 具有天然优势。  
- **CTGAN** 的表现略优于 **MedGAN 和 TableGAN**。  
- **TableGAN** 在这些数据集上表现意外地较好，尽管它将 **离散列视为连续值**。  
  - 可能的原因是，在我们的模拟数据中，大多数变量的类别数 **少于 4**，因此这种转换 **不会造成严重问题**。

#### **真实数据**
- **TVAE 和 CTGAN** 优于 **CLBN 和 PrivBN**，而其他 GAN 模型无法达到贝叶斯网络的效果。  
- **在大规模真实数据集上，训练高质量的贝叶斯网络很困难**。  
  - 训练于 **CLBN 和 PrivBN 生成的合成数据** 的模型，比训练于真实数据的模型 **性能下降 36.1% 和 51.8%**。

#### **TVAE vs. CTGAN**
- **TVAE 在某些情况下优于 CTGAN**，但 **GAN 仍然具有一些优势**。  
- 这并不意味着 **应该始终使用 VAE 而非 GAN 来建模表格数据**。  
- **GAN 的生成器在整个训练过程中无法访问真实数据**，因此 **CTGAN 比 TVAE 更容易实现差分隐私（differential privacy）[14]**。
