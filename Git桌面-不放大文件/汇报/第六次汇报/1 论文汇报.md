# Federated Learning with Positive and Unlabeled Data

我们研究了在联邦环境下从正的和未标记的(PU)数据中学习的问题，由于资源和时间的限制，每个客户端只标记其数据集的一小部分。与传统PU学习中否定类由单个类组成的设置不同，在联合设置中客户端不能识别的否定样本可能来自客户端未知的多个类。因此，现有的PU学习方法很难应用于这种情况。为了解决这一问题，我们提出了一个新的框架，即具有正面和未标记数据的联邦学习(federal learning with Positive and Unlabeled data，FedPU)，通过利用其他客户端中的标记数据来最小化多个负面类的预期风险。我们从理论上分析了该算法的泛化能力。实验表明，与传统的监督和半监督联邦学习方法相比，该方法具有更好的性能。代码可在https://github.com/ littleSunlxy/FedPU-torch获得

![image-20240820230310706](D:\Typora\images\image-20240820230310706.png)

## 方法

在这一节中，我们研究了每个客户端在MPMN-普学习环境下的联合学习问题。

3.1.问题设置这里我们首先介绍联合学习中的符号，这里有K个不同的客户端和一个中央服务器。

给定数据空间S和参数W的假设空间，训练数据分布在K个不同的客户端上，并且从数据空间S生成，其被表示为{Sk} K k=1 ∈ S。将T表示为时间t ∈ {1，...T}，权重wt首先从中央服务器传送到每个客户端，然后分别使用每个客户端中的训练数据进行更新，并导出K个不同的权重:

![image-20240820230419160](D:\Typora\images\image-20240820230419160.png)

其中w k t+1，k ∈ {1，...K}是来自客户端K的更新权重，客户端更新阶段是用于更新梯度的传统训练方法。此后，更新的权重被传送回中央服务器以更新权重矩阵:

![image-20240820230439182](D:\Typora\images\image-20240820230439182.png)

其中n k是客户端k中训练样本的数量，n = PK k=1 n k是所有训练样本的数量。

在传统的联合学习设置中，每个客户端中的训练数据都是完全标记的。然而，由于每个客户端的时间和资源限制，在许多真实场景中，样本并不总是被完全标记。具体来说，客户端k中的训练数据Sk由正数据Pk和未标记数据Uk组成，可以表示为:

![image-20240820230509546](D:\Typora\images\image-20240820230509546.png)

给定类别集合为C = {1，...，C}其中C是类的总数，客户端k中的正数据的类的集合(即正类)被表示为CPk，而负类被表示为CNk，其中CPk S CNk = C。换句话说，每个客户端只能从数据集Sk中识别部分类。

此外，由于数据太多而无法完全标注，因此只能标注正类中的一部分数据。因此，不仅存在来自负类的未标记数据，还存在来自正类的未标记数据，即CUk = C = CPk S CNk。具体来说，我们有:

![image-20240820230529092](D:\Typora\images\image-20240820230529092.png)

注意，不同的客户端具有不同的正类集合，并且所有的正类应该覆盖数据集中的所有类，即S Pk CPk = C。

在这种情况下，传统的联邦学习算法不能直接应用。刘等(2003)提出的正无标记学习方法可以很好地解决这个问题。然而，传统的PU学习方法将负类视为单个类，这在联邦学习中是不合适的，因为一个客户端的负类可能由其他客户端的多个正类组成。因此，我们遇到了一个MPMN(多正多负)PU学习问题，现有的方法不能直接处理。

为了解决MPMN PU学习问题，我们提出了FedPU方法。为了简单起见，我们假设使用FedAvg作为联邦聚合方法。

这里，为了方便起见，我们首先在单个客户端(或者没有联邦设置)中呈现我们MPMN PU学习方案。

将训练样本表示为{(xi，易)} n i=1 ∈ S .在经典的多类分类中，给定类先验πi = p(y = i)，i=1，2，...c，分类器f(x；w)(简写为f(x))，其中w是分类器的参数，可以通过最小化期望误分类率R(f)来学习:

![image-20240820230742273](D:\Typora\images\image-20240820230742273.png)

其中PC i=1 πi = 1，Pi()表示在第I类样本中计算的概率。因此，Pi(f(x) 6= i)表示第I类的期望误分类率。

然而，在MPMN PU设置中，只有少数类别中的样本在每个客户的训练集中被标记。情商中的几类？5是未标记的，并且不能在每个客户中直接计算预期风险。因此，有必要使用未标记数据来分析负类中的预期风险。这里，我们首先引入RU (f)来表示未标记样本不属于每个负类的概率之和:

![image-20240820230844010](D:\Typora\images\image-20240820230844010.png)

其中PU()表示在未标记样本中计算的概率。由于未标记样本可能来自正类和负类，因此概率PU()可被分成P i∈CP Pi()和P j∈CN Pj()。最后，RU (f)可分为三项，其中第一项是正面数据未被分类到负面类集合的概率，第二项是负面数据未被分类到相应类别的概率负类，第三项是负数据没有被归类到其他负类的概率。请注意，第二项正是负类中的预期风险，等式。5可重新表述为

![image-20240820230950053](D:\Typora\images\image-20240820230950053.png)