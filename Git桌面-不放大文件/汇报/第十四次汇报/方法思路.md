## 1. 为什么要拆分为二分类子问题？

在多分类半监督场景下，如果我们想直接把 **PU Bagging** 的想法扩展到“多类别 + 未标记数据 (U)”的条件下，可能会面临一个核心问题：对于某个类别 $ C_i $ 来说，未标记数据里不仅有可能是真正的 $ C_i $ 类样本，也有可能是其他类别的样本。传统 PU Bagging 在二分类场景是将 **P**(正样本) 与 **U**(未标记) 中抽样得到的“负”样本进行训练；但是当类别数>2 时，“负”就不再是简单的一类，而是“非该类”的所有其他类别 + 未标记。

**One-vs-Rest (OvR)**（也叫 **One-vs-All**）是常见的多分类思路：  
- 对于第 $ i $ 个类别 $ C_i $，将它看作“正类”，其它所有类别的数据都看成“负类”。  
- 这样可以把多分类问题拆分为多个二分类问题，每个问题训练一个“判别 $ C_i $ 与非 $ C_i $”的模型。  
- 推广到 PU Bagging，则可针对每个类别分别做一个 **PU Bagging** 流程，然后最后综合判断。

---

## 2. 在多分类半监督场景中应用 PU Bagging 的思路

假设你有 $ K $ 个类别，标注数据包括：  
- $\mathcal{L} = \{(x, y)\}$，其中 $ y \in \{C_1, C_2, \ldots, C_K\} $  
- $\mathcal{U}$，未标记数据（不知道它们属于哪个类别）

我们可以针对每个类别 $ C_k $ 做如下处理：

1. **提取“正类”样本**：  
   - 把标注集中**属于**类别 $ C_k $ 的样本视为 **$ P_k $**。  
   - 这些正样本是相对可信的，与传统 PU 设置中正样本地位相同。

2. **构造“负类”+ 未标记数据**：  
   - 把标注集中**不属于** $ C_k $ 的样本（即其它 $ C_{j}, j \neq k $）视为“已知负样本”一部分，可记为 **$ N_k $**。  
   - 所有未标记样本 $\mathcal{U}$ 也参与进来，但其中只**可能**包含$ C_k $ 类样本，也可能是其他类。

3. **PU Bagging 思路**：  
   - 在针对 $ C_k $ 这个二分类问题时，传统 PU Bagging 的关键操作是：  
     - “正样本” = $ P_k $。  
     - “未标记样本” = $ \mathcal{U} \cup N_k $ 里的某些子集，**假设**其中大部分是负的。  
   - 多轮训练：每一轮抽取 $\mathcal{U} \cup N_k$ 的一个子集作为“假设负样本”，与 $ P_k $ 一起训练一个分类器。  
   - 多次循环后，对这些分类器进行集成 (投票或平均输出) 获得对“是否是 $ C_k $”的预测。

4. **得到多分类预测**：  
   - 当我们为每个类别 $ C_1, C_2, \ldots, C_K $ 都训练好一个二分类器后，就可以对任意样本 $ x $ 做“多类别打分”或“多类别概率预测”。  
   - 常见做法是：对样本 $ x $ 送入每个二分类器，得到 $ K $ 个输出分数（或概率），再选择最高概率对应的类别；或者根据阈值做多标签预测（如果允许多标签）。

---

## 3. 具体实现/算法流程 (示例)

假设类别总数为 $ K $，我们对每个类别 $ k \in \{1,\dots,K\} $ 做如下操作：

1. **整理数据**  
   - $ P_k $ = 所有标注为 $ C_k $ 的样本；  
   - $ U_k $ = $\mathcal{U} \cup N_k$，其中 $ N_k $ 是所有标注为“非 $ C_k $”的已知负样本。

2. **Bagging 轮次**：设定 Bagging 迭代次数 $ M $。  
   - 对第 $ m $ 次迭代 ($m = 1, \dots, M$)：  
     - 从 $ U_k $ 中随机抽取若干子集 $ U_k^{(m)} $，把它当成“负样本”（注意可能混有正样本，这是 PU 学习的常见假设）。  
     - 训练第 $ m $ 个分类器 $ f_k^{(m)} $ 使之区分 $ P_k $ (正) 和 $ U_k^{(m)} $ (负)。  

3. **集成 (Ensemble)**  
   - 得到 $ M $ 个模型：$ \{f_k^{(1)}, f_k^{(2)}, \dots, f_k^{(M)}\} $。  
   - 可以通过投票或对输出概率/打分做平均，得到一个集成模型：
     $$
     F_k(x) = \frac{1}{M} \sum_{m=1}^{M} f_k^{(m)}(x).
     $$
   - 这样就可以对新样本 $ x $ 输出它属于 $ C_k $ 的估计概率 $ F_k(x) $。

4. **多类别综合**  
   - 上面步骤对每个类别 $ k $ 都会得到一个 $ F_k $。  
   - 最终预测时，可用：
     $$
     \hat{y}(x) = \underset{k}{\mathrm{argmax}}\, F_k(x).
     $$
   - 或者，如果你想允许多标签（假设一个样本可能归属于多个类），可以在每个 $ F_k(x) $ 上设置不同的阈值来判断是否输出该标签。

---

## 4. 注意事项

1. **类别间数据分布差异**  
   - 有些类别样本可能非常少（稀有类别），或非常多（多数类），导致不同类别之间的分类难度差异较大。  
   - 在“负”样本构造时，可能需要保证抽样规模的平衡，或者加权处理。

2. **未标记数据不均衡**  
   - 如果在未标记数据 $\mathcal{U}$ 中，不同类别分布不平衡，PU Bagging 仍然会遇到**潜在正样本被当作负样本**的问题，但通过多轮抽样和集成，可以在一定程度上降低这种偏差。  
   - 若能事先对 $\mathcal{U}$ 做一些**特征筛选**或**聚类**，尝试“划分可能的正样本候选区域”，也许能减轻对正样本的错误标注。

3. **模型选型**  
   - 由于要训练 $ K $ 个分类器、每个又包含多轮 Bagging，训练开销可能比较大，需要评估计算资源。  
   - 如果你选用的基学习器是随机森林或 XGBoost 一类自带集成属性的模型，可能可以适当简化 Bagging 步骤或者做混合改进。

4. **阈值或后处理**  
   - 多类别输出时，每个 $ F_k(x) $ 通常会被标准化为概率（比如 logistic output）。需要在推断阶段根据概率分布合理设置决策策略，比如最高概率对应的类别、或多标签阈值策略等。

---

## 5. 扩展：结合其他半监督技巧

- **自训练 (Self-training)**：在多次集成后，如果对某些未标记样本有非常高的置信度可以判断其所属类别，则可以把它们“伪标注”加入训练集迭代更新。  
- **一致性正则化 (Consistency Regularization)**：如 MixMatch、FixMatch 等思路，都能在多分类半监督时发挥作用，和 PU Bagging 可以互相借鉴。  
- **伪标签 (Pseudo-labeling)**：若某些样本在大多数分类器的预测下都倾向于某一类别，可将其加上伪标签来强化该类别的分类器。

---

### 总结

在多分类半监督学习场景下，“**拆分为多个 One-vs-Rest 二分类问题 + PU Bagging**”的方案是相对容易上手的做法。通过多轮随机抽取未标记样本作为“负样本”，并对各轮分类器做集成，可以**降低**把潜在正样本当作负样本的风险。最终再将所有类别的二分类器组合起来，就能完成多分类的推断。

*希望这些思路能帮到你。如有更多需求，可以考虑结合其他半监督学习手段，比如自训练、一致性正则化等，让模型更好地利用未标记数据。*