下面给出一种**纯矩阵**形式的线性回归推导过程，包含了**可分离的偏置 $b$** 和 **权重向量 $\theta$**，并带有 **$L_2$ 正则化**（即岭回归，正则化系数记为 $\lambda$），且**不对偏置 $b$ 进行正则化**。

---

## 1. 问题设定

给定训练数据集
$$
\{(x_i,\,y_i)\}_{i=1}^m,
$$
其中每个 $x_i \in \mathbb{R}^d$，$y_i \in \mathbb{R}$。将所有特征行向量排成一个 $m \times d$ 的矩阵
$$
X = 
\begin{bmatrix}

- x_1^\top - \\
- x_2^\top - \\
\vdots \\
- x_m^\top -
\end{bmatrix},
\quad
\text{以及输出向量}
\quad
y =
\begin{bmatrix}
y_1 \\[6pt]
y_2 \\[2pt]
\vdots \\[2pt]
y_m
\end{bmatrix}.
$$
令 $\theta \in \mathbb{R}^d$ 表示模型的权重向量，$b \in \mathbb{R}$ 为偏置(截距)项。我们的模型是

$$
\hat{y} = X\theta \;+\; b \,\mathbf{1},
$$
其中 $\mathbf{1}$ 表示全是 1 的 $m$-维列向量，即 
$$
\mathbf{1} = 
\begin{bmatrix}
1 \\[2pt]
1 \\[2pt]
\vdots \\[2pt]
1
\end{bmatrix}_{m\times 1}
$$

我们希望最小化以下目标函数（包含了 $L_2$ 正则化，且**不**对偏置 $b$ 进行惩罚）：

$$
\begin{aligned}
J(\theta,b)
&= \frac{1}{2}\,\bigl\|\,y - (\,X\theta + b\,\mathbf{1}\,)\bigr\|^2 
 \;+\; \frac{\lambda}{2}\,\|\theta\|^2 \\
&= \frac{1}{2}\,\bigl(y - X\theta - b\,\mathbf{1}\bigr)^\top \bigl(y - X\theta - b\,\mathbf{1}\bigr)
 \;+\; \frac{\lambda}{2}\,\theta^\top \theta.
\end{aligned}
$$

> **说明**：有些教材会将偏置合并到参数里(通过在 $X$ 增加一列全 1)，然后对除了偏置对应的那一列之外的其余参数进行正则化。但这里我们显式分离出了 $b$，只对 $\theta$ 做 $L_2$ 惩罚。

---

## 2. 求解偏置 $b$

令目标函数记作
$$
J(\theta,b) \;=\; \frac{1}{2}\,\|\,y - X\theta - b\,\mathbf{1}\,\|^2 + \frac{\lambda}{2}\|\theta\|^2.
$$
分别对 $\theta$ 和 $b$ 求偏导，并令其为 0。  
先对 $b$ 求导：
$$
\frac{\partial J}{\partial b}
= \frac{\partial}{\partial b} 
\biggl[
\frac{1}{2}\,(y - X\theta - b\,\mathbf{1})^\top (y - X\theta - b\,\mathbf{1}) 
\biggr].
$$
忽略正则化项（因为它不含 $b$），有

$$
\begin{aligned}
\frac{\partial}{\partial b}
\bigl[
\tfrac12(y - X\theta - b\,\mathbf{1})^\top (y - X\theta - b\,\mathbf{1})
\bigr]
&= 
\frac{1}{2}\cdot 2\,\bigl(-(y - X\theta - b\,\mathbf{1})^\top \mathbf{1}\bigr) \\
&= -\,\bigl(y - X\theta - b\,\mathbf{1}\bigr)^\top \mathbf{1}.
\end{aligned}
$$
令其等于 0，可得
$$
-(y - X\theta - b\,\mathbf{1})^\top \mathbf{1} = 0 
\quad \Longrightarrow \quad
\mathbf{1}^\top \bigl(y - X\theta - b\,\mathbf{1}\bigr) = 0.
$$
于是
$$
\mathbf{1}^\top y \;-\; \mathbf{1}^\top X\,\theta \;-\; b\,\mathbf{1}^\top \mathbf{1} = 0.
$$
因为 $\mathbf{1}^\top \mathbf{1} = m$，故
$$
b 
= 
\frac{\mathbf{1}^\top y - \mathbf{1}^\top X\,\theta}{m}.
$$
这给出了偏置 $b$ 的闭式解，它依赖于 $\theta$。当 $\theta$ 确定以后，可立刻求得 $b$。

---

## 3. 求解权重 $\theta$

再来看对 $\theta$ 的偏导。目标函数可拆为两部分：  
- $\tfrac12\|y - X\theta - b\mathbf{1}\|^2$，  
- $\tfrac{\lambda}{2}\|\theta\|^2$。  

故
$$
\frac{\partial J}{\partial \theta}
= 
\frac{\partial}{\partial \theta}
\Bigl[
\tfrac12\|\,y - X\theta - b\,\mathbf{1}\,\|^2
\Bigr]
\;+\;
\frac{\partial}{\partial \theta}
\Bigl[
\tfrac{\lambda}{2}\|\theta\|^2
\Bigr].
$$
第一部分（平方误差项）对 $\theta$ 的导数为
$$
-\,(X^\top)\,\bigl(y - X\theta - b\,\mathbf{1}\bigr),
$$
第二部分（正则项）对 $\theta$ 的导数为
$$
\lambda\,\theta.
$$
令这二者之和为 0，则有  
$$
-\,X^\top\,\bigl(y - X\theta - b\,\mathbf{1}\bigr) \;+\; \lambda\,\theta = 0,
$$
即
$$
X^\top X\,\theta + b\,X^\top \mathbf{1} - X^\top y + \lambda\,\theta = 0.
$$
将上一步得到的 $b$ 代入，即
$$
b 
= 
\frac{\mathbf{1}^\top (\,y - X\theta)}{m}
\quad \Longrightarrow \quad
b\,X^\top \mathbf{1}
= 
X^\top \mathbf{1}\,\frac{\mathbf{1}^\top (\;y - X\theta)}{m}
= 
\frac{X^\top \mathbf{1}\,\mathbf{1}^\top y}{m}
\;-\;
\frac{X^\top \mathbf{1}\,\mathbf{1}^\top X\,\theta}{m}.
$$
因此
$$
X^\top X\,\theta 
\;+\; 
\lambda\,\theta
\;+\;
\underbrace{
\bigl(\tfrac{X^\top \mathbf{1}\,\mathbf{1}^\top y}{m}
- 
\tfrac{X^\top \mathbf{1}\,\mathbf{1}^\top X\,\theta}{m}
\bigr)
}_{b\,X^\top \mathbf{1}}
\;=\;
X^\top y.
$$
整理得
$$
\Bigl(X^\top X 
- 
\tfrac{X^\top \mathbf{1}\,\mathbf{1}^\top X}{m}
+ 
\lambda I
\Bigr)\,\theta
\;=\;
X^\top y 
- 
\tfrac{X^\top \mathbf{1}\,\mathbf{1}^\top y}{m}.
$$
只要矩阵
$$
\bigl(X^\top X - \tfrac{X^\top \mathbf{1}\,\mathbf{1}^\top X}{m} + \lambda I\bigr)
$$
是可逆的(通常在 $\lambda>0$ 并且 $X$ 的列不完全线性相关时可逆)，就能得到

$$
\theta
=
\Bigl(X^\top X 
- 
\tfrac{X^\top \mathbf{1}\,\mathbf{1}^\top X}{m}
+ 
\lambda I\Bigr)^{\!-1}
\Bigl(
\,X^\top y 
- 
\tfrac{X^\top \mathbf{1}\,\mathbf{1}^\top y}{m}
\Bigr).
$$

最后再回头带入 $\theta$ 求 $b$：
$$
b = \frac{\mathbf{1}^\top \bigl(y - X\theta\bigr)}{m}.
$$

---

## 4. 将偏置合并到增广矩阵 (可选思路)

在许多教材或工程实现里，会把偏置 $b$ 合并到参数中去，方法是给 $X$ 额外添加一列全 1，记作

$$
\widetilde{X} = 
\begin{bmatrix}
X & \mathbf{1}
\end{bmatrix}
\quad (\text{维度 }m\times(d+1)),
\qquad
\widetilde{\theta} 
= 
\begin{bmatrix}
\theta \\
b
\end{bmatrix}
\quad (\text{维度 }(d+1)\times 1).
$$
这样我们的模型就可写成 
$\;\hat{y} = \widetilde{X}\,\widetilde{\theta}\,$，  
并将正则化矩阵设为 
$\;R = \mathrm{diag}(\lambda,\,\lambda,\dots,\lambda,\,0)\;$  
(即对前 $d$ 个分量进行 $\lambda$ 惩罚，对最后一维对应偏置的分量不惩罚)。  
然后整体目标函数就是  
$$
J(\widetilde{\theta}) 
= 
\frac12\,\|\;y - \widetilde{X}\,\widetilde{\theta}\;\|^2
\;+\;
\frac12\,\widetilde{\theta}^\top R\,\widetilde{\theta}.
$$
求导后可得同样的结论：

$$
\widetilde{\theta}
=
\Bigl(\widetilde{X}^\top\,\widetilde{X} + R\Bigr)^{-1}
\,\widetilde{X}^\top\,y.
$$
拆分出 $\theta$ 和 $b$ 即可得到上文结果。

---

## 5. 小结

- **目标函数**：  
  $$
  J(\theta,b)
  = 
  \frac{1}{2}\,\|\,y - X\theta - b\,\mathbf{1}\,\|^2 + \frac{\lambda}{2}\,\|\theta\|^2.
  $$
  我们仅对 $\theta$ 做 $L_2$ 正则，不惩罚偏置 $b$。

- **最优偏置 $b$**：  
  $$
  b 
  = 
  \frac{\mathbf{1}^\top \bigl(y - X\theta\bigr)}{m}.
  $$

- **最优权重 $\theta$**：  
  $$
  \theta
  =
  \Bigl(X^\top X 
  - 
  \tfrac{X^\top \mathbf{1}\,\mathbf{1}^\top X}{m}
  + 
  \lambda I\Bigr)^{\!-1}
  \Bigl(
  \,X^\top y 
  - 
  \tfrac{X^\top \mathbf{1}\,\mathbf{1}^\top y}{m}
  \Bigr).
  $$

在实际实现时，更常见也更简洁的方式是使用增广矩阵 $\widetilde{X}$，并对增广后的参数 $\widetilde{\theta}$ 一次性求解，但要记得在正则化时排除掉偏置项所对应的参数维度。以上两种推导思路在本质上是等价的。