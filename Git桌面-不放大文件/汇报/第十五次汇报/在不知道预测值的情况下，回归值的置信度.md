如果在不知道真实值的情况下（例如，实际应用中只有预测值，没有真实值），我们无法直接通过误差来评估预测的“好坏”。但可以通过其他方法对预测值进行排名，以下是一些可能的启发式方法：

---

### 方法 1：基于预测值的分布（离群值检测）
在没有真实值的情况下，可以假设预测值的分布是合理的。如果某些预测值远离预测值的主要分布范围（例如，异常值或离群值），可以认为这些预测值的置信度较低，排名靠后。

#### 实现步骤：
1. 计算预测值的均值和标准差。
2. 计算每个预测值与均值的偏离程度（例如，Z 分数）。
3. 根据偏离程度对预测值进行排名。

#### 示例代码：
```python
import numpy as np

# 假设 predictions 是模型的预测值
# 示例：predictions = reg.predict(X_test)

# 1. 计算预测值的均值和标准差
mean_prediction = np.mean(predictions)
std_prediction = np.std(predictions)

# 2. 计算每个预测值的 Z 分数（标准化偏离程度）
z_scores = np.abs((predictions - mean_prediction) / std_prediction)

# 3. 对 Z 分数进行排序（Z 分数越小，预测值越接近均值，越“正常”）
sorted_indices = np.argsort(z_scores)  # 从小到大排序
sorted_predictions = predictions[sorted_indices]
sorted_z_scores = z_scores[sorted_indices]

# 4. 打印排名结果
print("排名前10的预测值（最接近均值的预测值）：")
for i in range(10):
    idx = sorted_indices[i]
    print(f"样本索引: {idx}, 预测值: {sorted_predictions[i]:.4f}, Z 分数: {sorted_z_scores[i]:.4f}")

print("\n排名后10的预测值（最远离均值的预测值）：")
for i in range(1, 11):
    idx = sorted_indices[-i]
    print(f"样本索引: {idx}, 预测值: {sorted_predictions[-i]:.4f}, Z 分数: {sorted_z_scores[-i]:.4f}")
```

#### 解释：
- Z 分数表示预测值与均值的偏离程度，偏离越小，预测值越“正常”。
- 偏离较大的预测值可能是异常值，置信度较低。

---

### 方法 2：基于模型的不确定性（如果模型支持）
某些模型（例如，贝叶斯模型、随机森林、梯度提升树等）可以输出预测的不确定性（如方差或置信区间）。如果模型支持，可以使用预测的不确定性来评估预测值的置信度。

#### 示例（以随机森林为例）：
```python
from sklearn.ensemble import RandomForestRegressor

# 假设你使用 RandomForestRegressor 训练了模型
reg = RandomForestRegressor(n_estimators=100, random_state=42)
reg.fit(X_train, y_train)

# 1. 获取每棵树的预测值
all_tree_predictions = np.array([tree.predict(X_test) for tree in reg.estimators_])

# 2. 计算每个样本预测值的方差（不确定性）
prediction_variances = np.var(all_tree_predictions, axis=0)

# 3. 根据方差对预测值进行排名（方差越小，置信度越高）
sorted_indices = np.argsort(prediction_variances)  # 从小到大排序
sorted_predictions = predictions[sorted_indices]
sorted_variances = prediction_variances[sorted_indices]

# 4. 打印排名结果
print("排名前10的预测值（置信度最高的预测值）：")
for i in range(10):
    idx = sorted_indices[i]
    print(f"样本索引: {idx}, 预测值: {sorted_predictions[i]:.4f}, 方差: {sorted_variances[i]:.4f}")

print("\n排名后10的预测值（置信度最低的预测值）：")
for i in range(1, 11):
    idx = sorted_indices[-i]
    print(f"样本索引: {idx}, 预测值: {sorted_predictions[-i]:.4f}, 方差: {sorted_variances[-i]:.4f}")
```

#### 解释：
- 方差表示模型对某个样本预测值的不确定性，方差越小，置信度越高。
- 排名前 10 的样本是置信度最高的预测值，最后 10 名是置信度最低的预测值。

---

### 方法 3：基于预测值的局部一致性
如果特征空间中相邻样本的预测值差异较大，可能说明模型在该区域的预测不稳定，置信度较低。可以通过计算预测值的局部一致性来排名。

#### 实现步骤：
1. 对每个样本，找到其在特征空间中的最近邻样本。
2. 计算该样本的预测值与最近邻样本预测值的差异。
3. 根据差异对样本进行排名。

#### 示例代码：
```python
from sklearn.neighbors import NearestNeighbors

# 1. 使用最近邻算法找到每个样本的最近邻
nbrs = NearestNeighbors(n_neighbors=2).fit(X_test)  # 找到每个样本的最近邻
distances, indices = nbrs.kneighbors(X_test)

# 2. 计算每个样本与其最近邻的预测值差异
neighbor_differences = np.abs(predictions - predictions[indices[:, 1]])

# 3. 根据差异对样本进行排名（差异越小，置信度越高）
sorted_indices = np.argsort(neighbor_differences)  # 从小到大排序
sorted_predictions = predictions[sorted_indices]
sorted_differences = neighbor_differences[sorted_indices]

# 4. 打印排名结果
print("排名前10的预测值（与最近邻预测值差异最小）：")
for i in range(10):
    idx = sorted_indices[i]
    print(f"样本索引: {idx}, 预测值: {sorted_predictions[i]:.4f}, 差异: {sorted_differences[i]:.4f}")

print("\n排名后10的预测值（与最近邻预测值差异最大）：")
for i in range(1, 11):
    idx = sorted_indices[-i]
    print(f"样本索引: {idx}, 预测值: {sorted_predictions[-i]:.4f}, 差异: {sorted_differences[-i]:.4f}")
```

#### 解释：
- 如果某个样本的预测值与其最近邻样本的预测值差异较小，则认为该样本的预测值更可靠。
- 差异较大的样本可能位于特征空间的边界区域，模型在这些区域的预测不稳定。

---

### 总结

在不知道真实值的情况下，可以通过以下方法对预测值进行排名：
1. **基于预测值的分布**：计算预测值的偏离程度（如 Z 分数）。
2. **基于模型的不确定性**：利用模型输出的方差或置信区间。
3. **基于局部一致性**：计算预测值与最近邻样本预测值的差异。

具体选择哪种方法取决于你的模型和数据特点。如果模型支持不确定性估计（如随机森林或贝叶斯模型），建议优先使用方法 2。否则，可以尝试方法 1 或方法 3。