## 8.5 常见面试题

这次课是我们的最后一课，那么这次课我来给大家讲解一些常见的面试题，那么说是面试题，其实我不是真的给你讲题，我是给大家总结一下，那么面试的时候有哪几大块是面试官的比较常问的，那么我把这几块重要的知识点挑出来给大家就是过一遍，然后有些知识点是我们课程中已经讲过的，那么我就是一笔带过在这里，只是做一个提醒的作用，表示说这个东西重要，你课后的话做一个回顾，然后还有一些内容，课程上我们没有讲过，或者说没有详细的讲，那么我会做一些补充是这样的。

然后这些内容你都搞透了，面试的时候无论说他从哪个角度问他是出什么样的方式去考你，那么你明白这个原则基本上就都能够把这些内容给它回答清楚，这是我们这个课的一个目的。

然后我给大家整理的面试的常用的知识点有三个方面，一个是my circle其实问的是挺多的，第二个是reds问的就也非常的多。

最后是spring，我们整个的应用是构建在spring之上，当然了他问的也比较多，然后当然了我们这三块的内容合起来，他知识点是特别多的，我这里挑了一部分非常重要的非常高频的给你做一些总结，这里列举了这么多内容，是我一会要讲的内容，我就不一个一个来念了，我们就一个的去去过。

首先我们先来看一下 my circle，那么我们先来说一下 my circle的存储引擎，其实my circle它是一个基于存储引擎的数据库，它有很多个存储引擎可以供我们选择，然后我们选的是in rdb因为自从 my circle5.1开始，它默认的引擎就是inner DB，而从5.1之前是 isam那么为什么要切换成因特DB？因为它好在哪？它有一个比较典型的特点，突出的特点就是你看这个是它知识的内容， Transactions，事物 in the DB是支持事物的，而其他的引擎不支持事物，尤其不支持事物。

你想我们要不要用inner，DB自然是要用的，所以绝大部分的场景我们都会使用 inner DB引擎，所以我们才把它设置为默认的。

当然了还有一个引擎也是支持事物的 ndb但是ndb我们用的不多，因为 nd GB引擎它是在集群当中使用的一个引擎，其他的引擎是不支持集群的。

我们之前讲过部署，就是说我们 my circle我们通常能不做集群就不去做集群，因为如果你做集群以后，你还要考虑就是分布式的事物非常麻烦。

好了，当然了因特DB引擎还有一些其他的特点，比如说它是它支持外建，然后之前的就不支持。

再一个我这里提存储引擎的目的是因为我们一会儿要说事物，要说索引，其实我们都是要基于引擎来说的，因为不同的引擎它机制不一样，而我们又没有必要说把每一个引擎所有的机制都了解到，我们只要了解因特DB它是什么样的方式就可以了，因为我们用它好，总之存储引擎我们就做这么一个大概的了解就可以了。

然后接下来我们看这个事物，我记得我们第三章有一节我们专门讲了事物，包括我们回顾了事物的4个特性，再1个我们重点讲的事物的隔离性，如果说你没隔离好，他会有什么问题，对吧？然后我们在做隔离的时候有4种隔离级别，他们分别各自能解决哪些问题，我做了详细的阐述。

最后我们那节课上还讲了，这个spring他怎么管理事务，这些内容因为我之前的课当中已经讲得非常的详细了，所以说我在这次总结课里就不给大家重新讲一遍了，这里是给你提个醒，这个内容非常重要。

经常问尤其是隔离级别相关的内容，你一定要好好的复习，然后我们那次课也讲了说要实现隔离性怎么办？需要枷锁，而当时我在讲枷锁的时候，锁我们只是一笔带过，并没有讲得很详细，这次课我希望把这个锁给大家讲的是详细一点。

那么 my circle的锁我们从它锁的范围上来说，它主要有两个范围，一个是表及锁，就是锁整个表，那么这种锁它开销小，开销比较小，然后加锁的速度很快，但是它有一个缺点就是发生冲突概率高，然后并发的程度低，然后它不会出现死锁的现象。

然后还有一个是行级锁就是加在一行上，那么它的开销比较大，加锁速度比较慢，然后发生所的冲突的概率低，病发程度高，有可能会出现死锁。那么 isam的引擎它默认的是表级锁，它都不支持行级锁，所以说它的锁的力度是比较粗的，它的并发能力就一般，然后 inner DB它是支持行激素的，而且它默认就是行激素，所以它并发能力比较强。

好，然后我们就说一下 inner DB， inner DB它所的一些机制，那么对因特地比来说，它从类型上来划分，分为这么几个类型，一个是共享锁叫s锁，这是行级锁，然后就是在读取一行的时候可以加锁。

第二个是排他锁x锁也是行级的，当我们更新一行的时候需要加锁，也就是说当我更新这一行的时候，加上锁以后，你别人就不能读也不能更新了这样。

然后它还有一种锁叫意向锁，意向共享锁is这是表级锁，那么在我给一个数据加s锁之前，我需要先给这个表加意向共享所，他的意思是我准备加共享所，所以再加共享所之前先加，然后还有意向排他所。

Ix也是表机锁，它的意思是准备加排他锁，也就是说我在加排他锁之前需要先加上 x这个锁，好。

当然还有最后1个，一会我们再说了，那么这4个锁我画了1个图1个表格，我们来看一下，其中这一列表示的是事物a它的所的级别代表是事务二，那就是说我事务一加了一个，所以后事务二能不能加其他的锁，就是说我事务一加了锁以后，它和事务二的某些锁是冲突的这个意思。

那么如果事务一加了意向共享锁，比如说我想读取这个表里的某一行的数据，这个时候事物二它不能加排他所，因为你加排他所意味着你要写了我正在读，我要读你却正在写，那就冲突了，所以你不能不能写，但是你可以准备读，你可以读，你也可以准备写，这都可以。

所以这个不冲突，那么事物一如果是我加了意向排他锁，事物二你就不能加s和x所，因为我准备写，这个时候你就不要读了，你也不要写，但是你可以做准备，你可以准备读准备写。

好事物一如果是加的是共享所，比如说我正在我要读这一行，马上就读这一行，这个时候事务二就不能写，也不能准备写，但是你可以准备读或读，如果事务一加了排他锁事务二什么也不能做，就排他所和任何的行为都是互斥的。

所以通过这么一个例子对比，你就能理解这个锁加上以后别人能干什么不能干什么，就是这样你自己的客户再把这个表格好好的琢磨一下，对比着看一下。

然后除此以外，还有一个所叫间隙所叫nk那么这个所也是杭机所，它是发生在查询的时候，当我们使用范围条件查询时，比如说ID大于几小于几，我们一查是查多条数据对吧？使用范围条件时我们对范围内不存在的记录加速，比如说我想ID大于100，可能比如说我这个表里有101 102 103，然后没有了，那么会怎么样？

就是这个锁会加给那些不存在的技术，104 105他现在又给加上了，为什么要这样做？

它是为了防止换读，如果说你不加锁，你说我查ID大于100的值，然后我正在查的过程中，比如说有人插入了，他为了防止这样的一个换读，再一个它是为了满足恢复和复制的一个需要大家恢复的数据的时候，复制的数据的时候也需要用到这样的一个锁。

好了，这是因特DB它的集中锁的一个这个概念，然后我们再说一下我们怎么去加锁，那么首先我们在增加行级锁之前， index会自动给表加意向锁，所以意向所自动的，但这个是意向共享所，然后我们在执行。这个是意向，不是这个是意向，就意向所有可能是意向共享所也有可能是意向排他所，就统称为意向所。

然后我们在对某一条数据执行dml语句的时候，那么in the DB会给自动的给这个数据加排他锁，所以排他锁是自动加的，意向锁也是自动加的。

那么除了这些语句之外，还有查询语句，我们在执行查询语句的时候默认不加锁，那么如果你想加锁需要用特殊的语法，比如说我想给查到的数据加共享锁，s锁，那么我就需要在 Sql语句的后面加上log CM的，这样就加上了共享锁，然后如果我想加排他锁，我就在这个查询语句的后面加上for update，就加了排他锁。

然后间隙锁是针对查询而言的，那么上面的查询语句如果我们使用的是范围条件，那么英德DB就会对不存在的记录自动加间隙数是这么一个原则。好了，最后加锁的话，咱们一开始说引擎的时候也说了，就是说行解锁它有可能会出现死锁的现象，那么我们说一下什么情况下会出现死锁以后我们应该怎么办？

首先我说一下这个场景，比如说事务一他做了这样的事情，他更新一张表，t表条件的是ID等于1，先更新了ID等于一的这行记录，然后再更新ID等于二的记录，而事务二的操作与它相反，先更新ID二，再更新ID一，有可能有这样的情况就非常巧，失误先执行一半，更新了ide的数据。与此同时失误二更新了ID v二的数据，它俩是与此同时发生的，然后这个时候会怎么样？因为你这是一个dm二语句， Ide就被事物e加锁，idea就被事物二加速，这个时候往再往后事物一想，更新idea一看它被别人锁住了，他就等着，而事物二又想更新ID，一一看也被别人锁住，他就等着那他俩就互等。

如果说没有一个人让步的话，这就一直等下去就死循环了，这就是死锁的一个场景，那么这个解决方案其实也好办，就是说通常情况下因特尔DB它比较聪明，它能够自动检测到这种行为，而且它能够自动处理，它能够让一个事物回本，另一个事物继续所以通常它会自动解决。

再一个我们要注意就是说需要设置参数 in the DB lock，wait time out，设置一下等待时间，如果一个事物它在执行的过程中超过这个时间，我就自动让它回滚，因为有可能是死锁，也有可能是出现一些其他的问题，通过这个可以做一个兜底的这么一个方案，但是你要注意其实出现死锁很多时候是我们的逻辑写的有缺陷，你最好避免这样的逻辑，这完全是可以避免的。

我们更多的应该是避免写出这样的代码，怎么避免就是说我们在不同的业务访问并发访问多个表的时候，我们应该约定你最好以相同的顺序来访这些表，你不要换着来访问。首先表的顺序你要以相同的顺序来访问。

第二个当我们以批量的方式处理数据的时候，你应该先对数据排序，然后保证各个线程按照一个固定的顺序来处理数据，就是保证顺序一样，你不要混乱的顺序就有可能容易思索。

然后第三个，那么我们在事故中如果要更新记录，你最好就直接申请足够级别的锁，也就是排他锁，你上来就申请排他所，而不是说你先申请个共享锁再转换成排他锁，这样的话也有助于避免死锁的现象。

好了，以上是关于死锁的一些说明，那么刚才我们说的是my circle它的锁的机制，那么买circle锁加的这种锁，我们通通的称其为悲观锁，当然不只是买这种数据库，加的锁都是悲观锁，就是他天生他认为这一定会出问题，我一定得先加锁，他是持一个悲观的态度。

那么如果说我们不用数据库的锁机制，我们自己实现也可以我们自己实现，我们可以实现，用乐观者的方式自定义乐观锁，那么乐观锁通常有两种实现机制，一个是利用版本号，这个麻烦在哪？

我们每一张表都得加一个word版本，你得改这个表，而且每个circle都得把 Word带上，他对于蛇口的表的侵入性比较强，但是它确实很有效，或者说它效率比较高，乐观所天生我认为这不会发生什么问题，但一旦发生问题我又能解决。

当然悲观所的话就是什么？如果你更新数据很频繁，你最好就悲观所如果你根据数据不频繁查询数据的情况多，你乐观锁效率就高，是这样的。

好，我们再看一下这个版本号的机制，就是说我给这个表加了版本号以后，那么我在更新数据的时候，我要把版本号加一，然后更新，这是必须的，每次更新版本号必须加一，然后 Where条件里不管之前条件带上什么，我都需要加，再加上版本号这个条件word等于word，原先参数问的是什么？

是我之前我在更新之前先查到这个数据，然后去改，改完之后再更新，我之前查到的 word，也就是说我刚才查到的word，比如是二，现在word把表里的word也等于2，这个条件匹配我就能更新成功。

如果我这个word刚才我查到的是二，但你现在的表里的数据变成了三，就意味着别人改过了，产生了并发的冲突，这个时候条件不匹配，更新失败，整个更新语句最后的反馈结果是个0，对吧？失败了那一失败我就知道这有冲突了，就能避免这个问题，很有效。

那么除了这个以外，还有一种常见的机制叫做cas算法，它是一组单词的缩写，叫compare and swap比较和替换，然后这种算法它是一种无锁的算法，就是我们利用一个无锁的方式来实现一个有所的感觉。

那么这个算法它底层涉及了三个操作数，三个数，一个是内存值v一个是旧的值a一个是新的值b然后算法的基本原则就是这样的，当你内存里的数据等于旧的值a的时候，我才采用原子原子方式，然后用b的值就是新的值去更新v就是说我内存里的值和旧的值相等的时候，我再去更新 a否则更新 v否则我就不更新了，是这个意思。

好，然后算法它通常采用的是自选的操作，所以叫自选锁。什么叫自选操作？就是说我a线程对这个数据加了锁，我b线程一看你加锁了，我怎么办？我不是阻塞的等待，而是循环着等我循环一次看，解没解锁没解锁，我再循环一次看解没解锁没解锁，它是不断的循环去等着你解锁，这种不断的循环等着你解锁，因为循环中间是几乎没有时间间隔的，它不是说我等10毫秒，它是连续没有时间间隔的，所以它效率很高，你那边解锁的我立刻就能感知到。

而反过来如果你阻塞，比如说我阻塞个两秒还是多少秒，可能是或者我每隔100毫秒看一下，可能中间的间隔比较大，效率就没有循环的方式那么快，是这样的。

但是 Cas算法的这种这种自选锁它也有明显的缺点，这缺点你要了解，第一个是 ABA的问题就是说如果我一个线程将 a的值改成了b然后我又改回了a那么对CIS会认为这a没有被改过。

它是这样的，就是说因为它是判断你值变没变，你这个值没变我才去更新的，但其实你变了，但又变回来了，他认为你没改过，他照样去更新，所以他可能会被误导，他可能会被欺骗，这是 ABA的问题。

然后第二个就是自旋操作，刚才说了它采用循环的方式来实现的，万一说某一个线程它对数据加的锁的时间比较长，处理时间非常长，这个时候我另外一个线程在那循环等它可能会循环好多次，这个循环没有间隔，会给CPU带来很大的压力很大的开销， CPU就受不了。

最后一个就是说 CS它这种算法只能保证一个共享变量的原子操作，如果有多个共享变量不好办。好，这是关于我们如何实现乐观所的一个介绍。那么关于 My circle，最后我们再说一下它的索引，这也是非常常见的一个问题。如果说事物是为了保证数据的一致性完整性，它是为了保证数据的安全的这么方面的一个话题，所以是为了提高查询的效率，所以这两方面就是面试官最关注的问题。

然后这里我们这里面我们也是说说 inner DB这个引擎， inner DB引擎索引用大家应该都会用都非常简单，然后的话当然你可以测一下，你要测索引的效率高与低的话，你需要数据多，比如说你要造个100 200万的数据，至少的效果可能会比较明显，然后你不加索引去用字段去搜，加索引再去搜，你去看一下它这个时间差别效果是比较明显的，我们课上就不去做这个事了，我只是跟你说一下索引背后的原理。

 Inner DB引擎它是采用 b加速的算法来实现的，索引我们主要说一下 b加数这种数据结构。那么我概括了几句话，首先说我们在存索引的时候，这个数据是分块存的，而每一块一叫一页数据，然后索引的所有的值，它是按照顺序存储的，是有序的，并且每一个叶子到根的距离是相同的，这会这个一会有图，咱们看看图会更直观一点。

那么非叶子节点存的是数据的边界，而叶子节点存的是指向数据行的指针，然后我们通过边界可以缩小数据的范围，从而避免全表扫描，加快查找的速度。说白了索引其实就跟我们读书那书的目录一样，我想读每一块我通过目录一找，很快就定位到它在哪一页，我上那一页去找，就这段内容这不就快对吧？就这样的。

然后其实跟类似然后我们看这个图，刚才说了索引是分块存的，这是一块一页，这是一块一页这是一页这是一页。

那么这些黄色的部分它是整棵树的末级，是叶子节点，所以它叫叶子叶，那么叶里存的是指向实际数据的指针，比如说我们是用户表，我是在邮政类目上加了索引，这个叶子节点会存的是一个指针指向整个某一个优质的那一行的数据的指针，而它的叶子节点的上层是对数据的一个key，或者说它是对数据的一个索引，然后叶子节点之间是有联系的，就是每一页数据它和另外一页数据之间是先后首尾相连的，首尾相连的，然后的话叶当中的这些数据是经过排序以后的数据了，那么它们连在一起相当于整张表的数据，在这里按照所有的字段它就做了一个自然的排序，整个表都在这一级做了一个排序，按照索引的字段，然后一上一层是对整个下一层的一个边界的一个索引，或者说是对下一层的边界的限制，比如说我一看我要查的数据是小于这个 t一的，这个地方它有一个指针指向了这一页，比如说我这个数据是在这一页当中的，我就上这一页里去去找去遍历这一页的数据找到我想要的值。

比如说我一看我的索引，我的数据也是位于这个范围之内，是位于k一和k二之间的，我这个数据就是相当于位于这一页。所以上一层的页里的数据，我们通过它是很快速的能够找到我的数据的，具体在哪一页，具体是哪一个，就是底层的页，然后找到这一页去编列这一页就可以了。

这样的话我就不用说我去遍历整个表里所有的数据，避免对整个表进行遍历，这样的话就通过这样的方式就很快找到这一块，提高了效率。然后你还要注意上面上层的节点，它不是一个它可能是多个，而且可能还有更高的层次，这个数的深度，这个是看表的数据量而言的。表的数据量少的话可能有2层3层，再多的话可能有4层甚至更多的层次，这都是有可能的。

好了，总之这就是 B加数它的一个数据的结构，大家把这个结构要做一个了解。

好了，那么my circle的这些方面的知识点我们就说完了，下面我们再说一下，首先 readiness我们重点要关注它的数据类型，当然了那数据类型我们在项目中大部分都用过，其实这个好说。

然后的话我们在大学的时候也学过这个数据类型，所以说基本上比较容易理解。那么你除了要知道，所以说 ready它支持哪些数据类型之外，你还要知道每一种类型它的长度是多少，它最多能存多少个数据，这是面试的时候他可能比较常问的一个话题。

这里我做了一个总结，我们首先把这个数据分为key和value，对吧？Key也说一下，这Kay就是字符串那么最大512整，然后只有这么多君西等等，那么使用字符串512兆，然后希list set都是能存多少数据？

是二的22的32次方减1这么多数据，那么它的单位是这么多个数据，这么多个兼职队，这么多个数据，这么多个无序数据，然后有序集合官方手册里没有写它到底最大的限制是多少，这里我也没有写。

没有不确定就是不确定。

然后 beta map他其实本质上它就是字符串，所以说它存的数据最大也是512兆，而害怕 log它是最大12k最坏的情况是12k那么总之 readies它支持的数据类型比较丰富，功能比较强大，那么你需要关注的是每一种类型它最多能存多少数据，我们在使用的时候要知道它的内存的使用情况以及它的一个极限，这样的话在某些情况下能够可能规避一些问题。

好，第二个我们来介绍一下 radius的过期策略就是说radius如果我们对key做了过期的设置了过期的时间的时候，那么他会把 key放到一个单独的字典里，然后在key过期时，它不会立刻把 key删掉，因为他如果每个k都看着过期，马上马上就删掉，效率低，然后它会通过两种策略来删除过期的k第一种策略叫做惰性删除，就是说你过期就过期，我还在那放着我不删。

当客户端访问在访问 key的时候，那么瑞丽总会检查一下 key过没过期，如果过期就删了，这样的。好，但是如果这样的情况下就会出现一个问题，有可能有一些key老也不会访问，他一直就不被删除这样的，key慢慢累积的多了，对内存是一个很大的消耗，对吧？肯定不能一直这样下去。

那么所以它还有第二种机制叫做定期扫描，那么它默认会每一秒执行10次过期扫描次数可以配在配置文件里，它有一个Hz的选项通过它来配，然后具体的扫描的策略是这样的，他每次扫描的时候从过期字典中选，随机选20个k然后把这20个k当中已经过期的k给它删了。

然后再判断一下你过去的k的比例超没超过25%，如果超过25%就认为他就认为什么？你字典里过期的比例已经很高了，我得赶紧再删一下，那就赶紧再执行，再重复执行步骤一再来一遍，这是它的过期的策略。

除此以外它还有一种淘汰策略，淘汰策略指的是什么呢？当readiness它实际占有的内存已经超出最大的限制的时候，我怎么把这个数据删掉一些，因为你超出限制了，哪怕没过期我也存不下别的数据了。

最大的限制我们可以通过max memory选项去设置，然后如下这么几种策略，我们可以通过 Max memory policy指定你要用哪一种策略。

好了，总之我们选择任何一种策略的目的都是为了让 riders它丢弃一些数据，或者说淘汰一些数据好，腾出新的空间我们继续玩下去，继续提供读写服务。他所提供的淘汰数据的策略有这么多，第一个这是默认的他对可能导致增大内存的命令，直接返回一个错误的消息。

比如说我要往 Reds里继续写数据，他认为你看我内存已经达到最大值了，你再写不下去了我就报错，大多数的写命令他都这样处理，但是得利的处罚，因为得利的是把数据删了，他允许好，这是默认的方式就是这样。

然后第二个是这个方式是指的是对于设置了过期时间的key，那么我会选择剩余寿命比较短的可以把它淘汰，因为剩余寿命比较短，就说明你快要过期了，我现在存不下了，你就提前退休，提前把你删掉了这样的，那么剩余寿命叫TT l所以说它策略的后缀 ttl然后是在设置过期时间的key当中，他会选择最少使用的key，将其淘汰。

那么最少使用的key它怎么选择最少使用k它用一个lru算法，我们一会再说，这个也非常合理，就是说我内存已经满了，然后你那些设置的过期时间的k当中，我不管你时间新和旧，只要你用的频率最少的 k说明你不怎么用，我就干脆把它淘汰也很合理。

然后还有一个这个是在设置了过期时间的k当中，我们随机选一些可以把它淘汰，不管你是时间新旧，也不管你用的多与少随机。

好，那么还有两个这个是其实这两个和这两个是类似的，只不过他选择的范围不一样all case所有的key是在所有的k当中选，最少使用的也是利用这个算法把它淘汰，而这个是在过期的k中选，这个是在所有的k中选，随机选一些把它淘汰，这个是在过期的k里选，所以是很像的。

好，整个这些策略当中，一个是涉及到 ttl选择剩余寿命这个好办，因为我们是给 k设置了过期时间，你直接看时间就知道剩余寿命对吧？这也没有什么需要特殊的算法。

我们如何确定一个t是否是最少使用还是最多使用，这里涉及到一个lru算法，这个算法你要知道官方手册上也有说明，这里我做了一个提炼，什么叫lru算法呢？

就是说这个算法我们是通过一个链表去统计，你是使用的多还是少的，我维护一个链表，然后我原来按照顺序存储访问过的key，那么当我访问一个数据的时候，那么我会把刚刚访问的key移到表头，比如说数据我访问过它就在链表里，它处于中间的位置，我刚才又访问它一遍，我就把 k从中间移到表头去，那么如果是我访问一个新数据，我就直接把它放到表头。

总而言之我通过这样的操作，就是新的key挪到表头，我就不断的往表头放，新的key挪新的key，最后表尾剩的一定就是最少访问的key，那么我淘汰的时候就从表尾去淘汰就可以了，所以是用一个链表去维护 k使用的新与旧。然后但是 release它不是直接采用原始的lru算法，它是自己做了一些变通，我们称之为近似lru算法。

这个逻辑是借鉴了lru效果也和你差不多，但是逻辑实际实现的方式就变了，它是这样实现的，但是每一个k给 k维护一个时间戳，我淘汰的时候随机选5个k然后我从中淘汰到最旧的 k因为时间戳我就知道谁最旧淘汰掉一个，如果内存还是超出限制，我再继续这样的操作，再随机一遍再淘汰。

有人说这样有什么好处，它的好处是这种方式。特别lru节约内存，因为lru你会把所有的key都存一下，反馈的key都存一下，它很占内存的，但我这种方式它比较节约内存，而效果却和 Lru非常的相似。右边这个图你看这个图就是ll算法的一个图绿的，比方说比较新的数据，深灰的就表示比较旧的数据，浅灰的已经被淘汰的数据，最终是这样一个效果。

然后其他的三个图是 Release不同的版本，用这个算法能达到的一个效果。我们就看这个3.0，这是比较新的一个效果，而且它是每次选5选10个数据，那么它的效果和这个图已经非常的接近了，已经非常的能够满足我们的需求了。所以说这就是瑞丽斯他采用了一个近似lru算法来实现的这么一个淘汰策略，然后其他两个版本我们就不说了。

好，那么因为rides我们是内在内存中存数据，我们是缓存数据，所以我们非常关注缓存它释放的及不及时，清理的及不及时，这是第一个。

第二个我们还关注什么？缓存失效的问题，如果说你缓存一下子失效了，那会造成一个很恶性的后果就是说我请求就直接抵达了数据库，存储层，对数数据库造成过大的压力，可能把数据库给压瘫痪了，数据库一瘫痪，我们整个应用就歇菜了。

好，那么我们在使用ready的时候，怎么说我们要避免三种与缓存相关的问题，我们来说一下。

第一个是缓存的穿透问题，什么叫缓存的穿透场景就是这样的，说有的人他故意使坏，黑客故意想黑你，他访问的时候你看我可以直接敲个路径访问这个网站，比如说我敲discus，然后斜线写一个帖子ID，如果我写这个帖子ID是-1的话，我根本这个数据就我故意查不存在的数据，你release里一定没有这个数据，这个时候我就请求直接就访问了数据库，我把这种请求搞得多一点，你对你数据库就造成很大的压力，有可能就把你搞死搞死机了，就这个意思，这里边画了一个图，就是客户端故意查，没有的数据-1，访问缓存的时候肯定查不到miss，然后的话又去访问存储层，其实也是miss存储层就会给你返回一个空的结果0的结果，我再来一次又返回零0，很频繁，数据库就被这样玩死了，怎么解决其实也很好办。

第一个办法缓存空对象，如果说我存储层没有命中数据miss了以后，我仍然把空值存到缓存里，你下次再访问的时候直接给你返回一个空值缓存给你返回，你别访问数据库了，就在这个地方我访问数据库的时候查不到我不要return吗？Return之前我先把这个数据空值也存到这个缓存里，当你下次再访问这个没有的数据，直接就给你返回空值，别走数据库就好了。

然后还有第二种办法是不能过滤器，这是release自带的一个过滤器，那么它可以将所有存在的key，我们需要把所有的key提前存到过滤器里，然后把过滤器部署在缓存层之前，在这儿在缓存之前加上过滤器里存了所有已知的key，那么它会起到一个拦截的作用，如果请求防缓存层先经过过滤器，然后过滤器判断一下你这个请求的key有没有，如果没有的话，直接就给你返回一个空值就完了，就连缓存都不让你访问了。

这样好这是缓存，穿透它的特点是我访问一个根本就不存在的数据，别管是缓存还是数据层，没有。

第二种情况是缓存击穿，场景是这样的，我有一份热点数据访问访问得非常的频繁，访问量还很大，然后那热点数据我们肯定会存到 reds里缓存里，对吧？

但是你要注意，如果说我们在失效的那一瞬间，因为我们不是设置了过期时间，它失效的那一刻，那么大量请求一看缓存里没有数据，他们一下就涌到了存储层上面去，如果这个请求特别多，上千上万，有可能就把数据库搞崩溃了。

那一份热点数据有可能非常量大，有可能出现这种情况，那么这种情况我们怎么办？主要两种办法，一个是加互斥锁，就是说你对数据访问的时候，对reds里数据访问的时候，我给你访问加速，当某一个线程访问这个数据的时候，它就加了锁，其他线程就只能等待你就等一会再访问，而这个线程访问过以后，你不是数据失效了吗？

我访问的时候没有数据，那就访问数据库，访问数据库得到数据以后缓存被更新对吧？或者说缓存被重建这个时候我访问完了，我把手释放了，其他线程它就可以从火车里取值了，就可以避免同时抵达数据库的这么一个问题。

然后第二种办法是永不过期，我不给这样热点数据设置过期时间，你就不会出现上述的问题，那么这是物理上的不过期。

其实还有一种层面，我们也可以给每个value设置一个给value，不是给key给value设计一个逻辑的时间，然后我们有一个线程去检查这个东西，一旦发现一个值逻辑上是过期了，我单独启动一个线程去重建缓存去把缓存更新掉，这也可以好。

这是缓存击穿。

然后第三个还有一种场景是缓缓存，雪崩可能是由于某种原因 rise缓存不能再提供服务了，这个时候请求就直接访问了数据库，有可能造成存储层的宕机，这种方式就是整个缓存层整个整体不可用，这叫缓存雪崩。

刚才说的缓存击穿是一个热点数据，是某一个数据，而这个是大批量的数据，这个范围不一样。那么这种情况下我们怎么解决问题？第一个你要避免同时过期，就是说缓存成不能提供服务的未必是ready是挂了，有可能是你有很多key在同一时刻失效了，对吧？这个时候访问这么多k的那些请求，直接就到达了数据访问层，所以我们应该避免同时过期。

就是说我们给 Key设置过期时间的时候，你不要10秒20秒30秒，这样很容易就凑到一块去，整数就过期了，你最好是我在10秒20秒一分钟2分钟之外，再给它加一个随机数，这样的话每个k的过去时间它肯定是不同的，错开了就好一点。

好，第二个我们在构建瑞丽斯缓存的时候，你应该构建高可用的reduce缓存，就是说你部署多个实例做集群，那么一个节点棒了，其他的节点还能用，避免说出现这种情况高可用。

然后第三个万一高可用也不行，你最好是构建多级缓存，你把本地缓存加上去，我们这样的话本地缓存加ready缓存，两级缓存对吧？多一层屏障，那么你就可以降低请求直达存储层的一个几率，这也是一种办法。

再有一个如果说本地缓存也不行对吧？Red is它也挂了，请求就是要去访问数据库，这个时候怎么办？我们也不能干，等着我们对数据库也要启用限流和降降级的措施。对存储层增加限流措施有对应的框架，你去利用它去限流。

然后当超出这个限制以后，其他的流量怎么办？我们就也不是不给他提供服务，我们给他提供降级的服务，降级你自己定义，但通常其实就是给他返回一个默认值，返回一个空值，或者是给他返回一个错误的信息，这样的话其实比如说一共有5000个请求来，我只能处理2000个，这2000个我还正常处理，那3000个我给你返回空值或者是返回的错误消息，但我整体服务还在运转着，我没有挂掉它总比挂掉强。

所以以上是我们缓存雪崩的一些方案。

当然了就是说我刚才所说的这些缓存的问题，这解决方案只是一个热门的方案，大家公认的比较有效的方案，其实也有可能有一些其他的方案，你也可以自己想一些方案，这都可以，那么这只是给你做一个就是参考或者是准备。

那么关于rise你还要了解一个内容，就是分布式锁这个话题，面试时问的是极多的，因为怎么说，我们通常的互联网的项目都是分布式不足，绕不开这个话题。

首先你要理解什么是分布式锁，这个场景是这样的，就是我们修改数据的时候，我们通常设备需要要把这个数据先读取到内存里，读到内存里干什么可能要做一个判断，你数据合不合适，你比如说我要买东西，我读这个数据，我看一下它的库存够不够，对吧？

这样的，那么我首先要把数据读到内存里，然后改了，存回去往往是这样的一个操作。

那么这个操作我们是单体应用，没什么问题，但分布式应用就有可能什么多个进程同时做这样的事情。因为你分布式应用server有多个，你有可能是多个server同时做这样的事情，同时改同一份数据，读同一份数据然后要改对吧？然后你但是你要知道我读和改这两个操作它不是原子操作，所以多个进程同时做这样的事情，就可能会产生不一致的现象，就会产生冲突。

分布式锁是为了解决这类问题，而分布式锁它的基本原理是什么？其实和我们Java中的同步锁原理是差不多的，我们回顾一下同步锁，同步锁其实就是说我们解决多个线程访问同一个数据的问题怎么办？

我就枷锁，所谓枷锁我在这多个线程都能访问到的一个地方，其实就是堆内存打一个标记说当前这个数据归属是谁哪个县城，你别人就别碰了，就这个意思。

好，这就是同步数的原理，而分布式数原理跟它一样，但分布式锁是进程是多个进程，你要加锁你要打标记，你需要把标记放到多个进程都能仿造的地方，那就不能放到这个内存里了。你放到servo一的内存里，servo二防不了servo一的内存对吧？怎么办？具体解决方案有三种方式，我们可以把数据存到数据库里来，实现分布式锁，我把锁存到数据库里，你多个server可以访问同一个数据库对吧？

就解决这个问题，放到他们都能够得到的地方，或者是我把这个锁放到rids里也可以，或者说我把这个锁放到组keep也行，三种主流的方案，那么通常使用rides实现的比较多，所以我们是把这个内容放到 Rise里来讲，或者也经常是我们问readiness的问题的时候，愿意问分布式说，其实分布式说不是瑞丽斯独有的一个能力，好，我们使用rise实现分布式锁的原则是什么呢？

有三个原则，第一个我们要考虑安全属性，锁必须是互斥的，在任意时刻只有一个客户端能持有锁，你不能两个人都有锁那不行。

第二个是考虑它的 a活性b活性a指的是你需要无死锁，就哪怕说你有锁的客户端崩溃了，或者网络被分裂了，其实就是断网了，那么这个锁仍然可以被获取到，不然的话你说我加了锁，然后我挂了，这个时候不就死锁了对吧？

好，活性币指的是它的容错的一个特性，就是说只要大部分的risk节点都活着，那么客户端就可以获取和释放锁，并不是说百%的，因为分布式的系统很有可能某一个节点挂掉，这是很正常的。所以说它只要大部分都活着就可以继续，这是它的三个原则。

好，再往下看，那么具体来说我们怎么去利用rise来实现分布式锁分两种场景，一种场景是我们单个reds实例，我们怎么实现？当然我们通常都是多个实例，但是你要理解这个单个实例，因为多个实例也是在一个基础上进一步实现的。

单个实例它实现分布式锁，首先它需要它加锁的时候，或者说它获取锁的时候使用这样一个命令set，然后 resource name其实就是key。

 My random value其实就是一个值，但这个值通常建议是随机的，你每一个server产生的随机值都不一样，后面 nx是not exist，不存在，它的意思是只有说在 k不存在时它才成功，如果k已存在，比方说别人用了 k别人已经加了锁，我就失败。

然后 px后面跟的是一个时间，只是说设置锁的自动过期时间，万一说你挂了，我们有一个自动过期时间的机制让能够解锁这个意思。

好，然后我们主动的解锁你加锁以后，当你执行完你的操作以后，你要把所释放好，让别人去积蓄对吧？一定要有释放所的一个行为，或者说把锁删掉的一个行为就删掉这个数据。

释放所 Reds官方建议是用卢瓦脚本去执行写这么一个脚本，我获取 k判断它和我之前的 k是不是相等，如果是相等，我就把它删了，就说白了如果是我的t我就把它删了，这个意思好。有人说为什么要用卢瓦去删呢？我们赛特的值我们完全可以通过release命令去删，那么主要是为了避免这样一个问题，它可以避免删除别的客户端，获取成功的锁，什么意思？

就是说如果我们用命令reds命令来删锁，可能会出现这样的情况，你看 AA服务a客户端，我对数据加了锁加锁以后它阻塞了，然后在它阻塞的过程当中锁超时了，自动被释放了，注意它是阻塞，它没有死掉，被自动释放了。

你所一释放以后是不是b这个客户端也可以就可以加锁了，他就加上了，加上以后这个时候a很AA从这个阻塞的状态恢复回来了，他恢复以后他下一步要干嘛，他要释放锁他就释放锁，然后但是他其实之前已经被自动释放了，他又执行了一遍释放锁的代码，结果把b的锁给释放了，所以说就有这样一种情况，就是我释放锁，我把别人的锁给释放了，那么用这个撸脚本不走 rise客户端，那么可以规避这样的问题，所以说利用这个办法会更好一点。

好了，那么如果是多个rise实例，怎么实现这个分布式锁，其实也是要利用刚才的命令，但是他是对命令又做了封装，又有了一些新的要求，那么这个要求称之为 read log算法，这是 reads的作者又发明了一个算法，那么这个算法它有现成的实现，不用我们自己去写，那么Java版本的实现叫ready，如果你要用的话就下载这个包，然后这个算法大概的原则或者步骤是5步，第一步我想获取当前的 UNIX时间，就是从1970年到现在的一个毫秒为单位，然后我依次尝试，因为是分布式多个rise实例，我依次尝试从n个实例使用相同的k和随机值，获取锁就串联锁，然后一定要注意你要设置一个响应超时时间，因为你有n个release实例，有可能哪一个不给你响应怎么办？

你要设置超时间，如果说我服务器没有在规定时间内得到响应，我怎么办？我赶紧尝试去访问另外一个ready的实例，我就不用傻等着。我们搜房ready获取锁的时候要挨个获取，要判断响应时间，如果超时我就下一个，这个是它的原则。

然后第三个就是客户端使用当前时间减去开始获取锁的时间，这就是开始获取锁的时间，我客户端其实就是server对于riders而言，server去访问它，server就是客户端使用当前时间减去开始获取锁的时间，那会得到一个获取所使用的时间，我获取所也是需要消耗一些时间的，然后当期仅当大多数的release节点都取到了所一，多半取到了所，并且使用的时间小于失效的时间，锁失效的时间，这锁我才算是取得成功了。

你看就分布式是非常麻烦，我要考虑的是多个节点，大部分成功的情况才算成功，你要这样去协调。当然了你得一多半节点都我都拿到了锁我才认，这是第一个前提。

第二个前提我拿到锁这个时间小于所失效的时间，如果我拿到锁以后这锁就失效了，那就白拿了对吧？所以两这两点都满足，我才能够认为枷锁是成功的。那么如果说我得到了锁，而key的这个时候我就可以用锁了， Key它真正有效的时间我们注意是等于什么？是等于它原本的你设置的有效时间减去你获取锁的时间，你要有一些损失的，而如果你获取锁失败怎么办？你就需要对所有的release实例解锁，因为你刚才获取锁其实就是枷锁，如果一旦失败了，你要把那些锁都解掉，对所有的ready的实力实行执行。

解锁的代码，你别管他加没加锁都要去进行解锁，因为你也不知道哪个成功哪个失败这样。

好了，那么刚才呢我们是解释的是 Rise相关的一些知识，总之其实数据库层面的面试问的是比较多的，数据库，一个官营数据库，my circle一个就是reds，这两个问的都比较多，然后我们整个项目的根基在于spring， spring也问的比较多，但是spring它内容比较多，重点是在于三个方面，一个是IOC因为所有的功能都构建在LC之上，第二个是aop那么AOC解决不了的问题，aop可以解决，而很多的功能又构建在aop之上。

第三个是spring mvc，因为我们外部项目关键就这儿。好，那么首先说IOC其实IOC我在第一章有一节专门讲了，其实讲的也比较详细了，这里我不再重新讲一遍，但是我做一个补充的是并的作用域。我当时讲的时候说讲b是有作用域的，我们默认是单立的，我们可以通过scope注解去改它，我可以改成 product type。

所以大家对于单利的作用域 product type，应该是明白，我们之前讲过默认是单立的，但是因为当时我们还没有学习外部开发，所以我就没有讲到外部应用当中这些作用域，其实还有别的跟针对外部应用的作用域，有request，级别的作用域，就是说我对于某一个病人而言，我每次请求都给他建一个新的实例，就是request，级别，塞神级别、作用域是针对某一个病，每个会话我给他建一个实例，global session是全局的session，给他建立一个实例，但其实现在不用了，这只有在普特赖特这样的应用中才有效，不用了。

然后还有 application表示整个应用为整个外部应用建一个实例。

这个大家了解一下，其实其他的这些个中医我们几乎不怎么用，几乎不用，我们往往用的最多的一般都是心口疼，一般都是默认，你看我们那么多功能，我们哪个去改了对吧？但是面试时他可能会了解的就会说到这个话题，但是你只知道这两个就有点有点少有点薄，所以说其他的你也了解一下就好了。

那么Sebring第二个重点是epopee， aop我之前在第三章好像是最后一节，也详细的讲过，所以这里也不再进行重复，但是我想告诉你的是什么？就是aop在使用上它很简单的，但是在理解上就比较麻烦，所以说你要吃透它的每一个术语，你要理解这些组件之间的关系，你要理解说你要理解它的原理。所以当时我画了这么一个图，大家把这个图各个环节之间的关系，各个术语把它吃透，你做一个回顾就好了。

最后是spring mvc，面试官很关注你说你到底能不能做外部项目，你做外部项目，你整个流程你能不能衔接起来？通过哪能看你对整个流程熟不熟，通过问 Super mvc的，刘成你是不是mvc的流程熟了，至于说你CTRL Diao servis service Diao deo那个是简单的，这就好办了。

好，这里我又画了一个图，把整个spring mvc它的核心组件做了一个串接，把它们的顺序串在一起来，让你从一个更彻底的一个角度去理解 surprise，分析它处理请求的过程。当然了，如果你在 spm分析底层的代码里打断点，也可以跟到这个顺序，我建议你去跟一下。

整个spring mvc的核心是despatcher serval eyot组件之前我们也说过，所以当客户端发出请求访问服务器的时候，访问这个super mvc的时候，由谁来处理这个请求由他来处理，然后它会调用这么一系列的组件来解决这个问题，顺序是我标的这个步骤。

首先第二步，那么他会先调用组件叫handle卖品映射，组件能够根据你的访问路径找到这个路径，处理这个路径的组件，就说白了找到 CTRL了，然后他会给你返回给 dispatch server的返回对象叫handler excuse。

这里边封装了能够解决这个请求的control。

除此以外，还封装了能够对请求实现拦截的拦截器，就这里包装的是拦截器加CTRL a给了despatcher servitor，然后 dispatcher serverlet就去从这里得到comptroller得到拦截器去掉。第五步他去调谁，他不是直接调CTRL了，他是调handler的adapter， CTRL是封装在这里的，他从嵌里得到这个adapter去掉，然后 adapter里边内部掉了controller这样的。

二 this picture在调组件之前是先调所有得到的拦截器的，play很多方法，依次调拦截器，列表的plan的方法，在此之前 handle can handle adapter里边掉了了以后CTRL了最终会返回一个mode and view，把 mode and view返回给dispatch。

那么再返回 modle之后，dispatcher会调一下poste，handle方法调拦截器的post handle方法，所以就在这儿 dispatch，把拦截器controller调完了，然后最终得到了model and view，结果这里面封装了模型数据，封装了视图，然后 dispatcher调组件will reserve，视图解析器，他把 model and will给他，让他去处理数据的显示，而view reserve会根据 view找到对应的模板引擎，模板给你把数据给模板，然后由模板引擎向客户端做渲染，做展现，整个流程就是这样。

而模板引擎在向客户端输出数据以后，dispatcher又会去调拦截器的after completion这个方法。这就是整个 Spring mvc的处理请求的过程，这里边什么时候调拦截器的代码，什么时候去调CTRL，什么时候去调，这个模板顺序就一目了然了，如果你跟一下的话，这个效果可能会更好一点。

好了，我们这次课就讲这么多方面的内容，然后我们整个课就到此告一段落就结束了。

然后我们课程虽然结束了，但是课后如果说大家在学习的时候，你有问题你继续在这个群里去问，或者你在这个我们课程后面不是有个讨论区吗？去问咱们再去进一步的去交流。然后在这个课程即将结束的时候怎么说，也预祝大家能够找到一个自己比较满意的理想的工作，也希望我们这个课能够帮助到你。好了，我们这个课到此就讲解完了，咱们跟大家说一声，再见，咱们后会有期，拜拜。