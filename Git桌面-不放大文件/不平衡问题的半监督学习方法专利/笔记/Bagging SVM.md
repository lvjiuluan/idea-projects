# A bagging SVM to learn from positive and unlabeled examples

## 摘要

我们考虑从一组正例和未标记示例中学习二元分类器的问题，无论是在归纳设置还是在转导设置中。这个问题通常被称为PU学习，它与标准的监督分类问题的不同之处在于训练集中缺乏负例。它对应于许多应用中的普遍情况，例如信息检索或基因排名，当我们确定了一组具有特定属性的感兴趣的数据，并希望在大量容易获得的未标记数据中自动检索具有相同属性的其他数据时。我们提出了一种基于自举聚合（bagging）技术的概念简单的PU学习新方法：该算法迭代地训练许多二元分类器来区分已知的正例和随机子样本中的未标记集，并对它们的预测进行平均。我们从理论上和实验上都表明，该方法可以匹配甚至超过PU学习的最先进方法的性能，特别是当正例数量有限且未标记示例中负例的比例较小时。与最先进的方法相比，所提出的方法也可以运行得更快，特别是当未标记示例集很大时。

## 引言

在许多应用中，例如信息检索或基因排名，我们会得到一组共享特定属性的有限数据，并希望找到具有相同属性的其他数据。例如，在信息检索中，有限集可以是用户查询或已知属于特定类别的文档集，目标是扫描大型文档数据库以识别与查询相关或属于同一类别的新文档。在基因排名中，查询是已知具有给定功能或与特定疾病相关的基因的有限列表，目标是识别具有相同属性的新基因（Aerts 等人，2006）。事实上，这种设置在许多应用中无处不在，其中识别感兴趣的数据很难或昂贵，例如，因为需要人为干预或需要昂贵的实验，而未标记的数据可以轻松收集。在这种情况下，有一个明确的机会借助机器学习技术减轻识别感兴趣数据的负担和成本。更正式地说，让我们为每个可能的数据分配一个二进制标签：对于感兴趣的数据为正（+1），对于其他数据为负（-1）。

未标记数据是我们不知道它们是否有趣的数据。设 $\mathcal{X}$ 为数据集，我们假设“查询”是带有正标签的有限数据集 $\mathcal{P} = \{x_1, \ldots, x_m\} \subset \mathcal{X}$，并进一步假设我们可以访问一个（可能很大）未标记数据集 $\mathcal{U} = \{x_{m+1}, \ldots, x_n\} \subset \mathcal{X}$。我们的目标是从 $\mathcal{P}$ 和 $\mathcal{U}$ 中学习一种方法，用以识别新的带有正标签的数据，这个问题通常被称为 PU 学习。更具体地说，我们区分了 PU 学习的两种形式：

- **归纳式 PU 学习（Inductive PU learning）**：目标是从 $ \mathcal{P} $ 和 $ \mathcal{U} $ 中学习一个函数 $ f : \mathcal{X} \to \mathbb{R} $，该函数能够为任意新数据 $ x \in \mathcal{X} $ 赋予一个分数或概率，使其可能是正例。新数据可能不在未标记数据集合 $ \mathcal{U} $ 的训练集中。这种情况通常出现在图像或文档分类系统中，其中网络的一部分被用作未标记集 $ \mathcal{U} $ 来训练系统，而系统必须能够扫描任何不属于训练集的新图像或文档。

- **直推式 PU 学习（Transductive PU learning）**：目标是从 $ \mathcal{P} $ 和 $ \mathcal{U} $ 中估计一个评分函数 $ s : \mathcal{U} \to \mathbb{R} $，即我们只关注在集合 $ \mathcal{U} $ 中找到正例数据。这种情况通常出现在疾病基因排名应用中，其中在人类基因全集已知的情况下，将已知疾病基因 $ \mathcal{P} $ 与其余基因 $ \mathcal{U} $ 进行划分。在这种情况下，我们只关心在 $ \mathcal{U} $ 中发现新的疾病基因。

近来，越来越多的研究工作集中在PU学习上。由于只有正例和未标记的例子可用，这阻止了使用需要训练集中有负例的监督分类方法。克服缺乏负例的一个初步方法是在训练过程中忽略未标记的例子，仅从正例中学习，例如，通过按与正例平均值的相似度递减顺序排列未标记的例子（Joachims, 1997），或使用更先进的学习方法，如1-class SVM（Schölkopf et al., 2001; Manevitz and Yousef, 2001; Vert and Vert, 2006; De Bie et al., 2007; Geurts, 2011）。

另外，从理论角度研究了归纳式 PU 学习问题（Denis 等，2005；Scott 和 Blanchard，2009），并产生了许多特定的算法。一些作者提出了两步算法，这些算法本质上是启发式的，首先尝试在未标记的集合中识别负例，然后从正例、未标记和可能的负例中估计分类器（Manevitz 和 Yousef，2001；Liu 等，2002、2003；Li 和 Liu，2003；Yu 等，2004）。另一种方法是，直接学习区分 P 和 U，可能在重新平衡两个类别的误分类成本以解决问题的不对称性之后，这种方法已被证明可以为归纳式 PU 学习带来最先进的结果。这种方法已经使用不同的加权方案进行研究，使用逻辑回归或 SVM 作为二元分类器（Liu 等，2003；Lee 和 Liu，2003；Elkan 和 Noto，2008）。归纳式 PU 学习还与新颖性检测有关，并已用于新颖性检测，当 P 被解释为“正常”数据而 U 包含任意比例 p 的负例或“新颖”例子时（Scott 和 Blanchard，2009），或者当 P 减少到单个查询时用于数据检索（Shah 等，2008）。

Transductive PU学习被认为比归纳PU学习更容易，因为我们提前知道要筛选正标签的数据。当训练期间已知正负例时，已经提出了许多半监督方法来解决transductive学习问题，包括transductive SVM（Joachims，1999）或许多基于图的方法，这些方法由Chapelle等人（2006）回顾。相比之下，针对特定的transductive PU学习问题，投入的努力相对较少，值得注意的例外是Liu等人（2002），他们将问题称为部分监督分类，并提出了一种迭代方法来解决它，以及Pelckmans和Suykens（2009）将问题表述为图上的组合优化问题。最后，Sriphaew等人（2009）最近提出了一种与我们类似但更复杂的bagging方法，该方法仅在特定应用上进行了测试。

上面回顾的几种 PU 学习方法将问题简化为二元分类问题，我们学习区分 P 和 U。这在理论上至少可以在渐近情况下得到证明，因为正例和未标记例的条件分布之比随着正例和负例之比的单调增加而增加（Elkan 和 Noto，2008；Scott 和 Blanchard，2009），并催生了一些最先进的方法，例如偏置 SVM（Liu 等人，2003）或加权逻辑回归（Lee 和 Liu，2003）。尽管这种简化表明几乎任何（加权）监督二元分类方法都可以用来解决 PU 学习问题，但我们在本文中提出，在非渐近设置中，由于未标记类的特殊结构，某些方法可能比其他方法更适合。特别是，我们研究了基于聚合在人为扰动训练集上训练的分类器的方法的相关性，这种方法的灵感来自于 bagging（Breiman，1996，2001）。这些方法已知可以提高不稳定分类器的性能，我们认为这种情况在 PU 学习中可能特别发生。实际上，除了学习算法面对有限大小训练集的通常不稳定性外，未标记数据的随机子样本中正例和负例的内容可能会强烈影响分类器，因为 $ \mathcal{U} $ 中的正例污染使问题更加困难。$ \mathcal{U} $ 的污染率的变化可能对训练的分类器产生重要影响，因为较高的污染率在实践中使问题更加困难（Scott 和 Blanchard，2009），这是 bagging 类分类器可能受益的情况。

根据这个想法，我们提出了一种用于归纳PU学习的通用且简单的方案，类似于监督二元分类的不对称bagging形式。我们称之为bagging SVM的方法，通过聚合训练好的分类器来区分 $\mathcal{P}$ 和从 $\mathcal{U}$ 中随机抽取的小子样本，其中随机样本的大小起着特定作用。该方法可以自然地适应于传导PU学习框架。我们在模拟和真实数据上展示了bagging SVM至少与现有的PU学习方法一样有效，并且在 $|\mathcal{P}| \ll |\mathcal{U}|$ 时通常更快。

# 方法

## 直推式 PU 学习（Transductive PU learning）

在PU学习设置中学习分类器的起点是观察到，从未标记样本中区分正样本是实现我们目标的一个良好代理，而我们的目标是区分正样本和负样本。尽管未标记集合中混杂着隐藏的正样本，但通常认为其分布包含一些应该被利用的信息。这也是半监督方法的基础。

实际上，假设正例和负例是由类别条件分布 $ \mathbb{P}_+ $ 和 $ \mathbb{P}_- $ 随机生成的，其密度分别为 $ h_+ $ 和 $ h_- $。如果我们将未标记样本建模为以概率 $ \gamma $ 从 $ \mathbb{P}_+ $ 中随机抽取，以及以概率 $ 1 - \gamma $ 从 $ \mathbb{P}_- $ 中随机抽取，那么未标记样本的分布具有以下密度：
$$
h_u = \gamma h_+ + (1 - \gamma) h_-
$$
注意到:
$$
\frac{h_u(x)}{h_+(x)} = \gamma + (1 - \gamma) \frac{h_-(x)}{h_+(x)}
$$
这表明，正例和未标记例子的条件分布之间的比率随着正例和负例的比率的增加而单调增加（Elkan和Noto，2008；Scott和Blanchard，2009）。因此，任何估计正例与未标记数据的条件概率的估计器理论上也应适用于区分正例和负例。例如，逻辑回归或某些形式的支持向量机（SVM）就是这种情况（Steinwart，2003；Bartlett和Tewari，2007）。在实践中，通过对假阴性错误进行更多的惩罚，而对假阳性错误进行较少的惩罚，训练分类器来区分P和U似乎是有用的，以考虑到已知正例是正的，而未标记的例子被认为包含隐藏的正例。使用软边距SVM，同时对假阴性错误赋予高权重，对假阳性错误赋予低权重，导致了刘等人（2003）描述的偏置SVM方法，而使用逻辑回归的同样策略导致了李和刘（2003）的加权逻辑回归方法。
