  类别不平衡的半监督学习任务的训练数据由 $n$ 个带标签样本 ${{\mathsf{\mathcal{D}}}_{l}}=\{({{x}_{1}},{{y}_{1}}),\cdots ,({{x}_{n}},{{y}_{n}})\}$ 和 $m$ 个不带标签的样本 ${{\mathsf{\mathcal{D}}}_{u}}=\{({{x}_{n+1}}),\cdots ,({{x}_{n+m}})\}$ 。通常情况下，$m\gg n,x\in \mathsf{\mathcal{X}}\in {{\mathbb{R}}^{D}},y\in \mathsf{\mathcal{Y}}=\{1,\cdots ,C\}$，其中 $D$ 是输入维度的数量，$C$ 是训练样本中输出类别的数量。分别用 ${{n}_{c}}$ 和 ${{m}_{c}}$ 表示 ${{\mathsf{\mathcal{D}}}_{l}}$ 和 ${{\mathsf{\mathcal{D}}}_{u}}$ 下类别  $C$ 中的数据点数量，即：$\sum\nolimits_{c=1}^{C}{{{n}_{c}}=n}$ 且 $\sum\nolimits_{c=1}^{C}{{{m}_{c}}=m}$。假设 $C$ 个类别按降序排列，即 ${{n}_{1}}\ge {{n}_{2}}\ge \cdots \ge {{n}_{c}}$ 且 ${{m}_{1}}\ge {{m}_{2}}\ge \cdots \ge {{m}_{c}}$。在 ${{\mathsf{\mathcal{D}}}_{l}}$ 和 ${{\mathsf{\mathcal{D}}}_{u}}$ 下类别不平衡的比率分别表示为 ${{\gamma }_{l}}=\frac{{{n}_{1}}}{{{n}_{c}}}$ 和 ${{\gamma }_{u}}=\frac{{{m}_{1}}}{{{m}_{c}}}$。在类别不平衡的情况下，${{\gamma }_{l}}\gg 1,{{\gamma }_{u}}\ge 1$。通常，假设 ${{\mathsf{\mathcal{D}}}_{l}}$ 和 ${{\mathsf{\mathcal{D}}}_{u}}$ 具有相同的分布，即 ${{\gamma }_{l}}={{\gamma }_{u}}$。但也存在一些情况，${{\mathsf{\mathcal{D}}}_{l}}$ 和 ${{\mathsf{\mathcal{D}}}_{u}}$ 具有不同的分布，即${{\gamma }_{l}}\ne {{\gamma }_{u}}$。类别不平衡的半监督学习算法的目标是从不平衡的训练数据中找到一个合适的学习模型 $f(x;\theta ):\{\mathsf{\mathcal{X}}:\Theta \}\to \mathsf{\mathcal{Y}}$，该模型由参数 $\theta \in \Theta$ 定义，以减少泛化风险。

  以二分类问题为例，则 $C=2$，假设正样本的集合为 $P$，负样本的集合为 $N$，未标记样本为 $U$，则 $n = |P| + |N|$。在类别不平衡的情况下，$|P|$ 和 $|N|$ 的大小关系存以下两种可能：

1. $|P| >> |N|$
2. $|P| << |N|$



