

\chapter{总结与展望}
\thispagestyle{others}
\pagestyle{others}
\xiaosi

\section{研究总结}
本文针对纵向联邦学习（Vertical Federated Learning, VFL）场景下的正样本与未标记数据（Positive and Unlabeled, PU）学习问题，提出了一种创新性的解决方案——纵向联邦PU学习框架（VFPU）。通过理论分析与实证研究，本研究在隐私保护、算法性能及应用价值等方面取得了重要突破，主要结论可归纳为以下方面。

首先，本文首次将PU学习范式引入纵向联邦学习场景，突破了传统PU学习对集中式数据访问的依赖。针对VFL场景中正样本与未标记数据分布在不同参与方的特点，提出了一种基于加密样本对齐的三阶段处理流程，包括数据预处理、安全对齐及协同训练，以在不暴露原始数据的前提下实现特征空间融合。通过引入盲RSA协议与Paillier同态加密技术，设计了一种多方参与的隐私保护机制，确保样本ID对齐过程中仅交换加密哈希值而非原始标识符。实验结果表明，该框架在Bank、Credit和Census数据集上的AUC值分别达到0.886、0.639和0.854，相较于传统集中式PU学习方法仅下降1.5\%至3.2\%，实现了隐私保护与模型性能的有效平衡。

其次，针对未标记数据中潜在正样本识别的难题，本文创新性地将Bagging集成学习与两步式伪标签生成方法相结合。通过设计动态采样权重调整机制，在每轮迭代中依据预测置信度自适应调整未标记样本的采样概率。具体而言，本文引入Mordelet-Vert的PU Bagging方法，通过50次自助采样构建基分类器集合，以有效缓解单一模型的偏差。此外，提出概率加权伪标签选择策略，对未标记样本的预测概率进行高斯核密度估计，从而优先选择高密度区域的样本作为可靠正样本。同时，采用滑动窗口机制动态调整采样率，使得在Bank数据集上的误标率从固定采样方案的12.7\%降低至8.3\%。实验表明，VFPU\_GBDT模型在多个数据集上的F-score分别达到0.26、0.47和0.92，相较于传统Two-step方法提升23.8\%至41.6\%，充分验证了该方法的有效性。

综上所述，本文提出的VFPU框架在联邦学习场景下实现了高效的PU学习，兼顾隐私保护、模型性能和计算效率，同时在多个领域展现出广泛的应用价值。通过深入的理论分析与实证研究，该框架不仅在算法层面优化了PU学习在VFL中的应用模式，也在隐私保护与计算效率方面取得了重要突破，为未来联邦PU学习的研究和实践提供了有力支撑。



\section{未来工作展望}
尽管本文在纵向联邦PU学习方面取得了显著进展，但作为新兴交叉领域，仍存在诸多亟待突破的科学问题与技术挑战。未来研究可从以下几个方向展开深入探索。

当前联邦PU学习在算法效率方面仍面临挑战，特别是处理超大规模样本时存在计算瓶颈。未来可通过设计基于参数服务器的异步训练机制，采用模型分片与流水线并行技术提升效率，例如将GBDT的树结构划分为子树分配到不同计算节点，预期可显著提升训练速度。同时，梯度量化与稀疏化传输方案结合低秩矩阵分解技术也亟待研发，实验表明适当的量化可大幅减少通信量，而模型精度损失可控制在可接受范围内。此外，开发在线联邦PU学习算法，通过重要性采样和动态权重调整能够实现模型持续更新，在高速数据流场景下保持低延迟模型更新。

现有方法普遍假设各参与方数据服从独立同分布，这与实际应用场景存在明显偏差。针对非独立同分布(Non-IID)场景，我们需要设计基于域适应的特征对齐网络，通过最大均值差异(MMD)最小化实现跨域分布匹配。研究显示，在特征偏移度较高时，目标域准确率可获得显著提升。标签分布不平衡是另一关键挑战，联邦自适应重采样技术可根据各方标签分布动态调整采样权重，使得在正样本比例差异较大的极端情况下，仍能保持较为稳定的评价指标。资源异构环境下，研发跨异构设备(如GPU-FPGA混合集群)的联合优化框架也势在必行，通过计算图动态分区可实现资源最优配置。

联邦PU学习的理论基础仍需进一步深化。建立考虑隐私噪声和非IID数据的泛化误差上界尤为重要，我们需要推导形式化表达式以量化各因素对模型性能的影响。异步联邦优化的收敛性研究同样关键，理论分析显示在合理延迟范围内，可保持良好的收敛速度。多方博弈均衡分析有助于构建激励相容模型，通过shapley值计算贡献度并设计合理收益分配机制，可有效促进参与方的可持续协作。

本文开辟了联邦学习与半监督学习交叉融合的新方向，后续研究需在理论深度、技术广度和应用生态三个维度持续突破。通过学术界与产业界的协同创新，最终构建安全、高效、可信的联邦PU学习体系，为数据要素市场化配置提供关键技术支撑。
