### 问题设置

考虑一个两方纵向联邦学习（Vertical Federated Learning, VFL）的场景，这是参考文献[40]中定义的典型 VFL 设置。参与方包括 Party A 和 Party B，其中只有一方拥有标签。

首先，Party A 拥有数据集：

$$
\mathcal{D}^A := \{X^A_i\}_{i=1}^{n^A}
$$

其中，$X^A_i$ 是第 $i$ 个样本的特征向量，$n^A$ 是样本数量。Party A 的数据仅包含特征，不包含标签。

接着，Party B 拥有数据集：

$$
\mathcal{D}^B := \{(X^B_i, Y^B_i)\}_{i=1}^{n^B}
$$

其中，$X^B_i$ 是第 $i$ 个样本的特征向量，$Y^B_i \in \{0,1\}^C$ 是对应的独热编码（one-hot encoding）真实标签，$C$ 表示类别数，$n^B$ 是样本数量。Party B 拥有标签，这在 VFL 中至关重要，因为标签通常用于监督学习任务。然而，Party B 缺乏足够的特征来单独构建一个准确的模型，因此需要利用 Party A 提供的补充特征。

需要强调的是，$\mathcal{D}^A$ 和 $\mathcal{D}^B$ 分别由 Party A 和 Party B 私有保存，双方不能互相暴露其数据集。

在 VFL 中，Party A 和 Party B 的数据集 $\mathcal{D}^A$ 和 $\mathcal{D}^B$ 包含了不同样本的特征。为了进行联合学习，需要将具有相同身份的样本对齐。假设通过隐私保护的加密实体匹配技术[30]，双方已经完成了样本对齐，得到了对齐样本集：

$$
\mathcal{D}_{al} := \{X^A_{i_{al}}, X^B_{i_{al}}, Y^B_{i_{al}}\}_{i=1}^{n_{al}}
$$

其中，$n_{al}$ 是对齐样本的数量。Party A 拥有对齐样本的特征：

$$
\mathcal{D}^A_{al} := \{X^A_{i_{al}}\}_{i=1}^{n_{al}}
$$

Party B 拥有对齐样本的特征和标签：

$$
\mathcal{D}^B_{al} := \{X^B_{i_{al}}, Y^B_{i_{al}}\}_{i=1}^{n_{al}}
$$

如果将 $\mathcal{D}^A$ 和 $\mathcal{D}^B$ 连接起来，并使具有相同身份的样本对齐，我们将得到一个如图 1.b 所示的单一数据集。这个数据集是垂直分割的，每个方拥有该数据集的一个垂直分区（或部分视图），这正是“纵向联邦学习”一词的由来。然而，两方之间通常只存在有限数量的对齐样本。

除了对齐样本外，每个方还拥有一些非对齐样本，即没有来自另一方对应样本的数据。对于 Party A，非对齐样本表示为：

$$
\mathcal{D}^A_{nl} := \{X^A_{i_{nl}}\}_{i=1}^{n^A_{nl}}
$$

对于 Party B，非对齐样本表示为：

$$
\mathcal{D}^B_{nl} := \{X^B_{i_{nl}}, Y^B_{i_{nl}}\}_{i=1}^{n^B_{nl}}
$$

从单一表格数据集（见图 1.b）的角度来看，每个方对于另一方的非对齐样本都没有对应的特征（或标签）。我们将这些特征（或标签）视为“缺失”。

传统的 VFL 方法仅使用对齐样本 $\mathcal{D}_{al}$ 来构建联邦机器学习模型，而将非对齐样本 $\mathcal{D}^A_{nl}$ 和 $\mathcal{D}^B_{nl}$ 弃置不用。这种做法在对齐样本数量较少时，可能会限制模型的性能，因为大量潜在有用的数据被忽略。

为了提升 VFL 的性能，特别是在对齐样本有限的情况下，本文提出了VFPU-M-Syn方法，。该方法不仅利用对齐样本 $\mathcal{D}_{al}$，还充分利用非对齐样本 $\mathcal{D}^A_{nl}$ 和 $\mathcal{D}^B_{nl}$，旨在提高模型的准确性和泛化能力。





下面一段内容是计算，但没有完全基于前面的问题设置，我希望阅读理解后修正它，
1、帮我换一套符号表达，不要与问题设置冲突，符合问题设置中的符号设置
2、优化我的语言，使其符合学术论文的严谨、科学
3、希望把符号系统说明融入到段落中，成为一段一段的话
4、在不影响连贯性的前提下，在描述每个步骤时解释所用符号

### 计算跨方特征列相关性排序列表

计算 A 方第 $m $ 个属性列和 B 方第 $n $ 个属性列之间相关性系数  的 ${\rho _{X_m^A,X_n^B}}$ 具体过程如下：  协调方 C 充当密钥方，并将公钥密钥发送给 A 方和 B 方，用于整个多方关联规则生成方法。对于 A 方第 $m $ 个属性列 $X^A_m $：
$$
X^A_m = (x^A_{1m}, x^A_{2m}, ..., x^A_{d_{A} \cap d_{B} m})
$$

其中 $i = 1, ..., d_{A} \cap d_{B} $，循环遍历 $X^A_m $ 中的每个属性值 $x^A_{im} $，并对其赋排名。排名从 1 开始，排名相同的值使用平均排名（即将相同值的排名求平均）。得到每个属性值 $x^A_{im} $ 的排名 $Rank^A_{im} $，将 $Rank^A_{im} $  加密后发送给 B 放。对于 B 方 第 $n $ 个 属性列 $X^B_n $：

$$
X^B_n = (x^B_{1n}, ..., x^B_{d_{A} \cap d_{B} n})
$$

其中 $i = 1, ..., d_{A} \cap d_{B} $，循环遍历 $X^B_n $ 中的每个属性值 $x^B_{in} $，并对其赋排名（排名方式与 $X^A_m $ 相同）。得到每个属性值 $x^B_{in} $ 的排名 $Rank^B_{in} $。

加密 $Rank^B_{in} $。在 B 方计算加密后的 $Rank^A_{im} $ 与 $Rank^B_{in} $ 之间的差值 $[d_i]$：

$$
[d_i] = [Rank^A_{im}] - [Rank^B_{in}]
$$

根据差值 $[d_i]$ 进行皮尔逊复相关性系数计算，得到相关性系数 $\rho_{A, B}$。计算公式如下：

$$
\rho_{X^A_m, X^B_n} = 1 - \frac{6 \sum_{i=1}^{num} [d_i]^2}{num(num^2 - 1)}
$$

其中，$num $ 为对齐的样本数，即 $num = d_A \cap d_B $。

根据公式 (2) 求出 A 方和 B 方每个 属性之间的相关性系数，得到多方属性相关性矩阵 $M $：

$$
M =
\begin{bmatrix}
\rho_{X^A_1, X^B_1} & \rho_{X^A_1, X^B_2} & \cdots & \rho_{X^A_1, X^B_n} \\
\rho_{X^A_2, X^B_1} & \rho_{X^A_2, X^B_2} & \cdots & \rho_{X^A_2, X^B_n} \\
\vdots & \vdots & \ddots & \vdots \\
\rho_{X^A_m, X^B_1} & \rho_{X^A_m, X^B_2} & \cdots & \rho_{X^A_m, X^B_n}
\end{bmatrix}
$$

特别说明，如果多方协作学习过程中，不只 A、B 两方，可将对齐参与方的所有属性列与样本缺少参与方的所有属性列之间进行属性相关性矩阵计算。

在获得多方属性相关性矩阵 $M $ 后，需进一步量化B方各属性列与A方属性集的整体关联强度。本文采用列平均策略对矩阵进行降维处理，并按关联强度升序排列，具体步骤如下：

步骤1：列平均计算  

对矩阵 $M \in \mathbb{R}^{m \times n} $ 的每一列 $\boldsymbol{\rho}_{X^B_j} = [\rho_{X^A_1, X^B_j}, \rho_{X^A_2, X^B_j}, ..., \rho_{X^A_m, X^B_j}]^T $ 计算算数平均值：
$$
\mu_j = \frac{1}{m} \sum_{i=1}^{m} \rho_{X^A_i, X^B_j} \quad \forall j \in \{1,2,...,n\}
$$

式中，$\mu_j $ 表征B方第$j $个属性与A方所有属性的平均相关性强度。

步骤2：生成排序列表  

将列均值集合构建为有序列表 $\mathcal{L} $：
$$
\mathcal{L} = [\mu_1, \mu_2, ..., \mu_n]
$$

应用升序排序算法对 $\mathcal{L} $ 进行重排，得到有序序列：

$$
\mathcal{L}_{sorted} = \text{sort}(\mathcal{L}, \text{ascending}=True)
$$

