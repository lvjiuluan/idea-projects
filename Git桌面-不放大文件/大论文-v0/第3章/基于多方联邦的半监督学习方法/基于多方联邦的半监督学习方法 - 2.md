# 中文

在推荐系统中，有效利用多个参与方的数据，同时应对特定挑战至关重要。在某些场景下，会出现 UDD-PU 学习问题，即某一方（在本例中为 A 方）缺乏足够的未标记样本，导致无法使用传统的正例-未标记（PU）学习技术来有效训练推荐模型。这种未标记数据的不足会影响模型的泛化能力，导致性能下降和推荐结果不够准确。为了解决这一问题，本章提出了 VFPU 算法，这是一种结合了纵向联邦学习框架与 PU 学习技术的新方法。VFPU 旨在解决 A 方未标记样本不足的问题，通过更好地利用分布式数据资源，提升推荐模型的性能。

在本章中，基于 VFPU 的推荐过程主要包括三个核心步骤：数据预处理、加密样本对齐以及 VFPU 算法的执行。这些步骤共同构成了一个稳健的流程，以在隐私保护的协作环境中提升推荐的准确性。VFPU 的主要目标是在多个参与方持有的未标记数据集中识别可靠的正例样本。通过精准定位这些可靠的正例样本，模型能够更好地区分正例和负例，即使在缺乏明确标注的负例数据的情况下——这是 PU 学习场景中的常见挑战。

这一能力在推荐系统中尤为关键，因为用户偏好通常是通过交互隐式表达的，而非通过显式标签标注。因此，模型需要从有限或噪声较大的数据中推断用户偏好。通过识别这些可靠的正例样本，模型能够更深入地理解正例实例的特征，例如用户偏好或产品相关性，从而最终生成更准确、更个性化的产品推荐，以满足 A 方的需求。

对于 A 方而言，由于数据资源有限，其推荐模型的性能可能受到约束。然而，通过这一联邦学习方法，A 方可以利用 B 方和 C 方的丰富数据集，从而显著增强推荐模型的稳健性。同时，确保数据隐私的保护，并促进多个参与方之间的无缝协作，严格遵循联邦学习的核心原则。在整个过程中，数据隐私得到了精心维护，每个参与方的原始数据始终保持本地化，仅共享模型更新或聚合后的信息，而不会泄露敏感的个人记录。

这种隐私保护的协作方式在 \autoref{fig:VFPU} 中得到了可视化展示，该图详细说明了推荐过程的具体流程。本章的后续章节将对这一过程中的各个步骤进行深入探讨，以提供对该方法的全面理解。

### 样本对齐和数据预处理

为了有效地训练模型，VFPU框架包含了一个两部分的预处理阶段：数据预处理和加密样本对齐。这些过程确保了来自A、B和C方的数据集在不损害隐私的情况下进行协调和安全对齐。 

\begin{enumerate}[label=(\arabic)]

\item 数据预处理 

对A、B和C方持有的异构数据应用各种预处理技术，包括数据清洗、规范化和特征编码。数据清洗是第一步，它涉及解决常见的数据质量问题，例如通过插补或删除处理缺失值，消除重复项，并解决数据收集过程中可能出现的错误。这些努力确保数据集可靠，并且没有可能扭曲模型性能的噪声。规范化紧随其后，确保各方所有特征都达到可比的规模，这对许多机器学习算法的最佳运行至关重要。具体来说，数值特征使用标准化缩放进行规范化，这是一种将数据转换为零均值和单位方差的技术，从而防止范围较大的特征不成比例地影响模型。同时，分类特征通常表示定性属性，例如产品类别或用户人口统计信息，使用独热编码进行处理。此方法通过为每个类别创建二进制向量来将分类变量转换为数字格式，确保模型解释这些特征，而不假设从其他编码方案（如标签编码）可能产生的任何意外的序数关系。总之，这些预处理步骤创建了一个标准化、高质量的数据集，为后续处理做好准备。

\item 加密样本对齐

在数据预处理之后，三方参与一个安全的样本对齐过程，该过程分两个不同的步骤进行，以同步其数据集，同时保护隐私。这种对齐对于实现垂直联邦学习至关重要，在垂直联邦学习中，不同的方持有重叠样本集的互补特征。 

\begin{itemize}

\item 步骤 1: B方和C方对齐其样本 ID 空间，只保留两方都共享的样本，丢弃未对齐的样本。此步骤确保B方和C方在一个共同的样本集上操作，这是垂直联邦学习的先决条件，在垂直联邦学习中，各方为相同的实体贡献不同的特征集，例如用户或项目。通过关注其样本集的交集，建立了一个一致的基础，其中B方和C方的特征对应于相同的人或项目，允许模型有效地从组合特征空间中学习。因此，B方和C方现在共享相同的样本，但保持独特的、互补的特征，为协作训练奠定了基础。

\item 步骤 2: A方和C方对齐其样本 ID 空间，不删除任何样本，与步骤 1 相比采用了一种更具包容性的方法。对齐的样本定义为存在于A方和C方数据集中的样本，而未对齐的样本仅存在于C方。这种对齐过程利用了来自A方的可用标签信息来丰富C方的数据集。具体来说，出现在A方和C方中的样本在C方中被分配一个标签 1，表示它们是正样本，因为它们对应于A方数据中已知的正实例，例如与确认的产品交互的用户。相反，C方中缺少A方对应物的样本被分配一个标签 -1，将其标记为可能包含正负实例混合的未标记样本。这种标记策略将C方的数据集转换为适合 PU 学习的数据集，其中挑战在于区分未标记集中真正的正样本。通过不丢弃任何样本，此步骤最大限度地利用了可用于训练的数据，同时利用A方的正样本来指导该过程。

\end{itemize}

\end{enumerate}

在完成加密样本对齐后，C方获得了一个包含正样本和无标签样本的数据集。这种转换有效地将原始的UDD-PU推荐问题——其特点是A方缺乏无标签数据——转变为一个垂直联邦训练场景。在这个场景中，PU学习问题由B方和C方协作解决，其中B方提供额外的特征，C方提供有标签和无标签的样本。这种合作框架充分利用了所有方的优势，克服了A方在数据方面的限制，最终使其推荐系统受益。

为了在样本对齐过程中保护数据隐私，采用了基于盲RSA的私有集交集（PSI）协议 \textsuperscript{\cite{de2010practical}}。这种密码学技术使所有方能够安全地计算其数据集的交集，而不会暴露除共享样本ID之外的任何信息。具体来说，PSI确保B方和C方能够识别它们的共同样本，同时A方和C方能够确定它们的重叠样本，而不会泄露各自数据集的全部内容或关于未对齐样本的任何敏感细节。这种保护隐私的机制是联邦学习范式的核心，促进了各方之间的信任，并确保遵守数据保护标准。随着数据预处理和加密样本对齐的顺利完成，B方和C方的数据集现已完全准备就绪——经过对齐、标记和保护——可以用于执行VFPU算法。该算法及其训练过程的细节将在后续章节中详细阐述，基于此处奠定的基础。

# 英文

```
\subsection{Recommendation Based on VFPU}

In recommendation systems, effectively leveraging available data across multiple parties while addressing specific challenges is paramount. The UDD-PU learning problem arises in scenarios where one party, in this case, Party A, lacks a sufficient number of unlabeled samples to effectively train a recommendation model using traditional Positive Unlabeled (PU) learning techniques. This deficiency in unlabeled data can hinder the model's ability to generalize, leading to suboptimal performance and less accurate recommendations. To tackle this issue, we propose the VFPU algorithm, a novel approach that integrates a vertical federated learning framework with PU learning techniques. VFPU is specifically designed to address the problem of Party A's insufficient unlabeled samples, enhancing the recommendation model's performance by enabling better utilization of distributed data resources.
```

```
In this paper, the recommendation process based on VFPU is structured into three primary steps: data preprocessing, encrypted sample alignment, and the execution of the VFPU algorithm. These steps collectively form a robust pipeline to improve recommendation accuracy in a privacy-preserving, collaborative environment. The primary goal of VFPU is to identify reliable positive samples within the unlabeled dataset held across multiple parties. By pinpointing these reliable positive samples, the model gains the ability to better distinguish between positive and negative instances, even in the absence of explicitly labeled negative data—a common challenge in PU learning scenarios. This capability is particularly crucial in recommendation systems, where user preferences are often expressed implicitly through interactions rather than explicit labels, requiring the model to infer preferences from limited or noisy data. These identified samples allow the model to develop a deeper understanding of the attributes that characterize positive instances, such as user preferences or product relevance, ultimately resulting in more accurate and personalized product recommendations tailored to Party A's needs. For Party A, which may face constraints due to limited data resources, leveraging the richer datasets from Party B and Party C through this federated approach significantly enhances the robustness of the recommendation model. Simultaneously, we ensure data privacy and facilitate seamless collaboration among multiple parties, adhering to the core principles of federated learning. Throughout the process, data privacy is meticulously maintained by keeping each party’s raw data localized, sharing only model updates or aggregated insights rather than sensitive individual records. This privacy-preserving collaboration is visually depicted in \autoref{fig:VFPU}, which illustrates the recommendation process in detail. The intricate steps involved in this process will be thoroughly elaborated in the subsequent sections of this paper, providing a comprehensive understanding of the methodology.
```



#### Data Preprocessing and Encrypted Sample Alignment

```
To lay the groundwork for effective model training, the VFPU framework incorporates a two-part preparatory phase: data preprocessing and encrypted sample alignment. These processes ensure that the datasets across Parties A, B, and C are harmonized and securely aligned without compromising privacy.

\begin{enumerate}[label=(\arabic)]

\item Data Preprocessing

We apply a variety of preprocessing techniques to the heterogeneous data held by Parties A, B, and C, encompassing data cleaning, normalization, and feature encoding. Data cleaning is a critical initial step that involves addressing common data quality issues, such as handling missing values through imputation or removal, eliminating duplicate entries, and resolving inconsistencies that may arise from data collection processes. These efforts ensure that the datasets are reliable and free from noise that could skew model performance. Normalization follows, ensuring that all features across the parties are brought to a comparable scale, which is essential for the optimal functioning of many machine learning algorithms. Specifically, numerical features are normalized using standardized scaling, a technique that transforms the data to have a zero mean and unit variance, thereby preventing features with larger ranges from disproportionately influencing the model. Meanwhile, categorical features, which often represent qualitative attributes such as product categories or user demographics, are handled using one-hot encoding. This method transforms categorical variables into a numerical format by creating binary vectors for each category, ensuring that the model interprets these features without assuming any unintended ordinal relationships that could arise from alternative encoding schemes like label encoding. Together, these preprocessing steps create a standardized, high-quality dataset ready for subsequent processing.

\item Encrypted Sample Alignment

Following data preprocessing, the three parties engage in a secure sample alignment process, conducted in two distinct steps to synchronize their datasets while preserving privacy. This alignment is pivotal in enabling vertical federated learning, where different parties hold complementary features for overlapping sets of samples.

\begin{itemize}

\item Step 1: Party B and Party C align their sample ID spaces, retaining only the samples that both parties share and discarding those that remain unaligned. This step ensures that Party B and Party C operate on a common set of samples, a prerequisite for vertical federated learning where each party contributes different feature sets for the same entities—such as users or items. By focusing on the intersection of their sample sets, we establish a consistent foundation where the features from Party B and Party C correspond to identical individuals or items, allowing the model to effectively learn from the combined feature space. As a result, Party B and Party C now share the same samples but maintain distinct, complementary features, setting the stage for collaborative training.

\item Step 2: Party A and Party C align their sample ID spaces without removing any samples, adopting a more inclusive approach compared to Step 1. Aligned samples are defined as those present in both Party A’s and Party C’s datasets, while unaligned samples exist solely in Party C. This alignment process leverages the labeled information available from Party A to enrich Party C’s dataset. Specifically, samples that appear in both Party A and Party C are assigned a label of 1 in Party C, indicating they are positive samples, as they correspond to known positive instances in Party A’s data—such as users with confirmed product interactions. Conversely, samples in Party C that lack counterparts in Party A are assigned a label of -1, marking them as unlabeled samples that may contain a mix of positive and negative instances. This labeling strategy transforms Party C’s dataset into one suitable for PU learning, where the challenge lies in distinguishing true positives within the unlabeled set. By not discarding any samples, this step maximizes the data available for training while utilizing Party A’s positive samples to guide the process.

\end{itemize}

\end{enumerate}
```

```
Upon completing the encrypted sample alignment, Party C emerges with a dataset comprising both positive and unlabeled samples. This transformation effectively converts the original UDD-PU recommendation problem—characterized by Party A’s deficiency in unlabeled data—into a vertical federated training scenario. Within this scenario, the PU learning problem is addressed collaboratively between Party B and Party C, where Party B provides additional features and Party C supplies the labeled and unlabeled samples. This cooperative framework leverages the strengths of all parties to overcome Party A’s data limitations, ultimately benefiting its recommendation system.

To safeguard data privacy throughout the sample alignment process, we employ the Blind RSA-based Private Set Intersection (PSI) protocol \cite{de2010practical}. This cryptographic technique enables all parties to securely compute the intersection of their datasets without exposing any information beyond the shared sample IDs. Specifically, PSI ensures that Party B and Party C identify their common samples, and Party A and Party C determine their overlapping samples, without revealing the full contents of their individual datasets or any sensitive details about unaligned samples. This privacy-preserving mechanism is fundamental to the federated learning paradigm, fostering trust and compliance with data protection standards. With the successful completion of data preprocessing and encrypted sample alignment, the datasets across Parties B and C are now fully prepared—aligned, labeled, and secured—for the execution of the VFPU algorithm. The specifics of this algorithm and its training process will be detailed in the subsequent sections, building upon the foundation established here.
```

