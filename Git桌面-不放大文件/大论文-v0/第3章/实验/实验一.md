```
\subsubsection{RQ1: Performance comparison of PU Learning with and without federation}

To validate the impact of federation on PU Learning, we compared the performance of PU Learning with federation (using VFPU algorithm) and without federation (using non-federated counterparts). The key metrics included accuracy(acc), recall, precision, and the Area Under the Curve (AUC). These were evaluated across diverse base estimators and datasets, maintaining identical parameter settings with federation and without federation to ensure consistency.

For all datasets, LR, RF, GBDT, and LGB algorithms were applied as base estimators respectively. For the Logistic Regression (LR) algorithm as the base estimator, we used an L2 penalty coefficient of 0.8, a learning rate of 0.001, and a batch size of 64. For decision tree algorithms as the base estimator, we employed 50 trees with a maximum depth of 6 and a learning rate of 0.1.

The experimental results are presented in \autoref{RQ1}. The federated versions of these algorithms (Fed) showed lower accuracy, recall, precision, and AUC values compared to their non-federated counterparts (No\_Fed). This trend of the non-federated approach outperforming the federated approach persists across all base estimators and all three datasets.

However, it’s crucial to note that the performance gap between the two approaches is very narrow. For instance, in the Adult Census dataset, when using GBDT as the base estimator, the performance in terms of  acc, recall, precision and auc in the federation approach are  0.862, 0.188, 0.922, and 0.854 respectively, while the performance in the non-federation approach are 0.873, 0.205, 0.933 and 0.869 correspondingly. There shows a difference of 0.011, 0.017, 0.011, and 0.015 with respect to acc, recall, precision and auc, and the average difference is 0.0135, which is considerably small.  Futhermore, the overall average of difference over the four base estimators across all datasets and the four metics is 0.0174. Therefore, despite of the federation approach presenting a slight degradation of performance, the difference is insignificant.

In summary, the experimental results suggest that the VFPU algorithm, in spite of incorporating federated Learning, can achieve performance levels reasonably close to non-federated methods. This offers a valuable alternative for real-world applications with strict data privacy requirements.
	\begin{table*}
		\footnotesize
%	\setlength{\abovecaptionskip}{0pt}%    
%	\setlength{\belowcaptionskip}{10pt}%
	\centering
%	\captionsetup{singlelinecheck=false, justification=raggedright, margin=2.2cm}
	\caption{Performance comparison of PU Learning with and without federation}
	\label{RQ1}
	%		\begin{adjustbox}{width=\textwidth}
		\begin{tblr}{
				width=\textwidth,
				cell{1}{1} = {r=2}{},
				cell{1}{2} = {r=2}{},
				cell{1}{3} = {c=2}{},
				cell{1}{5} = {c=2}{},
				cell{1}{7} = {c=2}{},
				cell{3}{1} = {r=4}{},
				cell{7}{1} = {r=4}{},
				cell{11}{1} = {r=4}{},
				cell{15}{1} = {r=4}{},
				hline{1} = {1-2}{},
				hline{1} = {3-8}{Black},
				hline{2} = {3-8}{},
				hline{3,19} = {-}{Black},
			}
			Base Estimator & Metrics    & The Bank Marketing &         & {
				The Default of \\Credit Card Clients
			} &         & The Adult Census &         \\
			&            & Fed                & No\_Fed & Fed                                          & No\_Fed & Fed              & No\_Fed \\
			LR             & acc~↑      & 0.923              & 0.948   & 0.822                                        & 0.843   & 0.814            & 0.852   \\
			& recall↑    & 0.194              & 0.219   & 0.179                                        & 0.206   & 0.126            & 0.141   \\
			& precision↑ & 0.520              & 0.546   & 0.502                                        & 0.513   & 0.804            & 0.820   \\
			& AUC↑       & 0.658              & 0.685   & 0.621                                        & 0.643   & 0.854            & 0.858   \\
			RF             & acc~↑      & 0.935              & 0.952   & 0.826                                        & 0.851   & 0.848            & 0.852   \\
			& recall↑    & 0.219              & 0.248   & 0.190                                        & 0.212   & 0.154            & 0.165   \\
			& precision↑ & 0.587              & 0.613   & 0.546                                        & 0.562   & 0.755            & 0.770   \\
			& AUC↑       & 0.882              & 0.909   & 0.625                                        & 0.639   & 0.805            & 0.854   \\
			GBDT           & acc~↑      & 0.943              & 0.945   & 0.847                                        & 0.851   & 0.862            & 0.873   \\
			& recall↑    & 0.239              & 0.241   & 0.224                                        & 0.229   & 0.188            & 0.205   \\
			& precision↑ & 0.594              & 0.599   & 0.581                                        & 0.586   & 0.922            & 0.933   \\
			& AUC↑       & 0.886              & 0.891   & 0.639                                        & 0.647   & 0.854            & 0.869   \\
			LGB            & acc~↑      & 0.896              & 0.914   & 0.815                                        & 0.843   & 0.828            & 0.852   \\
			& recall↑    & 0.186              & 0.197   & 0.167                                        & 0.182   & 0.142            & 0.155   \\
			& precision↑ & 0.518              & 0.542   & 0.496                                        & 0.524   & 0.354            & 0.373   \\
			& AUC↑       & 0.587              & 0.612   & 0.569                                        & 0.582   & 0.705            & 0.721   
		\end{tblr}
		%	\end{adjustbox}
\end{table*}

这是我用latex撰写的论文，仔细阅读并理解，在不修改原本格式和含义的基础上，尽可能地丰富内容，扩充文字、因为我的学术论文对字数有严格要求。 用英文
```

# 扩写

```
\subsubsection{RQ1: Performance comparison of PU Learning with and without federation}

In this subsection, we thoroughly investigate how the incorporation of federated learning influences the performance of Positive and Unlabeled (PU) Learning. Specifically, we compare PU Learning with federation (using the VFPU algorithm) against its non-federated counterpart across multiple base estimators and datasets. The core objective is to evaluate if, and to what extent, federation affects classification quality when all other algorithmic parameters and experimental configurations are held constant. 

We employ four commonly used base estimators—Logistic Regression (LR), Random Forest (RF), Gradient Boosting Decision Tree (GBDT), and LightGBM (LGB)—across three real-world datasets: The Bank Marketing dataset, The Default of Credit Card Clients dataset, and The Adult Census dataset. For Logistic Regression (LR), we use an L2 penalty coefficient of 0.8, a learning rate of 0.001, and a batch size of 64, ensuring that convergence behavior remains consistent in both federated and non-federated runs. For the decision tree–based algorithms (RF, GBDT, and LGB), we configure them with 50 trees, a maximum depth of 6, and a learning rate of 0.1. These settings are carefully chosen to balance model complexity, training time, and generalization capability.

Table~\ref{RQ1} presents the results of our extensive experiments, detailing four performance metrics—accuracy (acc), recall, precision, and AUC—for each algorithm–dataset pairing under both federated (Fed) and non-federated (No\_Fed) modes. Our findings consistently reveal that the federated variants (Fed) show slightly lower values for accuracy, recall, precision, and AUC compared to the non-federated versions (No\_Fed). Although this difference is observed across all base estimators and datasets, it is important to emphasize that it is minimal in practical terms.

A closer look at the numbers illuminates this subtle performance gap. For instance, in the Adult Census dataset, using GBDT as the base estimator, the federated approach achieves an accuracy of 0.862, a recall of 0.188, a precision of 0.922, and an AUC of 0.854. By contrast, the non-federated counterpart reports slightly higher values of 0.873, 0.205, 0.933, and 0.869 for accuracy, recall, precision, and AUC, respectively. The gaps are 0.011, 0.017, 0.011, and 0.015 when viewed in terms of accuracy, recall, precision, and AUC. Numerically, the average difference for these metrics is 0.0135, which remains very small and indicates minimal compromise in performance.

Moreover, when averaged over all datasets, four metrics, and four base estimators, the difference stands at 0.0174—further demonstrating that while a performance reduction is consistently observed, the magnitude of this reduction is modest. These observations underscore the potential viability of the VFPU algorithm in real-world applications, where data privacy and security concerns may outweigh a small drop in predictive performance.

The experimental evidence thus indicates that integrating federated learning into PU Learning still preserves robust classification effectiveness. Even though the non-federated methods maintain a slight edge, the difference is not large enough to overshadow the privacy and data confidentiality benefits that federation provides. Therefore, for practitioners and researchers operating in sensitive domains—such as healthcare or finance—where data access is strictly regulated, VFPU represents a compelling option. The approach enables collaborative modeling across multiple parties without necessitating the sharing of raw data, thus striking an appealing balance between model accuracy and compliance with privacy requirements.

Overall, these experiments underscore that while a modest performance gap persists between federated and non-federated PU Learning, the VFPU algorithm still delivers robust results. This provides a practical and effective solution in domains where data privacy regulations are non-negotiable, confirming that slight reductions in accuracy, recall, precision, and AUC are a reasonable trade-off for enhanced data security and confidentiality.

给你一段latex撰写的英文论文，帮我翻译成中文，要求保持原始格式不变
```

```
\subsubsection{RQ1: 带联邦和不带联邦的PU学习的性能比较}

在本小节中，我们深入研究了联邦学习对正类和无标签（PU）学习性能的影响。具体来说，我们比较了使用VFPU算法的联邦PU学习与非联邦PU学习在多种基础估计器和数据集上的表现。核心目标是评估在其他算法参数和实验配置保持不变的情况下，联邦学习对分类质量的影响程度。

我们使用了四种常用的基础估计器——逻辑回归（LR）、随机森林（RF）、梯度提升决策树（GBDT）和LightGBM（LGB）——在三个真实世界的数据集上进行实验：银行营销数据集、信用卡客户违约数据集和成人普查数据集。对于逻辑回归（LR），我们使用了L2惩罚系数为0.8、学习率为0.001、批处理大小为64的配置，确保在联邦和非联邦运行中收敛行为保持一致。对于基于决策树的算法（RF、GBDT和LGB），我们将树的数量设置为50，最大深度为6，学习率为0.1。这些设置经过精心选择，以平衡模型复杂度、训练时间和泛化能力。

表~\ref{RQ1}展示了我们广泛实验的结果，详细列出了每种算法-数据集组合在联邦（Fed）和非联邦（No\_Fed）模式下的四种性能指标——准确率（acc）、召回率（recall）、精确率（precision）和AUC。我们的发现一致表明，联邦变体（Fed）在准确率、召回率、精确率和AUC方面略低于非联邦版本（No\_Fed）。尽管这种差异在所有基础估计器和数据集上都有观察到，但重要的是要强调，在实际应用中，这种差异非常小。

仔细观察数据可以揭示这种微妙的性能差距。例如，在成人普查数据集中，使用GBDT作为基础估计器，联邦方法达到了0.862的准确率、0.188的召回率、0.922的精确率和0.854的AUC。相比之下，非联邦方法报告了略高的0.873、0.205、0.933和0.869的准确率、召回率、精确率和AUC。差距分别为0.011、0.017、0.011和0.015。从数值上看，这些指标的平均差异为0.0135，仍然非常小，表明性能的妥协微不足道。

此外，在所有数据集、四种指标和四种基础估计器上平均，差异为0.0174——进一步证明虽然性能下降是持续观察到的，但这种下降的幅度是适度的。这些观察结果强调了VFPU算法在实际应用中的潜在可行性，在这些应用中，数据隐私和安全问题可能超过预测性能的微小下降。

实验证据因此表明，将联邦学习集成到PU学习中仍然保留了稳健的分类效果。尽管非联邦方法保持了轻微的优势，但这种差异不足以掩盖联邦学习提供的隐私和数据保密优势。因此，对于在敏感领域——如医疗保健或金融——操作的从业者和研究人员来说，VFPU代表了一个引人注目的选择，因为在这些领域，数据访问受到严格监管。该方法使多个参与方能够在不共享原始数据的情况下进行协作建模，从而在模型准确性和隐私要求合规性之间取得了吸引人的平衡。

总体而言，这些实验强调了虽然联邦和非联邦PU学习之间存在适度的性能差距，但VFPU算法仍然提供了稳健的结果。这为数据隐私法规不可妥协的领域提供了一个实用且有效的解决方案，确认了在准确率、召回率、精确率和AUC方面轻微的降低是增强数据安全和保密性的合理权衡。
```

```
\subsubsection{RQ1: 联邦学习与非联邦学习下的PU学习性能对比}

在本小节中，我们深入探讨了联邦学习的引入如何影响正样本和未标记样本（PU）学习的性能。具体而言，我们比较了使用联邦学习（VFPU算法）与非联邦学习的PU学习在多个基本估计器和数据集上的表现。核心目标是评估联邦学习是否，以及在多大程度上，影响分类质量，同时保持其他算法参数和实验配置的一致性。

我们采用了四种常用的基本估计器——逻辑回归（LR）、随机森林（RF）、梯度提升决策树（GBDT）和LightGBM（LGB）——在三个真实世界数据集上进行实验：银行营销数据集、信用卡违约数据集和成人普查数据集。在逻辑回归（LR）中，我们使用L2惩罚系数为0.8、学习率为0.001、批处理大小为64，确保联邦和非联邦运行中收敛行为的一致性。对于基于决策树的算法（RF、GBDT和LGB），我们将其配置为50棵树，最大深度为6，学习率为0.1。这些设置经过精心选择，以平衡模型复杂度、训练时间和泛化能力。

表~\ref{RQ1}展示了我们广泛实验的结果，详细列出了每个算法-数据集配对在联邦（Fed）和非联邦（No\_Fed）模式下的四个性能指标——准确率（acc）、召回率、精确率和AUC。我们的研究结果一致显示，联邦变种（Fed）在准确率、召回率、精确率和AUC方面的值略低于非联邦版本（No\_Fed）。尽管这种差异在所有基本估计器和数据集上都有观察到，但需要强调的是，在实际应用中这种差距是最小的。

更详细地观察这些数值，揭示了这一细微的性能差距。例如，在成人普查数据集上，使用GBDT作为基本估计器时，联邦方法的准确率为0.862，召回率为0.188，精确率为0.922，AUC为0.854。相比之下，非联邦方法的准确率、召回率、精确率和AUC分别为0.873、0.205、0.933和0.869，略高。按准确率、召回率、精确率和AUC来看，差距分别为0.011、0.017、0.011和0.015。从数值上来看，这些指标的平均差值为0.0135，表明这种性能差距非常小，几乎可以忽略不计。

此外，在所有数据集、四个指标和四个基本估计器的平均值下，差距为0.0174——进一步证明，尽管始终观察到性能下降，但这种下降的幅度非常适中。这些观察结果突出了VFPU算法在现实应用中的潜在可行性，在数据隐私和安全问题可能超过轻微的预测性能下降时，联邦学习的优势尤为突出。

实验结果表明，尽管引入联邦学习的PU学习在性能上略有差距，但仍能保持强健的分类效果。尽管非联邦方法略微占优，但这种差距并不足以掩盖联邦学习所带来的隐私保护和数据保密性优势。因此，对于那些在敏感领域（如医疗或金融）工作、且数据访问受到严格监管的从业者和研究人员来说，VFPU算法是一种极具吸引力的选择。该方法能够在多个方之间进行协作建模，而无需共享原始数据，从而在模型准确性和隐私合规性之间达到了一个理想的平衡。

总的来说，这些实验表明，尽管联邦和非联邦PU学习之间存在轻微的性能差距，但VFPU算法仍能提供强大的结果。这为那些数据隐私法规不可妥协的领域提供了一个切实有效的解决方案，证明了在数据安全性和保密性方面，准确率、召回率、精确率和AUC的轻微下降是可以接受的合理折衷。
```

