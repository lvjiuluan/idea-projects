# 第四章 基于半监督学习的纵向联邦参与方样本生成方法研究
## 1 问题设置

考虑一个两方纵向联邦学习（Vertical Federated Learning, VFL）的场景，这是参考文献[40]中定义的典型 VFL 设置。参与方包括 Party A 和 Party B，其中只有一方拥有标签。

首先，Party A 拥有数据集：

$$
\mathcal{D}^A := \{X^A_i\}_{i=1}^{n^A}
$$

其中，$X^A_i$ 是第 $i$ 个样本的特征向量，$n^A$ 是样本数量。Party A 的数据仅包含特征，不包含标签。

接着，Party B 拥有数据集：

$$
\mathcal{D}^B := \{(X^B_i, Y^B_i)\}_{i=1}^{n^B}
$$

其中，$X^B_i$ 是第 $i$ 个样本的特征向量，$Y^B_i \in \{0,1\}^C$ 是对应的独热编码（one-hot encoding）真实标签，$C$ 表示类别数，$n^B$ 是样本数量。Party B 拥有标签，这在 VFL 中至关重要，因为标签通常用于监督学习任务。然而，Party B 缺乏足够的特征来单独构建一个准确的模型，因此需要利用 Party A 提供的补充特征。

需要强调的是，$\mathcal{D}^A$ 和 $\mathcal{D}^B$ 分别由 Party A 和 Party B 私有保存，双方不能互相暴露其数据集。

在 VFL 中，Party A 和 Party B 的数据集 $\mathcal{D}^A$ 和 $\mathcal{D}^B$ 包含了不同样本的特征。为了进行联合学习，需要将具有相同身份的样本对齐。假设通过隐私保护的加密实体匹配技术[30]，双方已经完成了样本对齐，得到了对齐样本集：

$$
\mathcal{D}_{al} := \{X^A_{i_{al}}, X^B_{i_{al}}, Y^B_{i_{al}}\}_{i=1}^{n_{al}}
$$

其中，$n_{al}$ 是对 齐样本的数量。Party A 拥有对齐样本的特征：

$$
\mathcal{D}^A_{al} := \{X^A_{i_{al}}\}_{i=1}^{n_{al}}
$$

Party B 拥有对齐样本的特征和标签：

$$
\mathcal{D}^B_{al} := \{X^B_{i_{al}}, Y^B_{i_{al}}\}_{i=1}^{n_{al}}
$$

如果将 $\mathcal{D}^A$ 和 $\mathcal{D}^B$ 连接起来，并使具有相同身份的样本对齐，我们将得到一个如图 1.b 所示的单一数据集。这个数据集是垂直分割的，每个方拥有该数据集的一个垂直分区（或部分视图），这正是“纵向联邦学习”一词的由来。然而，两方之间通常只存在有限数量的对齐样本。

除了对齐样本外，每个方还拥有一些非对齐样本，即没有来自另一方对应样本的数据。对于 Party A，非对齐样本表示为：

$$
\mathcal{D}^A_{nl} := \{X^A_{i_{nl}}\}_{i=1}^{n^A_{nl}}
$$

对于 Party B，非对齐样本表示为：

$$
\mathcal{D}^B_{nl} := \{X^B_{i_{nl}}, Y^B_{i_{nl}}\}_{i=1}^{n^B_{nl}}
$$

从单一表格数据集（见图 1.b）的角度来看，每个方对于另一方的非对齐样本都没有对应的特征（或标签）。我们将这些特征（或标签）视为“缺失”。

传统的 VFL 方法仅使用对齐样本 $\mathcal{D}_{al}$ 来构建联邦机器学习模型，而将非对齐样本 $\mathcal{D}^A_{nl}$ 和 $\mathcal{D}^B_{nl}$ 弃置不用。这种做法在对齐样本数量较少时，可能会限制模型的性能，因为大量潜在有用的数据被忽略。

本文提出了一种新的方法 VFPU-M-Syn，旨在充分利用非对齐样本 $\mathcal{D}^A_{nl}$ 和 $\mathcal{D}^B_{nl}$，以提升纵向联邦学习（VFL）模型的性能。该方法结合了 纵向联邦半监督学习 和 表格数据生成技术，通过将对齐样本 $\mathcal{D}_{al}$ 视为有标签数据（其中 $X^A_{al}$ 的“标签”可看作 $X^B_{al}$ 的特征值），而将非对齐样本 $\mathcal{D}^A_{nl}$ 视为无标签数据，利用半监督学习从对齐样本中学习以增强模型的泛化能力，同时采用表格数据生成技术填补与 Party A 相关性较弱的特征缺失值，并与纵向联邦学习相结合优化数据补全。相比传统 VFL 方法，VFPU-M-Syn 不仅利用了对齐样本 $\mathcal{D}_{al}$，还充分利用了非对齐样本 $\mathcal{D}^A_{nl}$ 和 $\mathcal{D}^B_{nl}$，显著提高了数据利用率；通过纵向联邦半监督学习，模型能从无标签数据中提取有用信息，进一步提升泛化能力；而表格数据生成技术的引入则使得缺失特征的填补更加合理，从而优化了数据填补策略并提高了模型整体性能。总之，VFPU-M-Syn 在传统 VFL 框架基础上引入创新技术，充分利用非对齐样本，在对齐样本有限的情况下显著提升了 VFL 模型的准确性和泛化能力，实验结果也验证了其优越性。

## 2 VFPU-M-Syn方法介绍

### 2.1 Process I 计算跨方特征相关性

在纵向联邦学习（Vertical Federated Learning, VFL）框架中，不同参与方（Parties）拥有相同样本但不同特征的异构数据。为了有效利用对齐样本的特征信息，需要量化跨参与方特征之间的统计关联性。本节提出了一种基于隐私保护的Spearman秩相关分析方法，用于构建跨方特征相关性排序体系。

设协调方（Coordinator）$ C $ 作为可信第三方，负责生成同态加密（Homomorphic Encryption, HE）密钥对 $ \{\text{pk}, \text{sk}\} $，其中：
- $ \text{pk} $ 为公钥（Public Key），用于加密数据；
- $ \text{sk} $ 为私钥（Secret Key），用于解密数据。

协调方 $ C $ 将公钥 $ \text{pk} $ 分发给参与方 A（Party A）和参与方 B（Party B），以便它们对数据进行加密计算，而不直接暴露原始数据，具体计算流程如下：

### 定义 1 特征列秩向量

设参与方 A 的特征空间为 $ \Phi^A = \{\varphi^A_1, \varphi^A_2, ..., \varphi^A_{m_A}\} $，$ m_A $ 表示 A 方的特征维数，即 A 方拥有 $ m_A $ 个特征。$ \varphi^A_p \in \mathbb{R}^{n_{al}} $ 表示 A 方第 $ p $ 个特征在对齐样本集 $ \mathcal{D}^A_{al} $ 上的观测向量，$ \varphi^A_p = [\varphi^A_{p1}, \varphi^A_{p2}, ..., \varphi^A_{pn_{al}}] $ 表示该特征在所有对齐样本上的取值，$ n_{al} $ 为对齐样本的数量。

同理，参与方 B 的特征空间为 $ \Phi^B = \{\varphi^B_1, \varphi^B_2, ..., \varphi^B_{m_B}\} $，$ m_B $ 表示 B 方的特征维数，即 B 方拥有 $ m_B $ 个特征。$ \varphi^B_q \in \mathbb{R}^{n_{al}} $ 表示 B 方第 $ q $ 个特征在对齐样本集 $ \mathcal{D}^B_{al} $上的观测向量。$ \varphi^B_q = [\varphi^B_{q1}, \varphi^B_{q2}, ..., \varphi^B_{qn_{al}}] $ 表示该特征在所有对齐样本上的取值，$ n_{al} $ 为对齐样本的数量。

对于任意特征列 $ \varphi^A_p $，计算其秩向量（Rank Vector）：
$$
R^A_p = [r^A_{p1}, r^A_{p2}, ..., r^A_{pn_{al}}]
$$
$ r^A_{pi} $ 表示样本 $ i $ 在特征 $ \varphi^A_p $ 上的秩次（Rank），即该样本在该特征列中的排序位置，若存在相同值，则采用平均秩（Average Rank）处理。类似地，B 方的特征列 $ \varphi^B_q $ 也可以计算出对应的秩向量：
$$
R^B_q = [r^B_{q1}, r^B_{q2}, ..., r^B_{qn_{al}}]
$$

### 步骤 1 加密秩传输

A 方 使用公钥 $ \text{pk} $ 对秩向量 $ R^A_p $ 进行同态加密，得到：
$$
[R^A_p] = \{\text{Enc}(r^A_{p1}), \text{Enc}(r^A_{p2}), ..., \text{Enc}(r^A_{pn_{al}})\}
$$
并将加密后的秩向量发送给 B 方。类似地，B 方 也对自己的秩向量 $ R^B_q $ 进行同态加密，得到：
$$
[R^B_q] = \{\text{Enc}(r^B_{q1}), \text{Enc}(r^B_{q2}), ..., \text{Enc}(r^B_{qn_{al}})\}
$$

### 步骤 2 秩差计算
对于任意特征对 $ (f^A_p, f^B_q) $，B 方计算加密秩差向量：
$$
[D_{pq}] = \left[ \text{Enc}(r^A_{p1} - r^B_{q1}), ..., \text{Enc}(r^A_{pn_{al}} - r^B_{qn_{al}}) \right]
$$
其中，$ d_{pq}^i = r^A_{pi} - r^B_{qi} $ 表示样本 $ i $ 在 A 方特征 $ f^A_p $ 和 B 方特征 $ f^B_q $ 上的秩次之差，由于同态加密支持加法运算，B 方可以在加密状态下直接计算秩差，而无需解密。B 方将加密秩差向量 $ [D_{pq}] $ 发送给协调方 $ C $。



### 步骤 3 Spearman相关性计算
协调方 $ C $ 解密 $ [D_{pq}] $，得到：
$$
d_{pq}^i = r^A_{pi} - r^B_{qi}, \quad i = 1, ..., n_{al}
$$
然后计算 Spearman 相关系数：
$$
\rho_{pq} = 1 - \frac{6\sum_{i=1}^{n_{al}} (d_{pq}^i)^2}{n_{al}(n_{al}^2 - 1)}
$$
$ \rho_{pq} $ 表示 A 方特征 $ f^A_p $ 与 B 方特征 $ f^B_q $ 之间的 Spearman 相关系数。最终，构建跨方相关性矩阵：
$$
\mathbf{M} \in \mathbb{R}^{m_A \times m_B}, \quad \mathbf{M}(p,q) = \rho_{pq}
$$
$ \mathbf{M}(p,q) $ 存储 A 方第 $ p $ 个特征列与 B 方第 $ q $ 个特征列的 Spearman 相关系数。



### 定义 2 特征关联强度
对于 B 方的每个特征 $ f^B_q $，计算其与 A 方所有特征的平均关联强度：
$$
\mu_q = \frac{1}{m_A} \sum_{p=1}^{m_A} \rho_{pq}, \quad q=1,...,m_B
$$
$ \mu_q $ 表示 B 方特征 $ f^B_q $ 对 A 方特征空间的综合依赖程度。

### 步骤 4 生成排序列表
构建特征重要性序列：
$$
\mathcal{L}_B = \{(\mu_q, f^B_q)\}_{q=1}^{m_B}
$$
按 $ \mu_q $ 降序排列，得到排序后的特征列表
$$
\mathcal{L}_B^{sorted}
$$


该列表用于指导利用联邦半监督学习对 B 方对齐样本的特征补全，优先使用联邦半监督学习方法补充与 A 方特征关联性强的维度。

### 2.2 Process II 纵向联邦半监督预测缺失特征
如图所示，在计算跨方相关性列表之后，研究进入 Process II 阶段。在该阶段，我们从 B 方 中选择一部分与 A 方 具有较高相关性的列，以此作为生成过程的基础。具体而言，该选择过程基于前一阶段计算得到的跨方相关性列表，确保所选列能够最大程度地保留和反映 A 方 的特征信息，从而提高后续生成过程的准确性和有效性。在 Process II 阶段，列的选择标准通常依赖于相关性阈值设定，即仅保留那些与 A 方 相关性超过某一特定阈值的列。

在这一过程中，本方法将B方的高相关性特征逐列拆分，每一列特征单独作为一个标签列。随后，A方的数据与基于纵向联邦半监督学习方法生成的B方部分数据共同构成训练数据集，从而形成一个典型的纵向联邦半监督学习框架[1]。如图所示，$X^A$ 表示A方的数据，而 ${{X}^{{{B}_{predict}}}}$ 代表通过纵向联邦半监督学习方法推测得到的B方部分数据。此外，$f_{q}^{B}$ 表示B方的第 $q$ 个特征列，在本方法中，该特征列被视为 $X^A$ 和 ${{X}^{{{B}_{predict}}}}$ 进行纵向联邦学习时的标签。

在该框架下，A方和B方的数据仍然保持隐私保护，即A方无法直接访问B方的原始数据，B方也无法直接获取A方的数据。然而，通过联邦学习的协作训练机制，A方可以利用自身数据和部分推测得到的B方数据进行模型训练，以优化对B方特征的预测能力。与此同时，B方的高相关性特征被逐列拆分，使得每一列特征都可以单独作为监督信号，从而有效地提升模型的学习能力。

在本研究中，该问题被重新表述为一个纵向联邦半监督学习（Vertical Federated Semi-Supervised Learning, VFSSL）问题，其中特征集 $X^A$ 和 $X^{B_{\text{predict}}}$ 的数据被划分为有标签部分和无标签部分。文献 [1] 提出了VFPU（Vertical Federated Positive-Unlabeled Learning）算法来解决纵向联邦半监督学习问题。然而，VFPU 方法主要适用于PU（Positive-Unlabeled）学习，即仅包含正样本和未标记样本的情况，而在本研究中，$ f_q^B $ 特征列可能涉及二分类、多分类甚至回归任务，VFPU 方法无法直接适用。因此，本文在 VFPU 方法的基础上进行了改进，提出了一种新的方法——VFPU-M（Multi-task VFPU），使其能够适用于多种任务类型。

VFPU-M 主要通过以下五个步骤实现纵向联邦半监督学习，如图所示：

1. 基于对齐数据进行纵向联邦训练  
2. 利用训练好的基学习器对未对齐数据进行预测  
3. 计算预测结果的置信度  
4. 选择高置信度样本加入对齐数据集  
5. 重复上述过程，直至满足终止条件  

通过 VFPU-M 方法，本研究能够在纵向联邦学习框架下有效利用无标签数据，从而提升模型的泛化能力，并适用于多种任务类型（如二分类、多分类和回归任务）。实验结果表明，VFPU-M 在不同任务场景下均能取得优于传统 VFPU 方法的性能，进一步验证了其有效性和适用性。



以上是资料，你是一个SCI论文的审稿专家，我发你一段话，你对齐进行润色和内容扩充，要求符合学术论文的严谨、科学、正确。内容要求丰富，因为SCI论文有字数要求。需要扩写下面的内容:



本阶段主要是要执行两个算法，算法1：用纵向联邦半监督学习方法生成数据的过程和算法2：VFPU-M算法，在后文，将依次介绍这两个算法。

在本阶段的研究工作中，主要需要执行两个核心算法，以确保数据处理和模型训练的有效性。这两个算法分别为：算法1——基于纵向联邦半监督学习（Vertical Federated Semi-Supervised Learning, VFSSL）的方法用于数据生成的过程，以及算法2——VFPU-M（Vertical Federated PU Learning with Model Adaptation）算法。在后续章节中，我们将对这两个算法的理论基础、实现细节及其在本研究中的具体应用进行详细介绍。

### 算法 1：基于纵向联邦半监督学习的数据生成过程

本节介绍了一种基于纵向联邦半监督学习（Vertical Federated Semi-supervised Learning, VFSL）的方法，用于生成 B 方缺失的数据。该方法的核心思想是利用 A 方与 B 方对齐数据之间的统计相关性，结合联邦学习框架，在保证数据隐私的前提下，对 B 方未对齐样本进行特征补全。算法 1 详细描述了该数据生成过程。

1. 算法输入与参数定义

算法的输入包括以下几个关键元素：A 方对齐数据：$X_{al}^A \in \mathbb{R}^{n_{al} \times d_A}$，表示 A 方与 B 方样本空间对齐的特征矩阵，其中 $n_{al}$ 为对齐样本的数量，$d_A$ 为 A 方特征维度。A 方未对齐数据：$X_{nl}^A \in \mathbb{R}^{n_{nl} \times d_A}$，表示 A 方未对齐部分的特征矩阵，其中 $n_{nl}$ 为未对齐样本的数量。B 方相关系数列表：$\mathcal{L}_B = \{(\mu_q, \phi^B_q)\}_{q=1}^{d_B}$，其中 $\mu_q$ 表示 B 方特征列 $\phi^B_q$ 与 A 方数据的皮尔逊相关系数，$d_B$ 为 B 方特征维度。相关性阈值：$\tau$，用于筛选与 A 方数据具有显著相关性的 B 方特征列。该阈值的选取通常基于统计显著性检验，以确保筛选出的特征在统计上具有可靠性。

2. 算法流程

算法的核心目标是利用 A 方数据预测 B 方未对齐样本的特征值，并生成完整的 B 方数据矩阵 $X^{B_{predict}}$。整个过程可分为以下三个主要步骤：

 初始化阶段：目标数据集 $X^{B_{predict}}$ 为空集，表示尚未生成任何 B 方数据。通过相关性筛选，从 $\mathcal{L}_B$ 中选取所有相关性系数大于阈值 $\tau$ 的特征列，构造预测特征集合：
$$
\mathcal{L}_B^{\text{predict}} = \{(\mu_q, \phi^B_q) \in \mathcal{L}_B \mid \mu_q > \tau\}
$$
该筛选过程通常采用假设检验方法，以确保仅保留统计上显著相关的特征，从而提高数据生成的可靠性。

特征级联邦数据生成：对于每个满足相关性筛选条件的特征列 $(\mu_q, \phi^B_q) \in \mathcal{L}_B^{\text{predict}}$，执行以下步骤，数据分区  
将 B 方特征列 $\phi^B_q$ 的预测数据划分为：对齐部分：$X_{al}^{B_{predict}} \in \mathbb{R}^{n_{al}}$，对应于 A 方对齐样本的 B 方特征值。未对齐部分：$X_{nl}^{B_{predict}} \in \mathbb{R}^{n_{nl}}$，需要通过联邦学习方法进行预测。

这种数据分区方式与 A 方数据结构保持一致，有助于后续联邦建模的执行。

- 联邦预测建模  
  采用 VFPU-M（Vertical Federated Prediction with Unlabeled Missing data）算法进行特征预测，该算法将在后续章节详细介绍。其函数形式如下：
  $$
  p = \text{VFPU-M}(X_{al}^A, X_{nl}^A, X_{al}^{B_{predict}}, X_{nl}^{B_{predict}}, \phi^B_q)
  $$
  其中：
  - 对齐部分 $X_{al}^{B_{predict}}$ 直接使用 B 方已有的特征值。
  - 未对齐部分 $X_{nl}^{B_{predict}}$ 通过 VFPU-M 进行预测，生成伪标签数据。

  该过程确保了 B 方数据的补全，同时符合联邦学习的隐私保护要求。

- 数据合成  
  将 VFPU-M 预测得到的伪标签向量 $p$ 合并至目标数据集 $X^{B_{predict}}$，完成当前特征列的数据生成。

##### (3) 迭代执行
通过遍历所有满足相关性筛选条件的特征列，最终生成完整的 B 方数据矩阵：
$$
X^{B_{predict}} \in \mathbb{R}^{n_B \times |\mathcal{L}_B^{\text{predict}}|}
$$
该矩阵不仅保留了与 A 方数据的统计相关性，同时符合纵向联邦学习的隐私保护约束。

### 2.3 Process III 利用生成模型生成表格数据
目前表现比较优秀的数据生成方法主要有基于自编码的生成模型、生成对抗网络（Generative Adversarial Networks, GAN）、扩散模型（Diffusion Probabilistic Models，DDPM）等，旨在通过已有的样本来生成新的样本数据。
基于自编码的生成模型，如：自编码器AE[35]、变分自编码器VAE[37]等。L. Xu [38]等人提出的是对变分自编码器（VAE）的改进方法，通过对隐变量与表格数据特征的联合分布进行专门建模，以实现对连续和离散特征的有效生成与重构。
GAN[39]是 I. J. Goodfellow 等人在2014年提出的模型，GAN受博弈论的启发，内部有生成器（G）和判别器（D）两个网络，两个网络相互对抗博弈达到有效生成数据的目的。M. Mirza 等人[40]提出的CGANs（Conditional Generative Adversarial Nets）在生成模型和判别模型的建模中均引入条件变量，即数据的标签，将GANs从无监督学习变成有监督学习。M. Arjovsky 等人[42, 43]引入Wasserstein距离来替代JS散度和KL散度，并将其作为优化目标，从而提出了WGAN（Wasserstein GAN），从根本上解决了原始GAN的梯度消失问题。L. Xu 等人[44]提出了一种生成对抗网络Tabular GAN (TGAN)，使用LSTM和MLP分别作为生成器和判别器，生成如病例或教育记录等表格数据。2019年，L. Xu 等人[38]提出了一种基于Conditional GAN的CTGAN来生成表格数据，用于对表格数据分布和样本行进行建模。Y. Yu 等人[45]提出了一种基于改进的条件生成对抗网络CWGAN(Conditional Wasserstein Generative Adversarial Nets)来学习滚动轴承故障的时频谱特征，并根据输入类别生成相应故障类别的时频谱。J. Lee 等人[47]提出了一个广义的GAN框架的表格合成，它结合了GAN的对抗训练和可逆神经网络的负对数密度正则化，以提高生成数据的综合质量。2021年，M. Esmaeilpour 等人[48]提出了一种用于合成包含连续列、二进制列和离散列的表数据集的双判别器GAN。S. Singh 等人[49]提出MeTGAN，使用稀疏线性层来克服CTGAN的内存瓶颈，大大减少了训练的内存使用。Z. Zhao 等人[50]在CTGAN的基础上，提出了CTAB-GAN用于对不同数据类型的建模，包括连续变量、分类变量、混合特征变量等类型。J. Engelmann 等人[52]提出了一种基于条件Wasserstein GAN的方法，对具有数值和分类变量的表格数据集进行建模，并通过一个辅助分类器来特别关注下游分类任务。
DDPM[55]是 J. Ho 等人在2020年提出的扩散概率模型，通过正向的逐步加噪过程将数据分布转化为标准正态分布，并学习逆向去噪过程，从高斯噪声中生成目标数据。该方法通过多步马尔科夫链精确建模生成过程，生成质量高但效率相对较低。在此基础上，A. Kotelnikov 等人[56]提出了一种基于扩散模型的表格数据生成方法TabDDPM，通过特定的噪声添加和去噪过程，有效捕捉了数值型与类别型特征间的复杂关系。
伴随着人工智能和大数据技术的快速发展和应用，对基于生成对抗网络和扩散模型的数据生成方法为近几年的重要方法。然而，当样本中某些数据元素出现缺失时，无法给机器学习任务（如分类、预测等）的模型训练提供更多优质训练样本。因此，需要对样本中的缺失数据元素进行生成填补。目前主要的数据填补方法包括基于统计的填补方法、基于传统机器学习的填补方法、基于深度学习的填补方法等。

利用上面谈到的一些模型进行表格数据合成

