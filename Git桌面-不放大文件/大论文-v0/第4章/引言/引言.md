```
Federated learning allows multiple parties to build machine learning models collaboratively without exposing data. In particular, vertical federated learning (VFL) enables participating parties to build a joint machine learning model based upon distributed features of aligned samples. However, VFL requires all parties to share a sufficient amount of aligned samples. In reality, the set of aligned samples may be small, leaving the majority of the non-aligned data unused. Based on the content of Chapter 3, in this chapter, we propose VFPU-Multitask-Synthesis (VFPU-M-Syn), a vertical federated semi-supervised learning approach that improves the performance of the VFL model with limited aligned samples. More specifically, VFPU-M-Syn estimates representations for missing features.For high correlation features, VFPU-M-Syn predicts pseudo-labels for unlabeled samples to expand the training set. For the rest correlation features VFPU-M-Syn use generative model to synthesis the data.VFPU-M-Syn trains three classifiers jointly based upon different views of the expanded training set to improve the VFL model’s performance.FedCVT does not require parties to share their original data and model parameters, thus preserving data privacy. 

```



引言

```
With the increasingly stricter privacy-protection laws implemented worldwide, federated learning has received significant attention and become a popular research topic recently. As the research goes deeper and wider, the practice of federated learning has been expanded from building powerful mobile applications based on data resided in millions of mobile devices [28]to solving the problem of data silos among or within organizations. For example, many business decisions of a bank may rely on its customers’ purchasing preferences. This bank may share some customers with a local retail company that owns local people’s purchasing preference data. Thus, the bank can invite the retail company to build a joint model collaboratively by leveraging the data features of both sides to improve its business. The retail company can also benefit from this joint model.

This and various other similar practical demands [40] motivate the development of vertical federated learning (VFL) [39] (also called feature-partitioned federated learning), which enables participating parties to train a joint machine learning model collaboratively by utilizing scattered features of their aligned samples without disclosing original data. However, a critical prerequisite of VFL is that it requires all parties to share a sufficient amount of aligned samples to achieve competitive model performance. [26] proposes a federated transfer learning framework to address weak supervision (few labels) problems in the VFL setting. Nonetheless, it does not take full advantage of unlabeled samples for improving learning quality, and it aims to build a model only for the party of the target domain. Some other similar approaches, such as domain adaptation [24, 33, 34] and knowledge distillation [11, 22], have been applied in the federated learning setting. However, they mainly focus on scenarios where all parties share the same feature space (also known as horizontal federated learning [39]). Therefore, research on applying semi-supervised techniques in the VFL setting is insufficient.
```

```
Federated learning enables multiple parties to collaboratively build machine learning models without exposing their private data. In particular, vertical federated learning (VFL) constructs a joint model using distributed features of aligned samples. However, VFL requires participating parties to share a sufficiently large set of aligned samples—an assumption often violated in practice, where only a small fraction of data is aligned, leaving the majority of non-aligned data unused.

Motivated by the limitations discussed in Chapter 3, this chapter proposes VFPU-Multitask-Synthesis (VFPU-M-Syn), a vertical federated semi-supervised learning approach designed to enhance VFL performance when aligned samples are limited. Specifically, VFPU-M-Syn estimates representations for missing features. For features with high correlation, VFPU-M-Syn predicts pseudo-labels for unlabeled samples to expand the training set, whereas for features with lower correlation, it employs a generative model to synthesize data. VFPU-M-Syn then trains three classifiers jointly on these augmented views of the data to improve the overall VFL model’s performance. 

Moreover, VFPU-M-Syn preserves data privacy by ensuring that neither raw data nor model parameters are exchanged among parties, addressing a critical requirement in federated learning settings.
```

```
联邦学习使多个参与方能够在不暴露私有数据的情况下协作构建机器学习模型。特别是，纵向联邦学习（VFL）利用对齐样本的分布式特征来构建联合模型。然而，VFL要求参与方共享足够大的对齐样本集——这一假设在实践中常常不成立，因为只有一小部分数据是对齐的，留下大部分未对齐的数据未被利用。

受第3章讨论的局限性启发，本章提出了VFPU-Multitask-Synthesis（VFPU-M-Syn），一种纵向联邦半监督学习方法，旨在在对齐样本有限时提升VFL性能。具体而言，VFPU-M-Syn估计缺失特征的表示。对于高度相关的特征，VFPU-M-Syn预测未标记样本的伪标签以扩展训练集；而对于相关性较低的特征，则采用生成模型合成数据。随后，VFPU-M-Syn在这些增强的数据视图上联合训练三个分类器，以提高整体VFL模型的性能。此外，VFPU-M-Syn通过确保参与方之间不交换原始数据或模型参数来保护数据隐私，满足联邦学习环境中的关键要求。
```

