\section{基于联邦半监督学习的参与方样本生成方法框架}
如图 \ref{fig: FedPSG-PUM } 所示， FedPSG-PUM  方法的核心包含三个主要流程，这三个流程共同协作以实现跨方数据的高效处理和特征生成。

\vspace{-0.1cm}
\begin{figure}[h]  % 创建一个浮动图形环境，[h]表示尽量将图片放在当前位置(here)
	\centering     % 使图片居中显示
	\includegraphics[width=0.9\textwidth]{chapters/imgs/FedPSG-PUM }  
	\bicaption[\xiaosi  FedPSG-PUM 算法总体流程]
	{\wuhao  FedPSG-PUM 算法总体流程}
	{\wuhao The overall process of the proposed  FedPSG-PUM  algorithm}
	\label{fig: FedPSG-PUM }  % 为图片设置标签，可以在文中使用\ref{fig:VFPU}引用此图
\end{figure}
\vspace{-0.35cm}

首先，在 Process I 中，算法通过计算跨方特征之间的相关性，评估和量化各个特征之间的相互依赖关系。这一过程的目标是确保在纵向联邦学习框架中，不同方的特征能够高效对齐，并通过特征相关性分析揭示不同数据源之间可能存在的潜在依赖结构，从而为后续的建模步骤提供更加精确和有针对性的特征信息。接下来，在 Process II 中，方法采用纵向联邦半监督学习算法来进行数据预测。在这一阶段，算法通过结合来自多个方的信息，并利用半监督学习的策略，有效地预测出缺失或未标记的数据。这一过程不仅保证了数据的完整性，还通过有效利用部分标记数据和大量未标记数据，增强了模型的预测能力和鲁棒性。通过这种方式， FedPSG-PUM  方法能够在数据不完全或部分缺失的情况下，依然保持较高的预测精度。最后，在 Process III 中， FedPSG-PUM  方法利用生成模型生成数据。通过对已预测数据和其他相关特征的建模，生成模型能够创造出与真实数据相似的合成数据。这些生成的数据不仅能够补充现有数据的不足，还可以用来进一步优化模型的训练过程，提升模型在实际应用中的泛化能力。生成的数据也有助于应对训练数据中可能出现的偏差或不均衡问题，进一步增强模型的稳定性和可靠性。下面的小节将分别介绍这三个流程。



\subsection{计算跨方特征相关性}
在纵向联邦学习（Vertical Federated Learning, VFL）框架中，不同参与方（Parties）拥有相同样本但不同特征的异构数据。为了有效利用对齐样本的特征信息，需要量化跨参与方特征之间的统计关联性。本节提出了一种基于隐私保护的Spearman秩相关分析方法，用于构建跨方特征相关性排序体系。

设协调方（Coordinator）$ C $ 作为可信第三方，负责生成同态加密（Homomorphic Encryption, HE）密钥对 $ \{\text{pk}, \text{sk}\} $，$ \text{pk} $ 为公钥（Public Key），用于加密数据；$ \text{sk} $ 为私钥（Secret Key），用于解密数据。

协调方 $ C $ 将公钥 $ \text{pk} $ 分发给参与方 A（Party A）和参与方 B（Party B），以便它们对数据进行加密计算，而不直接暴露原始数据，具体计算流程如下：

定义特征列秩向量，设参与方 A 的特征空间为 $X^A \subseteq \mathbb{R}^{m_A}$，$ m_A $ 表示 A 方的特征维数，即 A 方拥有 $ m_A $ 个特征。$ x^A_p \in \mathbb{R}^{n_{al}} $ 表示 A 方第 $ p $ 个特征在对齐样本集 $ \mathcal{D}^A_{al} $ 上的观测向量，$ x^A_p = [x^A_{p1}, x^A_{p2}, ..., x^A_{pn_{al}}] $ 表示该特征在所有对齐样本上的取值，$ n_{al} $ 为对齐样本的数量。

同理，参与方 B 的特征空间为$X^B \subseteq \mathbb{R}^{m_B}$，$ m_B $ 表示 B 方的特征维数，即 B 方拥有 $ m_B $ 个特征。$ x^B_q \in \mathbb{R}^{n_{al}} $ 表示 B 方第 $ q $ 个特征在对齐样本集 $ \mathcal{D}^B_{al} $上的观测向量。$ x^B_q = [x^B_{q1}, x^B_{q2}, ..., x^B_{qn_{al}}] $ 表示该特征在所有对齐样本上的取值，$ n_{al} $ 为对齐样本的数量。

为了计算特征间的相关性，需要首先将特征值转换为秩次。对于任意特征列$x^A_p$，计算其秩向量（Rank Vector）：
\begin{equation}
	R^A_p = [r^A_{p1}, r^A_{p2}, ..., r^A_{pn_{al}}]
\end{equation}
式中，$r^A_{pi}$表示样本$i$在特征$x^A_p$上的秩次（Rank），即该样本在该特征列中的排序位置，若存在相同值，则采用平均秩（Average Rank）处理。这种转换可以有效减轻异常值对相关性分析的影响，提高方法的稳健性。类似地，B方的特征列$x^B_q$也可以计算出对应的秩向量：
\begin{equation}
	R^B_q = [r^B_{q1}, r^B_{q2}, ..., r^B_{qn_{al}}]
\end{equation}
基于上述定义，设计了一个安全高效的跨方特征相关性计算流程。首先进行加密秩传输，A方使用公钥$\text{pk}$对秩向量$R^A_p$进行同态加密，得到：
\begin{equation}
	[R^A_p] = \{\text{Enc}(r^A_{p1}), \text{Enc}(r^A_{p2}), ..., \text{Enc}(r^A_{pn_{al}})\}
\end{equation}
并将加密后的秩向量发送给B方。通过同态加密技术，A方可以安全地将自己的特征秩信息分享给B方，而不泄露原始数据。类似地，B方也对自己的秩向量$R^B_q$进行同态加密，得到：
\begin{equation}
	[R^B_q] = \{\text{Enc}(r^B_{q1}), \text{Enc}(r^B_{q2}), ..., \text{Enc}(r^B_{qn_{al}})\}
\end{equation}
接下来进行秩差计算，对于任意特征对$(x^A_p, x^B_q)$，B方计算加密秩差向量：
\begin{equation}
	[D_{pq}] = \left[ \text{Enc}(r^A_{p1} - r^B_{q1}), ..., \text{Enc}(r^A_{pn_{al}} - r^B_{qn_{al}}) \right]
\end{equation}
式中，$d_{pq}^i = r^A_{pi} - r^B_{qi}$表示样本$i$在A方特征$x^A_p$和B方特征$x^B_q$上的秩次之差。这里利用了同态加密的一个重要特性：支持加法运算，使B方可以在加密状态下直接计算秩差，而无需解密原始数据，从而保证了计算过程的隐私安全。计算完成后，B方将加密秩差向量$[D_{pq}]$发送给协调方$C$。在获得加密的秩差向量后，协调方$C$使用私钥$\text{sk}$解密$[D_{pq}]$，得到：
\begin{equation}
	d_{pq}^i = r^A_{pi} - r^B_{qi}, \quad i = 1, ..., n_{al}
\end{equation}
协调方然后基于这些秩差值计算Spearman相关系数，该系数是衡量两个变量单调关系强度的非参数度量：
\begin{equation}
	\rho_{pq} = 1 - \frac{6\sum_{i=1}^{n_{al}} (d_{pq}^i)^2}{n_{al}(n_{al}^2 - 1)}
\end{equation}
式中，$\rho_{pq}$表示A方特征$x^A_p$与B方特征$x^B_q$之间的Spearman相关系数。相较于Pearson相关系数，Spearman相关系数对数据分布不敏感，能够捕获非线性单调关系，更适合异构数据场景。通过计算所有特征对的相关系数，最终可以构建完整的跨方相关性矩阵：
\begin{equation}
	\mathbf{M} \in \mathbb{R}^{m_A \times m_B}, \quad \mathbf{M}(p,q) = \rho_{pq}
\end{equation}
式中，$\mathbf{M}(p,q)$存储A方第$p$个特征列与B方第$q$个特征列的Spearman相关系数，该矩阵全面反映了两方特征空间之间的关联结构。在获得特征间相关性矩阵后，进一步定义特征关联强度的概念。对于B方的每个特征$x^B_q$，计算其与A方所有特征的平均关联强度：
\begin{equation}
	\mu_q = \frac{1}{m_A} \sum_{p=1}^{m_A} \rho_{pq}, \quad q=1,...,m_B
	\label{eq:mu_definition}
\end{equation}

式中，$\mu_q$表示B方特征$x^B_q$对A方特征空间的综合依赖程度。这一指标综合考虑了B方特征与A方所有特征的关联性，可以有效评估该特征在跨方联合建模中的重要程度。关联强度高的特征通常包含更多与对方特征空间相关的信息，在后续的联邦建模中具有更高的价值。最后，基于特征关联强度生成排序列表。具体而言，构建特征重要性序列：
\begin{equation}
	\mathcal{L}_B = \{(\mu_q, \mathbf{x}^B_q)\}_{q=1}^{m_B}
\end{equation}
\subsection{纵向联邦半监督方法预测数据}
如图 \ref{fig: FedPSG-PUM } 所示，在完成跨方相关性矩阵计算后，研究工作进入Process II阶段。这一阶段的核心目标是从B方数据中识别并提取与A方具有较高相关性的特征列，作为数据生成的关键基础。这种特征选择过程绝非随机筛选，而是基于前一阶段通过严格数学建模计算得到的跨方相关性矩阵$\mathbf{M} \in \mathbb{R}^{m_A \times m_B}$，其中$\mathbf{M}(p,q) = \rho_{pq}$存储了A方第$p$个特征与B方第$q$个特征之间的Spearman相关系数。这一矩阵全面量化了双方特征空间之间的统计关联结构，为特征选择提供了可靠的数学依据。

在Process II阶段，特征列的选择遵循一个基于阈值的数学判定准则：系统仅保留那些综合相关强度$\mu_q$超过预设阈值$\tau$的B方特征列。其中，$\mu_q$定义为B方第$q$个特征与A方所有特征的平均相关系数，如公式~\eqref{eq:mu_definition}所示。

这一指标综合评估了B方特征$x^B_q$与整个A方特征空间的统计依赖程度，为后续的纵向联邦半监督学习奠定了理论基础。通过这种基于数学模型的特征筛选机制，系统能够最大限度地保留和利用跨方数据间的内在关联，从而显著提高生成过程的准确性和效率。

\subsubsection{联邦半监督学习框架设计}
在FedPSG-PUM方法中，采用"列级特征分解"(Column-wise Feature Decomposition, CFD)策略，将B方的高相关性特征空间$X^B_{high}$进行分解，使每一列特征$x^B_q$都被单独处理为一个独立的预测目标（即标签列），这种处理方式使得原来数据生成问题，变成某一列的联邦半监督预测问题。

从数学角度看，方法最终试图建立一个多对多的映射函数$f: \mathbb{R}^{d_A} \rightarrow \mathbb{R}^{d_B}$，直接从A方特征空间映射到B方整个特征空间，CFD策略将这一复杂映射分解为$d_B'$个独立的单维映射函数：$f_q: \mathbb{R}^{d_A} \rightarrow \mathbb{R}, q = 1, 2, ..., d_B'$，式中$d_B'$是筛选后的高相关性特征数量（$d_B' = |X^B_{high}| \leq d_B$）。每个$f_q$只负责预测一个B方特征，而这个问题可以借助第3章的方法进行解决。

在这一框架下，处理的是以下数据实体：
A方的特征矩阵$X^A \in \mathbb{R}^{n \times d_A}$，式中$n = n_{al} + n_{nl}$表示A方样本总数（对齐和非对齐样本之和），$d_A$表示A方特征维度； B方的对齐特征矩阵$X^B_{al} \in \mathbb{R}^{n_{al} \times d_B}$，式中$n_{al}$表示对齐样本数量，$d_B$表示B方特征维度；待预测的B方非对齐特征矩阵$X^B_{predict} \in \mathbb{R}^{n_{nl} \times d_B'}$，式中$n_{nl}$表示非对齐样本数量，$d_B'$表示高相关性特征数量

对于具体的特征预测过程，采用“多列对一列模型”（Multi-Column-One-Model, MCOM）的策略。对于每个高相关性特征$x^B_q \in X^B_{high}$，单独构建一个联邦半监督学习模型$\mathcal{F}_q$，形式化地：

\begin{equation}
	\mathcal{F}_q: X^A \rightarrow x^B_q, \quad \forall x^B_q \in X^B_{high}
\end{equation}


这种框架设计在多个方面展现出显著优势。首先，采用单特征预测模型能够有效降低模型的参数复杂度，相较于多特征联合建模而言，其过拟合风险更低，泛化能力更强。其次，为每个特征量身定制专属模型，有助于更精准地捕捉其与A方特征空间之间的特定关联模式，从而提升预测精度。此外，不同特征对应的模型可以并行进行训练与推理，显著提高了整体计算效率。在系统鲁棒性方面，该策略也表现出更高的容错性，即便某个模型出现故障，也仅影响对应特征的预测结果，不会导致整个系统失效。更重要的是，该方法具备高度的结构灵活性，能够根据特征的数据类型（如连续值、类别值、有序值等）选择最适合的模型结构进行建模。在CFD策略下，特征 $x^B_q \in \mathbb{R}^{n_{al}}$ 不再仅仅是一个被动的数据属性，而是被赋予了新的角色——在 $X^A$ 与 $X^{B_{predict}}$ 进行纵向联邦学习的过程中，它作为目标预测变量参与建模。这种概念上的重新定义，将特征预测问题巧妙转化为一系列半监督学习任务，不仅能够充分利用现有的半监督学习理论与算法，还能在整个过程中保持对数据隐私的严格保护，契合联邦学习框架的核心要求。

这种多层次的隐私保护架构确保了在整个联邦半监督学习过程中，A方无法访问B方的特征数据$X^B$，B方也无法获取A方的特征数据$X^A$。双方仅通过安全的加密通信渠道交换经过处理的中间结果，如加密梯度、噪声化参数更新等，而非原始数据本身。

协作训练机制的完整数学表达可概括为：A方利用自身数据$X^A$作为输入特征，将B方对齐样本特征$x^B_q|_{al} \in \mathbb{R}^{n_{al}}$作为标签，训练预测模型$\mathcal{M}_q$。训练完成后，A方可对其未对齐样本应用模型，生成预测结果$\hat{x}^B_q|_{nl} \in \mathbb{R}^{n_{nl}}$。最终，对所有高相关性特征重复此过程，可得到完整的B方预测特征矩阵：

\begin{equation}
	X^{B_{predict}} = [\hat{x}^B_1|_{nl}, \hat{x}^B_2|_{nl}, ..., \hat{x}^B_{d_B'}|_{nl}] \in \mathbb{R}^{n_{nl} \times d_B'}
\end{equation}

这种“多列对一列模型”的策略不仅显著提升了预测精度，而且具有很强的可解释性和灵活性，特别适合处理异构数据源之间的特征预测任务。

本文创新性地将纵向联邦学习环境中的数据缺失问题重新形式化为纵向联邦半监督学习框架（Vertical Federated Semi-Supervised Learning, VFSSL）下的多任务预测问题。这种重新建模不仅为解决原问题提供了新的技术路径，还建立了联邦学习与半监督学习的理论桥梁，使两个领域的技术优势得以有效融合。

在数学形式上，考虑A方特征集$X^A \in \mathbb{R}^{n \times d_A}$，式中包含$n = n_{al} + n_{nl}$个样本，每个样本具有$d_A$维特征。这些样本可进一步划分为两个互斥子集：

(1) 有标签子集 $X^A_{L} = X^A_{al} \in \mathbb{R}^{n_{al} \times d_A}$：这部分样本能够与B方样本通过安全实体对齐技术匹配，因此对应的B方特征值$x^B_q|_{al} \in \mathbb{R}^{n_{al}}$是已知的，可作为监督信号（标签）

(2) 无标签子集 $X^A_{U} = X^A_{nl} \in \mathbb{R}^{n_{nl} \times d_A}$：这部分样本没有对应的B方匹配样本，因此缺乏相应的特征标签，需要通过半监督学习技术进行预测

通过这种形式化表达，将问题变换为：对于每个高相关性特征$x^B_q \in X^B_{high}$，构建有标签数据集$\mathcal{D}_L^q$和无标签数据集$\mathcal{D}_U$：
\begin{align}
	\mathcal{D}_{L}^{q} &= \{(x_{i}^{A},y_{i}^{q})|x_{i}^{A}\in X_{L}^{A},y_{i}^{q}=x_{q}^{B}(i),i=1,2,...,{{n}_{al}}\} \\
	{{\mathcal{D}}}_{U} &= \{x_{j}^{A}|x_{j}^{A}\in X_{U}^{A},j=1,2,...,{{n}_{nl}}\}
\end{align}
式中，$y_i^q$是B方第$q$个特征在第$i$个对齐样本上的取值，可根据特征类型表现为连续值（回归任务）或离散值（分类任务）。研究目标是学习一组预测函数$\{f_q | q = 1,2,...,d_B'\}$，使得对于任意$x^A \in \mathbb{R}^{d_A}$，$f_q(x^A)$能够准确预测对应的$x^B_q$值。B方特征$x^B_q$可能是连续值（如年龄、收入等）、二分类值（如是/否）或多分类值（如教育水平等），需要算法能够灵活处理不同类型的预测任务。

\subsubsection{多任务联邦半监督学习算法}
根据上述框架设计，本文创新性地提出了改进型VFPU-M（Multi-task VFPU）方法。该方法通过纵向联邦协同训练构建特征预测模型，同时采用伪标签技术有效利用无标签数据，实现了在联邦环境下的高效半监督学习。VFPU-M的核心理念是通过迭代式地提高模型性能并从无标签数据中筛选出高可信度样本，逐步扩展训练集规模，从而在保护隐私的前提下提升预测精度。

\vspace{-0.1cm} 
\begin{table}[h]
	\renewcommand{\arraystretch}{0.6}
	\centering
	{\songti \wuhao
		\begin{tabular}{p{\textwidth}}
			\toprule[1.5pt]
			\makecell[l]{\songti\wuhao  算法 4-1 纵向联邦半监督方法生成数据算法}\\
			\midrule[0.75pt]
			\makecell[l]{\wuhao \textbf{输入:} A方对齐数据集 $X_{al}^A$, 未标记数据集 $X_{nl}^A$,B 方特性相关性列表 $\mathcal{L}_B$}\\
			\makecell[l]{\wuhao \quad 对齐数据集样本数量 $n_{al}$，标记数据集的样本数量 $n_{nl}$，相关性阈值 $\tau$}\\
			\makecell[l]{\wuhao \textbf{输出:} $X^{B_{predict}}$: 最终通过预测方法生成的B方数据}\\
			\makecell[l]{\wuhao \textbf{Process:}}\\
			\makecell[l]{\wuhao 1: Initialize $X^{B_{predict}} = \emptyset$, $\mathcal{L}_B^{\text{predict}} = \{(\mu_q, x^B_q) \in \mathcal{L}_B \mid u_q > \tau\}$}\\
			\makecell[l]{\wuhao 2: \textbf{for} $(\mu_q, x^B_q) \in \mathcal{L}_B^{\text{predict}}$ \textbf{do}}\\
			\makecell[l]{\wuhao 3: \quad $X_{al}^{B_{predict}} = \{x_{i}^{B_{predict}}\}_{i=1}^{n_{al}}$}\\
			\makecell[l]{\wuhao 4: \quad $X_{nl}^{B_{predict}} = \{x_{i}^{B_{predict}}\}_{i=n_{al}+1}^{n_{al}+n_{nl}}$}\\
			\makecell[l]{\wuhao 5: \quad $p = \text{VFPU-M}(X_{al}^A, X_{nl}^A, X_{al}^{B_{predict}}, X_{nl}^{B_{predict}}, x^B_q)$}\\
			\makecell[l]{\wuhao 6: \quad $X^{B_{predict}} = X^{B_{predict}} \cup \{p\}$}\\
			\makecell[l]{\wuhao 7: \textbf{end for}}\\
			\makecell[l]{\wuhao 8: 得到 $X^{B_{predict}}$}\\
			\bottomrule[1.5pt]
		\end{tabular}
	}
	\label{tab:algo-vfpu}
\end{table}
\vspace{-0.35cm}



算法4-1和算法4-2是VFPU-M方法的具体实现，共同构成了我们提出的纵向联邦半监督预测数据的完整技术路线。下面将系统地解析这两个算法的数学原理和实现细节。

(1) 算法4-1：纵向联邦半监督方法生成数据算法

算法4-1提出了一种基于纵向联邦半监督学习的缺失数据生成方法，通过深入挖掘参与方A与B之间对齐样本的统计关联特性，在联邦学习框架下构建特征补全模型，实现在保护各方数据隐私的前提下，高效补全B方未对齐样本的缺失特征。该算法的输入参数包括：A方对齐数据：$X_{al}^A \in \mathbb{R}^{n_{al} \times d_A}$，表示A方与B方样本空间对齐的特征矩阵。这一数据集是算法的核心训练资源，其中$n_{al}$为对齐样本的数量，反映了可用的标记数据规模；$d_A$为A方特征维度，表征了特征空间的复杂度；A方未对齐数据：$X_{nl}^A \in \mathbb{R}^{n_{nl} \times d_A}$，表示A方未对齐部分的特征矩阵。这些样本缺少对应的B方特征标记，是算法需要为其预测B方特征的目标数据集。参数$n_{nl}$为未对齐样本的数量，通常远大于$n_{al}$，表明了无标签数据的丰富程度；B方相关系数列表：$\mathcal{L}_B = \{(\mu_q, X^B_q)\}_{q=1}^{d_B}$，其中$\mu_q$表示B方特征列$X^B_q$与A方数据的综合相关系数（在前文中已定义）。这一列表对B方的每个特征进行了相关性量化，为特征选择提供了理论依据。参数$d_B$为B方特征维度，反映了需要生成的特征空间规模；相关性阈值：$\tau \in [0, 1]$，用于筛选与A方数据具有显著相关性的B方特征列。该阈值的选择直接影响算法的执行路径和生成数据的质量。较高的$\tau$值意味着更严格的特征筛选标准，通常会减少被选择的特征数量，但提高预测的准确性；较低的$\tau$值则会保留更多特征，可能增加噪声但提高了特征覆盖率。该算法的步骤如下：

步骤1：初始化与相关性筛选

算法首先将目标数据集$X^{B_{predict}}$初始化为空集，表示尚未生成任何B方数据：
\begin{equation}
	X^{B_{predict}} = \emptyset
\end{equation}
随后通过相关性筛选，从$\mathcal{L}_B$中选取所有相关性系数大于阈值$\tau$的特征列，构造预测特征集合：

\begin{equation}
	\mathcal{L}_B^{\text{predict}} = \{(\mu_q, X^B_q) \in \mathcal{L}_B \mid \mu_q > \tau\}
\end{equation}

这一筛选过程实质上是一种基于统计显著性的特征选择（Feature Selection）操作，确保只有那些与A方数据有足够强相关关系的B方特征被纳入预测范围。这种策略不仅降低了计算复杂度，而且通过过滤低相关特征减少了噪声干扰，提高了后续预测的准确性。从信息论角度看，筛选过程可以理解为保留了互信息（Mutual Information）较高的特征对，最大化了跨方数据之间的信息传递效率。

相关性阈值$\tau$的选择不是任意的，而是基于数据特性和任务需求的统计量。在实际应用中，可以通过假设检验方法确定统计显著性的$\tau$值，或通过交叉验证等方法从一系列候选值中选择最优$\tau$。不同的$\tau$取值会导致$\mathcal{L}_B^{\text{predict}}$包含不同数量的特征，从而影响算法的执行效率和预测精度。

步骤2：特征级联邦数据生成

算法接下来对每个满足相关性筛选条件的特征列$(\mu_q, X^B_q) \in \mathcal{L}_B^{\text{predict}}$执行迭代预测，这对应伪代码中的循环结构（2-7行）。

对于每个特征列，算法首先进行数据分区操作，将B方特征列$X^B_q$的预测数据划分为两部分：

对齐部分：$X_{al}^{B_{predict}} = \{x_{i}^{B_{predict}}\}_{i=1}^{n_{al}} \in \mathbb{R}^{n_{al}}$，对应于A方对齐样本的B方特征值。这部分数据在B方是已知的，可以直接用于模型训练的标签。

未对齐部分：$X_{nl}^{B_{predict}} = \{x_{i}^{B_{predict}}\}_{i=n_{al}+1}^{n_{al}+n_{nl}} \in \mathbb{R}^{n_{nl}}$，需要通过联邦学习方法进行预测。这部分是算法的预测目标。

这种数据分区方式与A方数据结构$\{X_{al}^A, X_{nl}^A\}$保持一致，确保了后续联邦建模过程中样本索引的对应关系，便于模型学习样本间的映射规律。在实现层面，这种一致性设计简化了代码架构，提高了系统的可维护性和扩展性。

随后，算法调用VFPU-M方法进行联邦预测建模，这是算法的核心功能调用：

\begin{equation}
	p = \text{VFPU-M}(X_{al}^A, X_{nl}^A, X_{al}^{B_{predict}}, X_{nl}^{B_{predict}}, X^B_q)
\end{equation}

在这个函数调用中：$X_{al}^A$和$X_{nl}^A$是A方的对齐和非对齐特征数据，作为预测模型的输入特征；$X_{al}^{B_{predict}}$是B方已知的特征值，作为训练模型的标签；$X_{nl}^{B_{predict}}$是需要预测的B方未对齐特征，在函数调用时可能为空值或初始化值，但会在函数执行过程中被填充为预测结果；$X^B_q$是当前处理的B方特征列，提供了预测任务的目标信息。

VFPU-M函数返回的$p$是预测结果向量，即对$X_{nl}^{B_{predict}}$的估计值。这个预测过程实现了从A方特征空间到B方单个特征的映射学习，是算法的核心预测环节。

步骤3：数据合成与迭代构建

获得预测结果向量$p$后，算法将其合并至目标数据集$X^{B_{predict}}$：

\begin{equation}
	X^{B_{predict}} = X^{B_{predict}} \cup \{p\}
\end{equation}

这一操作逐列构建了B方预测数据矩阵，每次迭代都增加一个新的特征列，直到所有满足相关性条件的特征都被预测完毕。这种逐列构建的策略使得算法能够针对每个特征的特性采用最适合的预测模型，而不是使用一个通用模型预测所有特征，从而提高了预测精度。

通过完整的特征迭代过程，算法最终生成完整的B方预测数据矩阵：

\begin{equation}
	X^{B_{predict}} \in \mathbb{R}^{(n_{al}+n_{nl}) \times |\mathcal{L}_B^{\text{predict}}|}
\end{equation}

其中$|\mathcal{L}_B^{\text{predict}}|$表示通过相关性筛选的B方特征数量。这个矩阵不仅保留了与A方数据的统计相关性，同时也符合纵向联邦学习的隐私保护约束，可以有效地补充B方的缺失数据，扩大可用的联合样本规模。

(2) 算法4-2：VFPU-M算法

算法4-2详细阐述了VFPU-M（Vertical Federated Positive-Unlabeled Learning with Multi-task）算法的实现过程。这是一种面向半监督联邦学习的创新方法，通过迭代伪标签生成和模型更新，实现对无标签数据的高效利用。该算法的输入参数包括：A方数据：$X_{al}^A \in \mathbb{R}^{n_{al} \times d_A}$和$X_{nl}^A \in \mathbb{R}^{n_{nl} \times d_A}$，分别表示A方的对齐和非对齐特征数据；B方数据：$X_{al}^B \in \mathbb{R}^{n_{al}}$和$X_{nl}^B \in \mathbb{R}^{n_{nl}}$，分别表示B方的对齐特征值和需要预测的非对齐特征；标签向量：$y \in \mathbb{R}^{n_{al}}$或$y \in \{0,1,2,...,C-1\}^{n_{al}}$，表示对齐样本的真实标签，可能是连续值（回归任务）或离散类别（分类任务）；置信度阈值：$\alpha \in [0,1]$，用于筛选高置信度预测结果，控制伪标签的质量；迭代次数：$T \in \mathbb{N}^+$，算法执行的最大迭代轮数。；选取比例：$k \in (0,1]$，每轮从高置信度样本中选取的比例，用于控制伪标签样本的增长速度。该算法的执行步骤如下:

\vspace{-0.2cm}
\begin{table}[h]
	\centering
	\renewcommand{\arraystretch}{0.6}
	{\songti \wuhao
		\begin{tabular}{p{\textwidth}}
			\toprule[1.5pt]
			\makecell[l]{\songti\wuhao 算法 4-2 VFPU-M 算法} \\
			\midrule[0.5pt]
			\makecell[l]{\wuhao \textbf{输入:} $X_{al}^A$, $X_{nl}^A$: 参与方A的对齐/非对齐数据; $X_{al}^B$, $X_{nl}^B$: 参与方B的对齐/非对齐数据; } \\
			\makecell[l]{\wuhao \qquad $y$: 标签; $\alpha$: 置信度阈值; $T$: 迭代次数; $k$: 选取比例} \\
			\makecell[l]{\wuhao \textbf{输出:} $\mathbf{y}^{\text{pseudo}}$} \\
			\makecell[l]{\wuhao 1: $\mathcal{D}_{L}^{(0)} = \{X_{al}^A, X_{al}^B, y\}$, 
				$\mathcal{D}_{U}^{(0)} = \{X_{nl}^A, X_{nl}^B\}$} \\
			\makecell[l]{\wuhao 2: \textbf{for} $t = 1$ \textbf{to} $T$ \textbf{do}} \\
			\makecell[l]{\wuhao 3: \quad $\theta^{(t)} \leftarrow \arg\min_\theta \sum_{(\mathbf{x}^A,\mathbf{x}^B,y)\in\mathcal{D}_L^{(t)}} \ell(f_\theta(\mathbf{x}^A,\mathbf{x}^B), y)$} \\
			\makecell[l]{\wuhao 4: \quad 对 $\forall (\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{D}_U^{(t)}$，计算置信度:
				$s_j = \begin{cases} 
					\max_{c} \mathbbm{P}(y=c|f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)) & \text{分类} \\
					1 - \frac{|\hat{y}_j - \mu_t|}{\sigma_t} & \text{回归}
				\end{cases}$} \\
			\makecell[l]{\wuhao 5: \quad $\mathcal{C}^{(t)} = \{(\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{D}_U^{(t)} | s_j \geq \alpha\}$; } \\
			\makecell[l]{\wuhao 6: \quad 按置信度排序选取前 $k$ 比例: $\mathcal{S}^{(t)} = \text{TopK}(\mathcal{C}^{(t)}, k)$}\\
			\makecell[l]{\wuhao 7: \quad $\forall (\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{S}^{(t)}, \hat{y}_j = \begin{cases}
					\arg\max_c P(y=c|f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)) & \text{分类} \\
					f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j) & \text{回归}
				\end{cases}$} \\
			\makecell[l]{\wuhao 8: \quad $\mathcal{D}_L^{(t+1)} \leftarrow \mathcal{D}_L^{(t)} \cup \{(\mathbf{x}^A_j,\mathbf{x}^B_j,\hat{y}_j)\}_{j\in\mathcal{S}^{(t)}}$; 
				$\mathcal{D}_U^{(t+1)} \leftarrow \mathcal{D}_U^{(t)} \setminus \mathcal{S}^{(t)}$} \\
			\makecell[l]{\wuhao 9: \textbf{end for}} \\
			\makecell[l]{\wuhao 10: $\mathbf{y}^{\text{pseudo}} = \left[ y, \bigcup_{t=1}^{T} \{\hat{y}_j\}_{j \in \mathcal{S}^{(t)}} \right]$} \\
			\makecell[l]{\wuhao 11: \textbf{return} $\mathbf{y}^{\text{pseudo}}$} \\		\toprule[1.5pt]
		\end{tabular}
	}
	\label{tab:algo-vfpu-m} 
\end{table}
\vspace{-0.5cm}


步骤1：初始化数据集

算法首先将数据集划分为有标签数据集和无标签数据集：
\begin{align}
	\mathcal{D}_{L}^{(0)} &= \{X_{al}^A, X_{al}^B, y\} \\
	\mathcal{D}_{U}^{(0)} &= \{X_{nl}^A, X_{nl}^B\}
\end{align}

这里的有标签数据集$\mathcal{D}_{L}^{(0)}$包含了A方和B方的对齐样本及其标签，而无标签数据集$\mathcal{D}_{U}^{(0)}$则包含了需要预测标签的非对齐样本。这种初始划分将半监督学习问题形式化为一个迭代扩展的监督学习过程，为后续的伪标签生成奠定了基础。

步骤2：迭代训练过程

VFPU-M算法的核心是一个迭代过程，每轮迭代包括模型训练、置信度评估、样本筛选和数据集更新四个主要步骤。具体来说：

模型训练：

在每轮迭代$t$中，算法首先使用当前有标签数据集$\mathcal{D}_L^{(t)}$训练联邦学习模型，优化模型参数$\theta^{(t)}$：

\begin{equation}
	\theta^{(t)} \leftarrow \arg\min_\theta \sum_{(x^A,x^B,y)\in\mathcal{D}_L^{(t)}} \ell(f_\theta(x^A,x^B), y)
\end{equation}

这个优化过程中，损失函数$\ell(\cdot)$根据任务类型选择：
- 对于分类任务，通常使用交叉熵损失：$\ell(f_\theta(x^A,x^B), y) = -\sum_{c=0}^{C-1} \mathbb{I}(y=c) \log(P(y=c|f_\theta(x^A,x^B)))$，其中$\mathbb{I}(\cdot)$是指示函数。
- 对于回归任务，通常使用均方误差：$\ell(f_\theta(x^A,x^B), y) = (f_\theta(x^A,x^B) - y)^2$。

联邦学习模型$f_\theta$可以是多种形式，如线性模型、决策树或神经网络等，根据具体任务特性选择。在联邦环境下，模型训练遵循联邦学习的privacy-by-design原则，即各方保留原始数据，只交换必要的模型参数或梯度信息。

置信度评估：

训练完成后，算法使用更新后的模型$f_{\theta^{(t)}}$对无标签数据集$\mathcal{D}_U^{(t)}$中的每个样本$(x^A_j,x^B_j)$进行预测，并计算置信度分数$s_j$。

对于分类任务，置信度定义为最高类别概率：

\begin{equation}
	s_j = \max_{c} \mathbb{P}(y=c|f_{\theta^{(t)}}(x^A_j,x^B_j))
\end{equation}

这个公式衡量了模型对样本分类的确定性，概率值越高表示模型对预测结果越有信心。例如，如果模型预测某样本属于类别0的概率为0.9，属于类别1的概率为0.1，则该样本的置信度分数为0.9。

对于回归任务，置信度通过预测值与当前标签分布的距离定义：

\begin{equation}
	s_j = 1 - \frac{|\hat{y}_j - \mu_t|}{\sigma_t}
\end{equation}

其中$\hat{y}_j = f_{\theta^{(t)}}(x^A_j,x^B_j)$是模型预测值，$\mu_t$和$\sigma_t$分别是当前训练集标签的均值和标准差。这个公式基于统计学原理，将预测值转换为标准化得分，反映了预测结果与标签分布中心的接近程度。具体来说，$\frac{|\hat{y}_j - \mu_t|}{\sigma_t}$计算了预测值的Z分数（绝对值），再用1减去该值得到置信度，使得预测值越接近分布中心，置信度越高。

样本筛选：

基于计算的置信度，算法筛选出置信度高于阈值$\alpha$的样本集合：

\begin{equation}
	\mathcal{C}^{(t)} = \{(x^A_j,x^B_j) \in \mathcal{D}_U^{(t)} | s_j \geq \alpha\}
\end{equation}

这一步骤实现了对预测结果的初步质量控制，只保留那些模型有充分信心的预测结果。置信度阈值$\alpha$是一个关键参数，其取值需要在保证伪标签质量和利用足够无标签样本之间取得平衡：
- 较高的$\alpha$值会提高伪标签的质量，但可能导致可用样本过少；
- 较低的$\alpha$值会增加伪标签样本数量，但可能引入更多错误标签。

为了进一步提高伪标签的质量，算法不是直接使用所有符合阈值的样本，而是按照置信度从高到低排序，选取前$k$比例的高置信度样本：

\begin{equation}
	\mathcal{S}^{(t)} = \text{TopK}(\mathcal{C}^{(t)}, k)
\end{equation}

其中$\text{TopK}$函数表示从集合$\mathcal{C}^{(t)}$中选择置信度最高的前$k$比例样本。这一操作实现了"置信度优先"的样本选择策略，确保每轮迭代中只有预测最可靠的样本被用于模型更新，从而降低错误累积的风险。

伪标签生成与数据集更新：

对于筛选出的高置信度样本$(x^A_j,x^B_j) \in \mathcal{S}^{(t)}$，算法生成相应的伪标签$\hat{y}_j$：

对于分类任务：
\begin{equation}
	\hat{y}_j = \arg\max_c P(y=c|f_{\theta^{(t)}}(x^A_j,x^B_j))
\end{equation}

这一公式选择概率最高的类别作为伪标签，实现了硬标签分配。例如，如果模型预测某样本属于类别0的概率为0.9，属于类别1的概率为0.1，则该样本的伪标签为类别0。

对于回归任务：

\begin{equation}
	\hat{y}_j = f_{\theta^{(t)}}(x^A_j,x^B_j)
\end{equation}

这一公式直接使用模型的预测值作为伪标签，适用于连续值预测场景。

生成伪标签后，算法更新有标签和无标签数据集：

\begin{align}
	\mathcal{D}_L^{(t+1)} &\leftarrow \mathcal{D}_L^{(t)} \cup \{(x^A_j,x^B_j,\hat{y}_j)\}_{j\in\mathcal{S}^{(t)}} \\
	\mathcal{D}_U^{(t+1)} &\leftarrow \mathcal{D}_U^{(t)} \setminus \mathcal{S}^{(t)}
\end{align}


这一更新过程将高置信度样本从无标签数据集移到有标签数据集，使得已标记数据集规模随着迭代过程不断扩大，为后续的模型训练提供更多的监督信号。同时，无标签数据集规模相应减小，逐步聚焦于那些难以预测的样本。

最终输出：

经过$T$轮迭代后，算法输出最终的伪标签集合：

\begin{equation}
	\mathbf{y}^{\text{pseudo}} = \left[ y, \bigcup_{t=1}^{T} \{\hat{y}_j\}_{j \in \mathcal{S}^{(t)}} \right]
\end{equation}


这个集合包含了原始标签$y$和所有迭代过程中生成的高置信度伪标签$\{\hat{y}_j\}_{j \in \mathcal{S}^{(t)}}$，构成了完整的预测结果向量，可用于后续的联邦学习任务。


\subsection{生成模型与纵向联邦半监督学习的协同框架}

如图 \ref{fig: FedPSG-PUM } 所示，在完纵向联邦半监督方法预测数据后，研究工作进入Process III阶段。为更好地应对A方特征与B方特征间低相关性（即$\mu_q \leq \tau$）场景中的预测挑战，FedPSG-PUM方法创新性地引入了生成模型技术，构建了一个半监督学习与生成模型协同的混合架构。这一设计本质上是一种"分而治之"（Divide and Conquer）策略，针对不同相关性水平的特征采用最适合的生成方法。

对于特征集合$X^B = \{X^B_1, X^B_2, ..., X^B_{m_B}\}$，基于相关性强度$\{\mu_q\}_{q=1}^{m_B}$将其划分为两个子集：

$$
X^B_{high} = \{X^B_q | \mu_q > \tau\}
X^B_{low} = \{X^B_q | \mu_q \leq \tau\}
$$

对于高相关性特征集$X^B_{high}$，采用VFPU-M方法进行预测；对于低相关性特征集$X^B_{low}$，则采用生成模型技术进行合成。这种混合策略的理论依据是：
- 对于与A方特征高度相关的B方特征，基于统计关系的半监督学习方法更为有效；
- 对于相关性较低的特征，直接预测的准确性有限，而生成模型可以通过学习B方内部特征之间的依赖关系，生成更符合实际分布的合成数据。

在B方本地，系统训练多种先进的生成模型，包括：

1. CTGAN（Conditional Tabular GAN）：条件表格生成对抗网络，引入条件向量和模式编码，专为处理混合类型表格数据设计，其目标函数为：

$\min_G \max_D \mathbb{E}_{x \sim P_{data}}[\log D(x)] + \mathbb{E}_{z \sim P_z, c \sim P_c}[\log(1 - D(G(z, c)))]$

其中$G$和$D$分别是生成器和判别器，$z$是随机噪声，$c$是条件向量，$P_{data}$、$P_z$和$P_c$分别是真实数据分布、噪声分布和条件分布。

2. TableGAN：针对表格数据的生成对抗网络，通过辅助分类器和信息损失，保持列间的相关性，优化目标为：

$\min_G \max_D \mathcal{L}_{GAN} + \lambda_1 \mathcal{L}_{AC} + \lambda_2 \mathcal{L}_{info}$

其中$\mathcal{L}_{GAN}$是标准GAN损失，$\mathcal{L}_{AC}$是辅助分类器损失，$\mathcal{L}_{info}$是信息损失，$\lambda_1$和$\lambda_2$是平衡参数。

3. CTABGAN（Conditional Table GAN）：增强版条件表格生成对抗网络，通过改进的条件向量设计和训练策略，提高了对复杂模式的捕获能力。

4. VAE（Variational Autoencoder）：变分自编码器，通过隐变量的概率分布建模数据生成过程，优化目标是变分下界（ELBO）：

$\mathcal{L}_{ELBO} = \mathbb{E}_{q_\phi(z|x)}[\log p_\theta(x|z)] - D_{KL}(q_\phi(z|x) || p(z))$

其中$q_\phi(z|x)$是编码器网络，$p_\theta(x|z)$是解码器网络，$p(z)$是先验分布，$D_{KL}$是KL散度。

5. TabDDPM（Tabular Denoising Diffusion Probabilistic Model）：表格数据扩散概率模型，通过定义一个从数据到噪声的马尔可夫链，再反向从噪声生成数据，其训练目标是：

$\mathcal{L} = \mathbb{E}_{x_0, \epsilon, t}[||\epsilon - \epsilon_\theta(x_t, t)||^2]$

其中$x_0$是原始数据，$x_t$是添加噪声后的数据，$\epsilon$是添加的噪声，$\epsilon_\theta$是噪声预测网络，$t$是扩散步骤。

除此之外，系统还可以采用专门针对缺失值填补设计的模型：

1. GAIN（Generative Adversarial Imputation Network）：生成对抗填补网络，通过对抗训练框架填补缺失值，其目标函数为：

$\min_G \max_D \mathbb{E}[\log D(X, M) + \log(1 - D(G(X, M), M))] + \lambda \mathbb{E}[||G(X, M) \odot (1-M) - X \odot (1-M)||^2]$

其中$X$是包含缺失值的数据，$M$是缺失值掩码，$G$是生成器，$D$是判别器，$\lambda$是平衡参数。

2. VGAIN（Variational GAIN）：变分生成对抗填补网络，结合VAE和GAN的优点，通过概率建模提高填补的稳定性和准确性。

3. VF\_GAIN（Vertical Federated GAIN）：适用于联邦环境的变分生成对抗填补网络，在保护数据隐私的前提下，协作完成缺失值填补。

这些生成技术与VFPU-M预测方法形成互补，共同提高数据补全的质量。整个系统的工作流程可以概括为：

1. 基于相关性阈值$\tau$，划分B方特征为高相关性特征集$X^B_{high}$和低相关性特征集$X^B_{low}$。
2. 对于$X^B_{high}$中的每个特征$X^B_q$，采用VFPU-M方法生成预测值。
3. 对于$X^B_{low}$中的特征，在B方本地训练生成模型，并使用训练好的模型生成合成数据。
4. 将两部分生成的数据合并，形成完整的B方预测数据矩阵$X^{B_{predict}}$。

这种协同框架充分利用了不同方法的优势，显著提高了生成数据的质量和可靠性。从理论上讲，当特征间相关性较高时，基于统计关系的半监督学习方法能够提供更精确的预测；而当相关性较低时，生成模型通过学习数据的内在分布，能够产生更符合实际分布的合成数据。这种互补性使得FedPSG-PUM方法能够在各种相关性条件下均保持良好的性能。

通过上述技术的有机结合，FedPSG-PUM方法构建了一个全面的纵向联邦样本生成框架，能够在保护数据隐私的同时，高效解决纵向联邦学习中的特征缺失问题，为构建高质量的联合样本集提供了坚实的理论基础和技术支持。

