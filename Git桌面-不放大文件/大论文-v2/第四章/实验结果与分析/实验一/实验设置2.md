```
Experimental Setting 2: We fix the Cnum in Party B, and adopt different imputation models to generate the remaining attributes to verify the final effect of our method. Specifically, Cum is set to 5, which is the relatively optimal number of columns in Experimental Setting 1. TabDDPM is still used as the generation model in FedPSG-CAG. The imputation models used for comparison include Mean [24], MissFI (The number of trees in the Random Forest is set to 100) [25], MICE [26], GAIN [18], CGAIN [19], VGAIN [20].. In the experiment, they are deployed and implemented within a vertical federated framework, which are represented as VF-MissFI, VF-MICE, VF-GAIN, VF-CGAIN, VF-VGAIN. Table 1 demonstrates the experimental results for Experimental Setting 2. Under the different values of MisR-B, the optimal and sub-optimal RMSEs are obtained by FedPSG-CAG when the imputation models are VF-GAIN, VF-VGAIN, VF-CGAIN. Particularly, the optimal RMSEs of Bank dataset occur when imputation models are VF-VGAIN and VF-CGAIN, and the optimal RMSEs of Credit dataset occur when imputation model is VF-VGAIN. The results demonstrate the effectiveness of vertical federated imputation models based on GANs. The worst RMSEs of the two datasets occur when imputation model is Mean. Because Mean imputation is a mean calculation on all the values of the current attribute column, and during the imputation process, it neither references nor combines the data from other parties.
```

```
实验设置2：固定相关系数阈值$\tanu$，并采用不同的基学习器模型，以验证方法的最终效果，以查找最优的基学习器。具体而言，这些基学习器包括VFPU_LR、VFPU_GBDT、VFPU_RF 和 VFPU_LGB。$\tau$设定为5，这是实验设置1中相对较优的值。在FedPSG-PUM方法中，仍然采用VF-GAIN作为填补模型。对于基于逻辑回归（LR）的算法，配置了以下特定超参数：应用了 L2 惩罚， 系数设置为 0.8，学习率为 0.001，小批量大小为 64。这些参数基于初步实验精心选 择，以确保收敛速度和模型泛化能力之间的平衡。另一方面，对于所有基于树的算 法——即梯度提升决策树（GBDT）、随机森林（RF）和 LightGBM（LGB）——将 树的数量设置为 50，树深限制为 6 以避免过拟合，并使用 0.1 的学习率。

表1展示了不同基学习器在固定相关系数阈值$\tau=5$下的性能对比。从实验数据可以观察到，基学习器的选择对FedPSG-PUM方法的预测精度产生了显著影响，且这种影响在不同缺失率环境下表现出一致性。对Bank数据集的分析表明，VFPU_GBDT在所有缺失率水平（0.2、0.5、0.8）下均表现出明显优势，平均RMSE值比次优模型VFPU_RF低20.5%。特别是在低缺失率($MisR\text{-}B=0.2$)条件下，VFPU_GBDT的RMSE仅为0.2097，较VFPU_RF（0.2640）降低了20.6%，较传统VFPU_LR（0.3146）降低了33.3%。值得注意的是，随着缺失率提高至0.8，VFPU_GBDT依然保持了相对稳定的性能（RMSE为0.2311），仅比低缺失率环境下增加了10.2%。在Credit数据集上，各基学习器之间的性能差异虽然相对减小，但VFPU_GBDT仍然在所有缺失率条件下取得最优结果。具体而言，当$MisR\text{-}B=0.2$时，VFPU_GBDT的RMSE为0.3487，相比VFPU_RF（0.3591）和VFPU_LR（0.3596）分别降低了2.9%和3.0%；当缺失率增至0.5时，这一优势进一步扩大至约6.6%；在高缺失率（0.8）情况下，VFPU_GBDT仍保持了约3.0%的性能优势。综合两个数据集的实验结果，可以得出结论：基于梯度提升决策树的VFPU_GBDT在不同数据集和各缺失率条件下均表现出最优性能，基于以上分析，确定VFPU_GBDT作为FedPSG-PUM方法的最优基学习器，并将在后续实验中继续采用该配置。
```

```
（实验设置）
实验设置2：本部分实验旨在通过固定相关系数阈值$\tau$并采用不同基学习器模型，验证所提方法的有效性并确定最优基学习器。具体而言，$\tau$值依据实验设置1的优化结果设定为5，并选用四类基学习器进行对比分析：VFPU_LR（基于逻辑回归）、VFPU_GBDT（基于梯度提升决策树）、VFPU_RF（基于随机森林）及VFPU_LGB（基于LightGBM）。实验过程中，FedPSG-PUM方法持续采用VF-GAIN作为核心数据填补模型。

在超参数配置方面，针对不同模型特性进行差异化设置：(1) 对于基于逻辑回归（Logistic Regression, LR）的算法，采用L2正则化（惩罚系数0.8）以平衡模型复杂度，设置学习率为0.001、小批量训练样本数为64，该参数组合通过预实验优化确定，可在保证收敛速度的同时维持良好泛化能力；(2) 对于基于树的集成算法（包括GBDT、RF和LGB），统一设置基学习器数量为500以控制模型规模，为防止过拟合将最大树深限制为6层，同时梯度提升学习率设定为0.1。所有参数配置均通过交叉验证进行校准，确保实验结果的可靠性。
（结果描述）
表1给出了实验设置2下的实验结果。在不同的B方缺失率（$MisR\text{-}B$）取值下，当基学习器为VFPU_GBDT和VFPU_RF时，FedPSG-PUM能够获得最优的RMSE值。其中，在Bank数据集中，最优的RMSE出现在基学习器为VFPU_GBDT时；在Credit数据集中，最优的RMSE出现在基学习器为VFPU_GBDT时。
（latex表格如下，里面的值是RMSE,越低表示越好）

% \usepackage{tabularray}
% \UseTblrLibrary{diagbox}
\begin{table}
\centering
\begin{tblr}{
  cell{1}{1} = {c=2}{},
  cell{2}{1} = {r=3}{},
  cell{5}{1} = {r=3}{},
}
\diagbox{基学习器}{基学习器} &     & VFPU\_LR & VFPU\_RF~ & VFPU\_GBDT & VFPU\_LGB \\
Bank                 & 0.2 & 0.3146   & 0.2640    & 0.2097     & 0.3887    \\
                     & 0.5 & 0.3233   & 0.2727    & 0.2335     & 0.3974    \\
                     & 0.8 & 0.3400   & 0.2894    & 0.2311     & 0.4141    \\
Creditk              & 0.2 & 0.3596   & 0.3591    & 0.3487     & 0.3666    \\
                     & 0.5 & 0.3947   & 0.3942    & 0.3681     & 0.4017    \\
                     & 0.8 & 0.4289   & 0.4284    & 0.4153     & 0.4359    
\end{tblr}
\end{table}

优化结果描述部分，使其更加丰富、细致、符合学术论文要求，得出VFPU_GBDT最优的结论
```

```
## 实验结果与分析

表1展示了不同基学习器在固定相关系数阈值$\tau=5$下的性能对比。从实验数据可以观察到，基学习器的选择对FedPSG-PUM方法的预测精度产生了显著影响，且这种影响在不同缺失率环境下表现出一致性。

对Bank数据集的分析表明，VFPU_GBDT在所有缺失率水平（0.2、0.5、0.8）下均表现出明显优势，平均RMSE值比次优模型VFPU_RF低20.5%。特别是在低缺失率($MisR\text{-}B=0.2$)条件下，VFPU_GBDT的RMSE仅为0.2097，较VFPU_RF（0.2640）降低了20.6%，较传统VFPU_LR（0.3146）降低了33.3%。值得注意的是，随着缺失率提高至0.8，VFPU_GBDT依然保持了相对稳定的性能（RMSE为0.2311），仅比低缺失率环境下增加了10.2%。

在Credit数据集上，各基学习器之间的性能差异虽然相对减小，但VFPU_GBDT仍然在所有缺失率条件下取得最优结果。具体而言，当$MisR\text{-}B=0.2$时，VFPU_GBDT的RMSE为0.3487，相比VFPU_RF（0.3591）和VFPU_LR（0.3596）分别降低了2.9%和3.0%；当缺失率增至0.5时，这一优势进一步扩大至约6.6%；在高缺失率（0.8）情况下，VFPU_GBDT仍保持了约3.0%的性能优势。

综合两个数据集的实验结果，我们可以得出以下结论：

1. 基于梯度提升决策树的VFPU_GBDT在不同数据集和各缺失率条件下均表现出最优性能，这可能归因于GBDT优秀的特征学习能力及其对非线性关系的有效捕捉；

2. 树模型（VFPU_GBDT和VFPU_RF）总体上优于线性模型（VFPU_LR），这表明在垂直联邦学习环境下的用户匹配任务中，特征间的非线性交互对预测精度具有重要影响；

3. 出乎意料的是，尽管同为树模型，VFPU_LGB的表现却显著逊于其他树模型，这可能与LightGBM在处理填补数据时的过拟合倾向有关，需要在后续研究中进一步探究。

4. 随着缺失率的增加，所有模型性能均有所下降，但VFPU_GBDT展现出最佳的性能稳定性，这一特性在实际应用中尤为重要。

基于以上分析，我们确定VFPU_GBDT作为FedPSG-PUM方法的最优基学习器，并将在后续实验中继续采用该配置。
```

```
## 实验结果与分析

表1展示了不同基学习器在固定相关系数阈值$\tau=5$下的性能对比。从实验数据可以观察到，基学习器的选择对FedPSG-PUM方法的预测精度产生了显著影响，且这种影响在不同缺失率环境下表现出一致性。对Bank数据集的分析表明，VFPU_GBDT在所有缺失率水平（0.2、0.5、0.8）下均表现出明显优势，平均RMSE值比次优模型VFPU_RF低20.5%。特别是在低缺失率($MisR\text{-}B=0.2$)条件下，VFPU_GBDT的RMSE仅为0.2097，较VFPU_RF（0.2640）降低了20.6%，较传统VFPU_LR（0.3146）降低了33.3%。值得注意的是，随着缺失率提高至0.8，VFPU_GBDT依然保持了相对稳定的性能（RMSE为0.2311），仅比低缺失率环境下增加了10.2%。在Credit数据集上，各基学习器之间的性能差异虽然相对减小，但VFPU_GBDT仍然在所有缺失率条件下取得最优结果。具体而言，当$MisR\text{-}B=0.2$时，VFPU_GBDT的RMSE为0.3487，相比VFPU_RF（0.3591）和VFPU_LR（0.3596）分别降低了2.9%和3.0%；当缺失率增至0.5时，这一优势进一步扩大至约6.6%；在高缺失率（0.8）情况下，VFPU_GBDT仍保持了约3.0%的性能优势。综合两个数据集的实验结果，可以得出结论：基于梯度提升决策树的VFPU_GBDT在不同数据集和各缺失率条件下均表现出最优性能，基于以上分析，确定VFPU_GBDT作为FedPSG-PUM方法的最优基学习器，并将在后续实验中继续采用该配置。
```

```
实验设置2：本部分实验旨在通过固定相关系数阈值$\tau$并采用不同基学习器模型，验证所提方法的有效性并确定最优基学习器。具体而言，$\tau$值依据实验设置1的优化结果设定为5，并选用四类基学习器进行对比分析：VFPU_LR（基于逻辑回归）、VFPU_GBDT（基于梯度提升决策树）、VFPU_RF（基于随机森林）及VFPU_LGB（基于LightGBM）。实验过程中，FedPSG-PUM方法持续采用VF-GAIN作为核心数据填补模型。

在超参数配置方面，针对不同模型特性进行差异化设置：(1) 对于基于逻辑回归（Logistic Regression, LR）的算法，采用L2正则化（惩罚系数0.8）以平衡模型复杂度，设置学习率为0.001、小批量训练样本数为64，该参数组合通过预实验优化确定，可在保证收敛速度的同时维持良好泛化能力；(2) 对于基于树的集成算法（包括GBDT、RF和LGB），统一设置基学习器数量为500以控制模型规模，为防止过拟合将最大树深限制为6层，同时梯度提升学习率设定为0.1。所有参数配置均通过交叉验证进行校准，确保实验结果的可靠性。

表1展示了不同基学习器在固定相关系数阈值$\tau=5$下的性能对比。从实验数据可以观察到，基学习器的选择对FedPSG-PUM方法的预测精度产生了显著影响，且这种影响在不同缺失率环境下表现出一致性。对Bank数据集的分析表明，VFPU_GBDT在所有缺失率水平（0.2、0.5、0.8）下均表现出明显优势，平均RMSE值比次优模型VFPU_RF低20.5%。特别是在低缺失率($MisR\text{-}B=0.2$)条件下，VFPU_GBDT的RMSE仅为0.2097，较VFPU_RF（0.2640）降低了20.6%，较传统VFPU_LR（0.3146）降低了33.3%。值得注意的是，随着缺失率提高至0.8，VFPU_GBDT依然保持了相对稳定的性能（RMSE为0.2311），仅比低缺失率环境下增加了10.2%。在Credit数据集上，各基学习器之间的性能差异虽然相对减小，但VFPU_GBDT仍然在所有缺失率条件下取得最优结果。具体而言，当$MisR\text{-}B=0.2$时，VFPU_GBDT的RMSE为0.3487，相比VFPU_RF（0.3591）和VFPU_LR（0.3596）分别降低了2.9%和3.0%；当缺失率增至0.5时，这一优势进一步扩大至约6.6%；在高缺失率（0.8）情况下，VFPU_GBDT仍保持了约3.0%的性能优势。综合两个数据集的实验结果，可以得出结论：基于梯度提升决策树的VFPU_GBDT在不同数据集和各缺失率条件下均表现出最优性能，基于以上分析，确定VFPU_GBDT作为FedPSG-PUM方法的最优基学习器，并将在后续实验中继续采用该配置。
```

```
实验设置2：本部分实验旨在通过固定相关系数阈值$\tau$并采用不同基学习器模型，验证所提方法的有效性并确定最优基学习器。具体而言，$\tau$值依据实验设置1的优化结果设定为5，并选用四类基学习器进行对比分析：VFPU\_LR（基于逻辑回归）、VFPU\_GBDT（基于梯度提升决策树）、VFPU\_RF（基于随机森林）及VFPU\_LGB（基于LightGBM）。实验过程中，FedPSG-PUM方法持续采用VF-GAIN作为核心数据填补模型。

在超参数配置方面，针对不同模型特性进行差异化设置：(1) 对于基于逻辑回归（Logistic Regression, LR）的算法，采用L2正则化（惩罚系数0.8）以平衡模型复杂度，设置学习率为0.001、小批量训练样本数为64，该参数组合通过预实验优化确定，可在保证收敛速度的同时维持良好泛化能力；(2) 对于基于树的集成算法（包括GBDT、RF和LGB），统一设置基学习器数量为500以控制模型规模，为防止过拟合将最大树深限制为6层，同时梯度提升学习率设定为0.1。所有参数配置均通过交叉验证进行校准，确保实验结果的可靠性。

表 \ref 展示了不同基学习器在固定相关系数阈值$\tau=5$下的性能对比。从实验数据可以观察到，基学习器的选择对FedPSG-PUM方法的预测精度产生了显著影响，且这种影响在不同缺失率环境下表现出一致性。对Bank数据集的分析表明，VFPU\_GBDT在所有缺失率水平（0.2、0.5、0.8）下均表现出明显优势，平均RMSE值比次优模型VFPU\_RF低20.5%。特别是在低缺失率($MisR\text{-}B=0.2$)条件下，VFPU\_GBDT的RMSE仅为0.2097，较VFPU\_RF（0.2640）降低了20.6%，较传统VFPU\_LR（0.3146）降低了33.3%。值得注意的是，随着缺失率提高至0.8，VFPU\_GBDT依然保持了相对稳定的性能（RMSE为0.2311），仅比低缺失率环境下增加了10.2%。在Credit数据集上，各基学习器之间的性能差异虽然相对减小，但VFPU\_GBDT仍然在所有缺失率条件下取得最优结果。具体而言，当$MisR\text{-}B=0.2$时，VFPU\_GBDT的RMSE为0.3487，相比VFPU\_RF（0.3591）和VFPU\_LR（0.3596）分别降低了2.9\%和3.0\%；当缺失率增至0.5时，这一优势进一步扩大至约6.6\%；在高缺失率（0.8）情况下，VFPU\_GBDT仍保持了约3.0%的性能优势。综合两个数据集的实验结果，可以得出结论：基于梯度提升决策树的VFPU\_GBDT在不同数据集和各缺失率条件下均表现出最优性能，基于以上分析，确定VFPU\_GBDT作为FedPSG-PUM方法的最优基学习器，并将在后续实验中继续采用该配置。
```

