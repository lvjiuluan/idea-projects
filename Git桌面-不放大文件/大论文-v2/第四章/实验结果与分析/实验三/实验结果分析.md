```
实验结果如图4所示，图4（a）-（f）分别表示了Bank和Credit数据集在B方样本缺少比为0.2、0.5、0.8下，构建联合样本集时不同缺少样本处理方式下，不同纵向联邦分类模型的ACC、AUC、F1 分数结果曲线。图4（a）-（f）每个子图中不同颜色的曲线表示不同的纵向联邦分类模型，横坐标表示针对B方缺少样本不同的处理方式，即：FedPSG-PUM、TabDDPM、A∞B-GM、N-GM，纵坐标表示纵向联邦分类模型在基于不同处理方式得到的联合数据集上训练后，模型在测试集上得到的ACC、AUC、F1 分数值。
如图4所示，在两个数据集的不管在何种缺少比下，采用FedPSG-PUM方法生成B方缺少样本所构建的联合样本集，不管用于VF-LR、VF-SVM、VF-GBDT、VF-RF、FinalNet哪种联邦机器学习模型的训练，其测试集的ACC、AUC、F1评估指标都是表现最为出色的。然后依次是TabDDPM、A∞B-GM、N-GM。分析出现这种结果的原因：
① 从样本数量的角度来分析，FedPSG-PUM、TabDDPM、A∞B-GM三种方式构建的联合数据集样本量相同，N-GM最少。如图4所示，在两个数据集的不管在何种缺少比下，样本量最少的N-GM方式下的联合样本集训练的纵向联邦分类模型的评估指标结果最差。这表明了联合样本量对纵向联邦机器学习模型训练的重要性。其他因素相同的情况下，样本量较大的联合样本集，训练的纵向联邦机器学习模型分类性能更好。如图4所示，我们用不同的联邦机器学习模型验证了这一结论。在同一个数据集中，随着B方缺少比的增加，N-GM方式获得的联合样本集样本量将大幅下降。当联合样本集样本量下降后，五种纵向联邦机器学习模型的评估指标值都下降了，尤其，FinalNet相对于VF-LR、VF-SVM、VF-GBDT、VF-RF的评估指标值有了更大幅度的下降。FinalNet是一种纵向联邦学习的深度学习框架。这同时也表明对于深度神经网络等复杂模型，用更多的样本量进行训练是有必要的。而本文方法提供了一种更有效解决参与方样本缺少时的联合样本量问题。
② 从样本质量的角度分析，虽然FedPSG-PUM、TabDDPM、A∞B-GM三种方式的联合样本集样本量相同，但他们的联合样本的质量却依次降低。FedPSG-PUM、TabDDPM这两种方式，A方的数据全部被保留了。比起A∞B-GM方式生成全新的联合样本，前两种方式构建的联合样本集中有更多的真实数据用于模型训练，联合样本质量更高。前两种方式中，FedPSG-PUM能够有效地学习缺少样本参与方本地高相关属性之间的数据分布，以及利用多方数据之间的关联性进行缺少样本的生成。而TabDDPM方式，缺少样本参与方的数据是由TabDDPM在B方本地生成的。这说明本文方法是解决参与方样本缺少问题的有效方法。如图4所示的实验结果验证了这一结论，也同时表示了模型的训练效果不仅仅依赖于样本量，还跟样本质量等其他因素有关。即使在B方高缺少比的情况下，本文方法也能为联合样本集提供更高质量的训练样本，更好地支持纵向联邦机器学习模型训练。如图4所示，这一结论适用于不同的机器学习模型。
```

```
过对四种样本补偿策略的横向对比分析，量化结果表明不同数据生成机制对联合样本集规模产生显著影响。具体而言，基于样本生成的FedPSG-PUM、TabDDPM与A∞B-GM三类方法均实现了完整的样本对齐：FedPSG-PUM和TabDDPM通过为B方生成与A方未对齐样本相匹配的补偿数据，使联合样本量达到A方原始样本总量；而A∞B-GM虽然采用VertiGAN生成与B方缺失量相当的合成数据，但由于其生成过程严格遵循A方样本分布特征，最终联合样本量仍由A方数据规模决定。相比之下，N-GM策略因未实施任何样本生成操作，在跨机构数据对齐过程中导致A方未匹配样本的主动丢弃，这使得其联合样本量仅保留B方原始数据规模，较其他方法减少约（具体比例需补充）%。这种现象揭示纵向联邦学习中样本生成策略与数据保留效率的内在关联：主动生成机制可有效提升跨机构样本利用率，而被动对齐策略则会造成显著的信息损失。
```



```
本研究对FedPSG-PUM、TabDDPM、A∞B-GM和N-GM四种数据处理方法生成的联合样本量进行统计分析，得出以下结论：

\begin{itemize}
    \item 基于样本生成的FedPSG-PUM、TabDDPM与A∞B-GM三类方法均实现了完整的样本对齐：FedPSG-PUM和TabDDPM通过为B方生成与A方未对齐样本相匹配的补偿数据，使联合样本量达到A方原始样本总量；而A∞B-GM虽然采用VertiGAN生成与B方缺失量相当的合成数据，但由于其生成过程严格遵循A方样本分布特征，最终联合样本量仍由A方数据规模决定。
    
    \item N-GM方法在联合数据集构建过程中表现出显著差异性。该方法采用严格样本对齐机制，当A方样本无法与B方缺失样本形成对应关系时，系统将主动丢弃A方未对齐样本。这种选择性保留机制导致最终联合样本规模受限于B方原始样本基数，因此其构建的联合数据集样本量呈现最小值，显著低于其他三种生成增强方法。
\end{itemize}

```



```
我们对FedPSG-PUM、TabDDPM、A∞B-GM、N-GM这4种处理方式得到的联合样本量进行统计和分析，有以下结论：

FedPSG-PUM、TabDDPM这两种方式是为B方相对于A方缺少的样本进行生成，使其可以与A方未对齐样本构建完整的联合样本。而A∞B-GM生成的联合样本跟B方缺少样本量相同。因此，由FedPSG-PUM，TabDDPM，A∞B-GM构建的联合样本集的样本量都是一样的，它们由A方样本数量确定。

N-GM这种处理方式构建的联合数据集中的样本量最少。因为，在N-GM方式下，当A方样本与法B方缺少的样本对齐时，在构建联合样本集时，A方未对齐样本将被丢弃。因此，N-GM方式下，联合样本集的样本数量由缺少样本生成前B方原有样本数量确定。
```

```
为系统评估FedPSG-PUM方法在数据缺失参与方样本生成方面的有效性，本研究设计如下验证方案：首先基于生成后的B方样本与A方原始样本构建联合样本集，继而开展纵向联邦学习模型的训练。通过系统比较不同缺失样本处理方式对模型性能的影响，评估所构建联合训练集在支撑不同纵向联邦分类模型训练中的有效性。

本实验构建的A-B跨机构联合样本集由以下两部分组成：A方原始数据与B方经不同生成方法补偿后的数据；双方原始数据的隐私保护对齐结果。实验设计包含三类样本生成策略：(1) 采用FedPSG-PUM方法框架实现缺失样本生成，集成VF-GAIN作为核心填补模型。该模型设置特征相关性阈值$\tau=0.6$与置信度阈值$\alpha=0.7$，基学习器选用VFPU\_GBDT算法。(2) 在B方本地部署TabDDPM模型生成缺失样本，该模型经实验2验证已达到当前生成式建模领域的SOTA性能，可作为基准生成方法进行横向对比。(3) 直接基于A、B双方原始数据进行隐私保护对齐，不进行任何样本生成操作，将这种处理B方缺少样本的方式记为“N-GM”。(4) 在N-GM生成的基准联合集基础上，采用VertiGAN[3]方法生成等量于B方缺失样本的合成数据，该方法作为当前纵向联邦样本生成领域的SOTA方法参与对比，将这种处理方式记为“A∞B-GM”。

本实验采用Bank和Credit两个基准数据集进行验证，其中B方特征缺失率设置为三个梯度（$\text{MisR-B} \in [0.2,0.5,0.8]$）。实验架构包含五类纵向联邦分类模型：逻辑回归（VF-LR）[37]、支持向量机（VF-SVM）[38]、梯度提升决策树（VF-GBDT）[39]、随机森林（VF-RF）[40]以及深度网络FinalNet[41]，涵盖参数模型与非参数模型、浅层学习与深度学习的多元技术路线。所有模型的性能通过准确率（ACC）、AUC-ROC和F1-score[42]三个指标进行综合评价，其中测试集固定为原始联合样本集的30\%，剩余70\%原始数据与不同生成方法获得的补偿数据共同构成动态训练集。各分类器的超参数经网格搜索优化后设定为：VF-LR（学习率0.01，迭代1000次，批次64）；VF-SVM（正则化参数C=1）；VF-GBDT（树数20，学习率0.1，最大深度6，子采样率0.2）；VF-RF（树数100，最大深度3，最小分裂样本2，叶节点最小样本1）；FinalNet（学习率0.001，迭代1000次，批次64，隐层维度128，L2正则系数0.0001）。

本研究对FedPSG-PUM、TabDDPM、A∞B-GM和N-GM四种数据处理方法生成的联合样本量进行统计分析，得出以下结论：

\begin{itemize}
	\item 基于样本生成的FedPSG-PUM、TabDDPM与A∞B-GM三类方法均实现了完整的样本对齐：FedPSG-PUM和TabDDPM通过为B方生成与A方未对齐样本相匹配的补偿数据，使联合样本量达到A方原始样本总量；而A∞B-GM虽然采用VertiGAN生成与B方缺失量相当的合成数据，但由于其生成过程严格遵循A方样本分布特征，最终联合样本量仍由A方数据规模决定。
	
	\item N-GM方法在联合数据集构建过程中表现出显著差异性。该方法采用严格样本对齐机制，当A方样本无法与B方缺失样本形成对应关系时，系统将主动丢弃A方未对齐样本。这种选择性保留机制导致最终联合样本规模受限于B方原始样本基数，因此其构建的联合数据集样本量呈现最小值，显著低于其他三种生成增强方法。
\end{itemize}

润色这段话，使其变得更加通顺、符合学术风格要求
【实验结果分析】
如图4所示，在两个数据集的不管在何种缺少比下，采用FedPSG-PUM方法生成B方缺少样本所构建的联合样本集，不管用于VF-LR、VF-SVM、VF-GBDT、VF-RF、FinalNet哪种联邦机器学习模型的训练，其测试集的ACC、AUC、F1评估指标都是表现最为出色的。然后依次是TabDDPM、A∞B-GM、N-GM。分析出现这种结果的原因：
① 从样本数量的角度来分析，FedPSG-PUM、TabDDPM、A∞B-GM三种方式构建的联合数据集样本量相同，N-GM最少。如图4所示，在两个数据集的不管在何种缺少比下，样本量最少的N-GM方式下的联合样本集训练的纵向联邦分类模型的评估指标结果最差。这表明了联合样本量对纵向联邦机器学习模型训练的重要性。其他因素相同的情况下，样本量较大的联合样本集，训练的纵向联邦机器学习模型分类性能更好。如图4所示，我们用不同的联邦机器学习模型验证了这一结论。在同一个数据集中，随着B方缺少比的增加，N-GM方式获得的联合样本集样本量将大幅下降。当联合样本集样本量下降后，五种纵向联邦机器学习模型的评估指标值都下降了，尤其，FinalNet相对于VF-LR、VF-SVM、VF-GBDT、VF-RF的评估指标值有了更大幅度的下降。FinalNet是一种纵向联邦学习的深度学习框架。这同时也表明对于深度神经网络等复杂模型，用更多的样本量进行训练是有必要的。而本文方法提供了一种更有效解决参与方样本缺少时的联合样本量问题。
② 从样本质量的角度分析，虽然FedPSG-PUM、TabDDPM、A∞B-GM三种方式的联合样本集样本量相同，但他们的联合样本的质量却依次降低。FedPSG-PUM、TabDDPM这两种方式，A方的数据全部被保留了。比起A∞B-GM方式生成全新的联合样本，前两种方式构建的联合样本集中有更多的真实数据用于模型训练，联合样本质量更高。前两种方式中，FedPSG-PUM能够有效地学习缺少样本参与方本地高相关属性之间的数据分布，以及利用多方数据之间的关联性进行缺少样本的生成。而TabDDPM方式，缺少样本参与方的数据是由TabDDPM在B方本地生成的。这说明本文方法是解决参与方样本缺少问题的有效方法。如图4所示的实验结果验证了这一结论，也同时表示了模型的训练效果不仅仅依赖于样本量，还跟样本质量等其他因素有关。即使在B方高缺少比的情况下，本文方法也能为联合样本集提供更高质量的训练样本，更好地支持纵向联邦机器学习模型训练。如图4所示，这一结论适用于不同的机器学习模型。
```

```
【实验结果分析】  
如图4所示，在Bank与Credit两个数据集中，无论B方特征缺失比例如何，采用FedPSG-PUM生成B方缺失样本并构建的联合样本集在所有评估指标（ACC、AUC、F1）上均取得了最佳表现，且这一结果对VF-LR、VF-SVM、VF-GBDT、VF-RF和FinalNet五种纵向联邦分类模型皆适用。与之相比，TabDDPM、A∞B-GM和N-GM三种方法的模型性能依次下降。基于实验结果可从以下两个方面进行分析：  

1)样本数量角度:FedPSG-PUM、TabDDPM与A∞B-GM三种方法均可生成与A方样本数目相当的B方补偿样本，使联合数据集规模相同；而N-GM仅能对齐B方已有样本，导致其最终联合样本量最少。如图4所示，在两个数据集中，无论缺失比例如何，N-GM构建的联合数据集在各项评估指标上均表现最差。这一结果说明，当其他条件相同的情况下，联合样本量对纵向联邦模型的分类性能具有关键影响。随着B方特征缺失比例上升，N-GM生成的联合样本量急剧下降，导致五种纵向联邦模型的评估指标均明显降低，尤其对于深度神经网络框架FinalNet而言，因其对样本量更加敏感，指标降幅更为显著。这表明在深度学习等复杂模型的纵向联邦训练中，充足的样本量至关重要，而FedPSG-PUM在提升联合样本数量方面具有显著优势。

2)样本质量角度：尽管FedPSG-PUM、TabDDPM与A∞B-GM这三类方法均实现了与A方数据规模相当的联合样本集，但它们所生成的样本质量存在差异。FedPSG-PUM和TabDDPM均保留了A方的全部真实数据，联合数据中真实样本所占比例较高；而A∞B-GM需要在A方分布的基础上通过VertiGAN生成全新样本，相应地，其联合样本的真实性略逊于前两种方法。进一步而言，FedPSG-PUM不仅能有效学习B方本地高相关属性的分布特征，还可利用多方数据间的关联信息生成更优质的补偿样本，因而在TabDDPM方法之上实现了进一步提升。实验证明，即使在B方高缺失比例条件下，FedPSG-PUM仍能够提供更高质量的训练数据，从而在多种纵向联邦模型中展现更优性能。这也表明纵向联邦学习不仅需要充分的样本数量，还需兼顾样本质量，二者对于模型性能提升同样重要。
```

