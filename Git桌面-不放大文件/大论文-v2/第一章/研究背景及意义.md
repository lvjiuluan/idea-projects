```
在当今数据驱动的社会中，机器学习技术在各个领域得到了广泛应用。然而，数据隐私和安全问题日益突出，传统的集中式数据处理方式面临严峻挑战\textsuperscript{\cite{chen2021secureboost+,de2010practical}}。联邦学习（Federated Learning，FL）作为一种分布式机器学习方法，允许多个数据持有者在不共享原始数据的情况下协同训练模型，从而在保护数据隐私的同时实现模型性能的提升。在实际应用中，获取大量标记数据往往成本高昂或不可行，而未标记数据通常大量存在。半监督学习（Semi-Supervised Learning，SSL）旨在利用大量未标记数据和少量标记数据来提高模型的泛化能力。将联邦学习与半监督学习相结合，可以在保护数据隐私的同时，利用未标记数据提升模型性能\textsuperscript{\cite{li2021comatch}}。这种结合在数据分布异构、标记数据稀缺的情况下尤为重要。

在多方联邦学习中，多个数据持有者共同参与模型训练，但各自的数据特征可能不同。这种情况下，半监督学习方法的设计需要考虑数据的异构性和隐私保护。例如，某些研究提出了在多方联邦环境下的半监督学习算法，通过共享中间模型参数而非原始数据来保护各方的隐私。在纵向联邦学习（Vertical Federated Learning，VFL）中，不同参与方拥有相同样本的不同特征。然而，实际应用中，参与方可能仅有部分样本的特征重叠，导致对齐样本不足，影响模型性能。为此，研究者提出了基于半监督学习的样本生成方法，通过生成缺失特征或伪标签来扩充训练数据集，提高模型的泛化能力。

本研究旨在探索基于联邦半监督学习的样本生成方法，以解决数据分布异构、标记数据稀缺和对齐样本不足等问题。通过在多方联邦环境下引入半监督学习策略，设计有效的样本生成方法，可以提升模型的性能，拓展联邦学习的应用范围。这对于需要在保护数据隐私的前提下，利用分布式数据训练高性能模型的领域，如医疗、金融和智能制造，具有重要的理论和实践意义。
```

```
随着大数据与人工智能技术的快速发展，数据驱动的决策模式已成为各行业发展的核心动力，然而数据隐私保护法规的严格化与数据孤岛现象的普遍存在，使得跨机构数据协作面临严峻挑战。联邦学习作为一种分布式机器学习框架，通过不共享原始数据而交换模型参数的方式，在保护隐私的同时实现了多方数据价值的联合挖掘，其中纵向联邦学习（Vertical Federated Learning，VFL）因能整合不同机构间的互补特征数据，在金融、医疗等领域备受关注\textsuperscript{\cite{chen2021secureboost+,de2010practical}}。然而，现有研究存在两大瓶颈：其一，传统联邦学习高度依赖监督学习范式，需充足的标注数据支撑，但实际场景中因标注成本高、专家资源有限，完全标记的数据集往往难以获取；其二，纵向联邦学习的有效性通常以样本对齐充分为前提，而现实中大量未对齐样本因缺乏标签或特征缺失无法被有效利用，导致模型泛化能力受限。尤其当标签仅由一方持有时，数据分布异构性、样本对齐不足与标签信息不完整等问题相互交织，进一步加剧了联合建模的复杂性。在此背景下，半监督学习技术特别是仅需正样本与未标记数据的PU学习（Positive and Unlabeled Learning）展现出潜力\textsuperscript{\cite{li2021comatch}}，但传统PU学习要求同时访问正样本与未标记数据，而纵向联邦场景下未标记数据可能因隐私约束或样本未对齐而“隐性缺失”，形成未标记数据缺失的PU学习问题。

**研究意义**  
本研究针对纵向联邦学习中的UDD-PU问题，提出基于PU学习的纵向联邦学习（Vertical Federated learning with Positive and Unlabeled data，VFPU）及结合联邦半监督与数据生成的样本生成方法（Participants Sample Generation method based on VFPU-Multitask，FedPSG-PUM），在理论与应用层面均具有突破性价值。理论层面，VFPU通过加密中间计算与PU学习策略的结合，首次在隐私保护框架下解决了未标记数据缺失的PU学习问题，弥补了传统联邦学习对完全标记数据的依赖，为半监督联邦学习提供了新的方法论；FedPSG-PUM进一步引入特征相关性分析、伪标签预测与表格数据生成技术，构建多任务协作框架，实现了未对齐样本的高效利用与缺失特征的合成增强，丰富了纵向联邦学习的理论体系。应用层面，两类方法均严格遵循数据隐私保护原则，仅通过加密参数交互完成联合训练，在金融风控中可整合多机构用户特征以提升信用评估精度，在医疗领域能协同跨医院数据优化疾病预测模型，同时避免敏感信息泄露；其核心创新在于通过半监督学习降低对对齐样本数量的依赖，通过数据生成技术扩充训练集多样性，显著提升了模型在样本稀缺场景下的鲁棒性与分类性能。此外，研究为跨行业数据合作提供了可落地的技术路径，推动数据要素价值在合规前提下最大化释放，对促进人工智能技术在隐私敏感场景中的普惠化应用具有深远的社会经济意义，亦为联邦学习与半监督学习的交叉研究奠定了重要基石。
```

```
随着大数据时代和人工智能技术的迅猛发展，数据资源已成为驱动各行各业决策能力和服务质量提升的重要战略要素。然而，数据隐私保护法规日益严格，以及广泛存在的数据孤岛现象，使得不同机构之间的数据协作面临着前所未有的挑战，严重制约了数据价值的充分挖掘。在此背景下，联邦学习作为一种新兴的分布式机器学习方法应运而生，通过允许多个数据拥有方在不共享原始数据的基础上，通过交换模型参数或梯度信息实现模型联合训练，成功解决了数据隐私保护与联合建模之间的矛盾。在联邦学习的众多研究方向中，纵向联邦学习（Vertical Federated Learning，VFL）因其能够有效整合不同机构所拥有的互补特征数据而得到广泛关注，并被广泛应用于金融、医疗、推荐系统等领域。然而，目前联邦学习主要集中于监督学习领域，严重依赖大量的标记和对齐数据，但实际应用场景中却普遍面临标注成本高、领域专家稀缺、资源受限以及样本对齐不足等现实挑战，导致大量潜在有用数据无法被有效利用，进而制约了模型泛化能力与应用效果的提升。此外，在现实应用中常常只有一方拥有标签信息，这进一步加剧了联合模型训练的复杂性和挑战。因此，如何高效利用未完全标记数据和未对齐样本成为当前纵向联邦学习领域亟待解决的重要课题。

针对上述问题，本研究提出了一种融合纵向联邦学习与半监督PU学习技术的方法（Vertical Federated learning with Positive and Unlabeled data，VFPU），有效地解决了未标记数据缺失的PU学习（Unlabeled-Data-Deficient PU，UDD-PU）问题。此外，本研究进一步提出一种基于纵向联邦半监督学习的样本生成方法（Participants Sample Generation method based on VFPU-Multitask，FedPSG-PUM），通过融合半监督学习与数据生成技术，在不共享原始数据和模型参数的前提下，实现对未对齐样本的高效利用。具体而言，VFPU方法允许多方在保护数据隐私的基础上，通过交换加密后的中间计算结果实现联合模型训练，有效弥补了现有联邦学习框架处理未完全标记数据的不足，拓宽了PU学习在真实业务场景中的应用范围。FedPSG-PUM方法则通过分析特征间相关性、伪标签预测和表格数据生成，有效解决了纵向联邦学习中样本对齐不足和标签信息缺失的难题，显著提高了数据资源的利用效率和模型的泛化性能。这些方法的提出不仅在理论上丰富了联邦学习与半监督学习的研究范畴，也为金融风险控制、医疗诊断预测、精准医疗、智能制造预测性维护和智能推荐系统等领域提供了切实可行的解决方案，有助于各行业在确保数据隐私安全的基础上更精准地进行数据驱动决策。这些研究成果不仅为联邦学习场景下复杂半监督学习问题提供了理论支撑和实践指导，也为未来的数据合作与价值共享提供了宝贵的技术路径与方法论支持。
```

```
1. 原来的第4章标题较长且表述不够清晰，建议改为：
第4章 基于纵向联邦的半监督样本生成方法研究
4.1 引言
4.2 基于半监督学习的纵向联邦样本生成模型设计
4.3 实验验证与分析
4.4 本章小结
明确强调是纵向联邦场景，突出半监督样本生成方法的研究。
2. 1.2节编号重复问题调整如下：
1.2 国内外研究现状及分析
1.2.1 联邦学习研究现状
1.2.2 半监督学习研究现状
1.2.3 联邦半监督学习研究现状
1.2.4 数据生成及数据填补方法研究现状
原1.2.3重复了两次，应将后一项修正为1.2.4
3. 第3章与第4章研究方法明确性强化.第3章具体明确提出的内容：提出一种面向多方联邦环境的半监督学习框架或算法（如联邦半监督自训练、联邦协同训练等）
明确描述提出的算法或框架的具体流程与细节。第4章具体明确提出的内容：明确提出一种纵向联邦场景下的半监督样本生成算法，如提出或改进的联邦生成对抗网络（FedGAN）模型或联邦扩散模型（Fed-Diffusion）
明确给出具体的算法设计与模型结构图，以增加研究的具体性和说服力

```

```
查非的结果
1、“该数据集的主要分类目标是预测客户是否会订购定期存款，即由变量‘y’(是 / 否) 表示的二元结果｡” 中 “即” 用词不当，可改为 “该”
2、“这一方法在底层数据分布复杂且呈多模态情况时尤为有效｡” 中 “呈多模态情况时” 表述啰嗦，可改为 “呈多模态时”
3、	“在整个过程中，原始数据与合成数据均严格保留在本地，从而确保了数据隐私的绝对安全｡” 中 “绝对” 用词过于绝对，可改为 “高度”
4、“在这种情况下，不同组织或机构拥有的用户群体与特征集合可能仅存在少量重叠，但依然可通过联邦迁移学习的思想，将部分预训练模型的知识进行迁移，从而提升任务的性能或模型的泛化能力｡” 句子主语不一致，可改为 “在这种情况下，不同组织或机构拥有的用户群体与特征集合可能仅存在少量重叠，但它们依然可通过联邦迁移学习的思想，将部分预训练模型的知识进行迁移，从而提升任务的性能或模型的泛化能力”
```

```

```

