```
随着数据隐私保护需求的日益增加以及分布式数据环境的广泛存在，联邦学习（Federated Learning, FL）作为一种保护数据隐私的分布式机器学习方法得到了快速发展。然而，在实际应用中，联邦学习面临标记数据稀缺、数据分布异构以及参与方样本对齐不足等挑战。半监督学习（Semi-Supervised Learning, SSL）因其能够有效利用少量标记数据和大量未标记数据提升模型性能，成为解决上述问题的重要手段。本文聚焦于联邦半监督学习方法及其在样本生成方法中的应用研究，旨在通过设计创新的算法和框架，在保护数据隐私的前提下，充分利用未标记数据和非对齐样本，提升联邦学习模型的泛化能力和应用价值。本文的主要研究内容如下：  

（1）针对多方联邦学习中未标记数据缺失的问题，提出了一种结合正样本-未标记样本学习（Positive-Unlabeled, PU）的联邦半监督学习方法VFPU。该方法基于对未标记数据缺失问题的深入分析，构建了一种创新的联邦协作框架，通过加密样本对齐、动态伪标签生成和集成学习策略，有效利用多方分散的未标记数据来训练模型。在隐私保护的基础上，VFPU方法显著提升了联邦推荐任务的精确率与召回率，实验证明其性能与集中式方法相当，成功地在模型性能和数据隐私保护之间实现了有效平衡。 
VFPU通过反复地从多方未标记数据中随机抽样，将被抽样的数据暂时视作负样本，由此形成多个训练集（其中正负样本比例平衡）以及多个包含未被抽样数据的测试集。对于每个训练集，VFPU在垂直联邦学习框架下迭代地训练基础分类器。接下来，我们利用训练好的基础分类器对测试集中的每个样本生成预测得分。根据各样本在测试集中出现的频率以及得分的总和，我们计算出每个未标记样本为正例的概率。具有最高概率的样本被认为是可靠的正例，然后将其加入正样本集中，并从未标记数据集中移除。这种“抽样—训练—选择正例”的过程不断重复迭代进行。实验结果表明，VFPU算法的性能与非联邦学习的类似方法相当，并且优于其他联邦半监督学习方法。

该方法基于对未标记数据缺失问题的深入分析，构建了一种创新的联邦协作框架，通过加密样本对齐、动态伪标签生成和集成学习策略，有效利用多方分散的未标记数据来训练模型。在隐私保护的基础上，VFPU方法显著提升了联邦推荐任务的精确率与召回率，实验证明其性能与集中式方法相当，成功地在模型性能和数据隐私保护之间实现了有效平衡。 
VFPU通过反复地从多方未标记数据中随机抽样，将被抽样的数据暂时视作负样本，由此形成多个训练集（其中正负样本比例平衡）以及多个包含未被抽样数据的测试集。对于每个训练集，VFPU在垂直联邦学习框架下迭代地训练基础分类器。接下来，我们利用训练好的基础分类器对测试集中的每个样本生成预测得分。根据各样本在测试集中出现的频率以及得分的总和，我们计算出每个未标记样本为正例的概率。具有最高概率的样本被认为是可靠的正例，然后将其加入正样本集中，并从未标记数据集中移除。这种“抽样—训练—选择正例”的过程不断重复迭代进行。实验结果表明，VFPU算法的性能与非联邦学习的类似方法相当，并且优于其他联邦半监督学习方法。

（2）针对纵向联邦学习（Vertical Federated Learning, VFL）中对齐样本数量有限、非对齐样本未被充分利用的局限性，本文提出了基于半监督学习的样本生成方法FedPSG-PUM。该方法通过跨方特征相关性分析、半监督预测和生成模型合成三种策略，生成高质量的伪标签和合成数据。具体而言，FedPSG-PUM计算跨方特征相关性以识别参与方数据间的依赖关系，利用纵向联邦半监督学习预测未标记样本的伪标签，并针对低相关性特征引入生成对抗网络（GAN）合成数据。 
  
```



```
随着数据隐私保护需求的日益增加以及分布式数据环境的广泛存在，联邦学习（Federated Learning, FL）作为一种保护数据隐私的分布式机器学习方法得到了快速发展。然而，在实际应用中，联邦学习面临标记数据稀缺、数据分布异构以及参与方样本对齐不足等挑战。半监督学习（Semi-Supervised Learning, SSL）因其能够有效利用少量标记数据和大量未标记数据提升模型性能，成为解决上述问题的重要手段。本文聚焦于联邦半监督学习方法及其在样本生成方法中的应用研究，旨在通过设计创新的算法和框架，在保护数据隐私的前提下，充分利用未标记数据和非对齐样本，提升联邦学习模型的泛化能力和应用价值。本文的主要研究内容如下：  

（1）针对多方联邦学习中未标记数据缺失的问题，提出了一种结合正样本-未标记样本学习（Positive-Unlabeled, PU）的联邦半监督学习方法VFPU。该方法通过反复地从多方未标记数据中随机抽样，将被抽样的数据暂时视作负样本，由此形成多个训练集（其中正负样本比例平衡）以及多个包含未被抽样数据的测试集。对于每个训练集，在纵向联邦学习框架下迭代地训练基学习器。接下来，利用训练好的基础分类器对测试集中的每个样本生成预测得分。根据各样本在测试集中出现的频率以及得分的总和，计算出每个未标记样本为正例的概率。具有最高概率的样本被认为是可靠的正例，然后将其加入正样本集中，并从未标记数据集中移除。这种“抽样—训练—选择正例”的过程不断重复迭代进行。实验结果表明，该方法的性能与非联邦学习的类似方法相当，并且优于其他联邦半监督学习方法。


（2）针对纵向联邦学习（Vertical Federated Learning, VFL）中对齐样本数量有限、非对齐样本未被充分利用的局限性，本文提出了基于半监督学习的样本生成方法FedPSG-PUM。该方法通过跨方特征相关性分析、半监督预测和生成模型合成三种策略，生成高质量的伪标签和合成数据。具体而言，FedPSG-PUM计算跨方特征相关性以识别参与方数据间的依赖关系，利用纵向联邦半监督学习预测未标记样本的伪标签，并针对低相关性特征引入生成对抗网络（GAN）合成数据。 
  针对纵向联邦学习中对齐样本不足导致模型性能受限的问题，提出了结合半监督学习与数据生成填补的样本生成方法。对于高度相关的特征，该方法采用预测未标记样本的伪标签以扩展训练集；而对于相关性较低的特征，则采用生成模型合成数据。随后，VFPU-M-Syn足联邦学习环境中的关键要求。
  
  总体而言，为了生成缺失的样本，该方法首先通过联邦半监督方法为这些缺失样本预测高度相关的属性列，然后再通过联邦填补或者生成方法补充剩余属性。具体来说，对于存在缺失样本的每个参与方，利用该参与方的已对齐样本集，确定与其缺失样本高度关联的属性。随后，利用这些属性训练本地生成模型，从而生成该参与方缺失样本的高相关属性数据。接下来，我们构建了一个基于生成对抗网络（GANs）的垂直联邦插补框架，用于生成缺失样本的其他剩余属性。在该联邦插补框架中，我们基于GANs重新设计了模型结构、损失函数以及训练流程。
  
  
  
```

```
（2）针对纵向联邦学习中对齐样本数量有限的问题，提出了结合半监督学习与数据生成填补的样本生成方法。该方法通过跨方特征相关性分析、半监督预测和生成模型合成三种策略，生成高质量的伪标签和合成数据。具体而言，FedPSG-PUM计算跨方特征相关性以识别参与方数据间的依赖关系，利用纵向联邦半监督学习预测未标记样本的伪标签，并针对低相关性特征引入生成对抗网络（GAN）合成数据。 

（2）针对纵向联邦学习中对齐样本数量有限的问题，提出了结合半监督学习与数据生成填补的样本生成方法。该方法通过融合联邦半监督学习与生成模型技术，有效提升了数据利用率和模型性能。具体而言，方法包含三个核心流程：首先，通过隐私保护的Spearman秩相关分析计算跨参与方特征间的相关性，构建特征关联强度排序体系；其次，针对高相关性特征，采用改进的VFPU算法进行纵向联邦半监督学习，该算法通过迭代式伪标签生成与筛选，在不同任务类型（分类/回归）下均能有效利用无标签数据；对于低相关性特征，则引入TabDDPM或VF-GAIN等生成模型进行数据合成。实验表明，在Bank、Credit、Letter和News四个数据集上，当相关性阈值τ=0.6、置信度阈值α=0.7且采用GBDT作为基学习器时，该方法获得了最优性能，即使在样本缺失率高达80%的情况下，该方法依然保持了稳定优势。
```

```
随着数据隐私保护需求的日益增加以及分布式数据环境的广泛存在，联邦学习（Federated Learning, FL）作为一种保护数据隐私的分布式机器学习方法得到了快速发展。然而，在实际应用中，联邦学习面临标记数据稀缺、数据分布异构以及参与方样本对齐不足等挑战。半监督学习（Semi-Supervised Learning, SSL）因其能够有效利用少量标记数据和大量未标记数据提升模型性能，成为解决上述问题的重要手段。本文聚焦于联邦半监督学习方法及其在样本生成方法中的应用研究，旨在通过设计创新的算法和框架，在保护数据隐私的前提下，充分利用未标记数据和非对齐样本，提升联邦学习模型的泛化能力和应用价值。本文的主要研究内容如下：  
（1）针对多方联邦学习中未标记数据缺失的问题，提出了一种结合正样本-未标记样本学习（Positive-Unlabeled, PU）的联邦半监督学习方法VFPU。该方法通过反复地从多方未标记数据中随机抽样，将被抽样的数据暂时视作负样本，由此形成多个训练集（其中正负样本比例平衡）以及多个包含未被抽样数据的测试集。对于每个训练集，在纵向联邦学习框架下迭代地训练基学习器。接下来，利用训练好的基础分类器对测试集中的每个样本生成预测得分。根据各样本在测试集中出现的频率以及得分的总和，计算出每个未标记样本为正例的概率。具有最高概率的样本被认为是可靠的正例，然后将其加入正样本集中，并从未标记数据集中移除。这种“抽样—训练—选择正例”的过程不断重复迭代进行。实验结果表明，该方法的性能与非联邦学习的类似方法相当，并且优于其他联邦半监督学习方法。
（2）针对纵向联邦学习中对齐样本数量有限的问题，提出了结合半监督学习与数据生成填补的样本生成方法。该方法通过融合联邦半监督学习与生成模型技术，有效提升了数据利用率和模型性能。具体而言，方法包含三个核心流程：首先，通过隐私保护的Spearman秩相关分析计算跨参与方特征间的相关性，构建特征关联强度排序体系；其次，针对高相关性特征，采用改进的VFPU算法进行纵向联邦半监督学习，该算法通过迭代式伪标签生成与筛选，在不同任务类型（分类/回归）下均能有效利用无标签数据；对于低相关性特征，则引入TabDDPM或VF-GAIN等生成模型进行数据合成。实验表明，在Bank、Credit、Letter和News四个数据集上，当相关性阈值τ=0.6、置信度阈值α=0.7且采用GBDT作为基学习器时，该方法获得了最优性能，即使在样本缺失率高达80%的情况下，该方法依然保持了稳定优势。
```

