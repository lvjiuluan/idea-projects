```
\subsection{实验一：比较联邦和非联邦的 PU 学习的性能}

在本小节中，深入研究了联邦学习对正类和无标签（PU）学习性能的影响。具体来说，比较了使用VFPU算法的联邦PU学习与非联邦PU学习在多种基础估计器和数据集上的表现。核心目标是评估在其他算法参数和实验配置保持不变的情况下，联邦学习对分类质量的影响程度。

使用了四种常用的基础估计器——逻辑回归（LR）、随机森林（RF）、梯度提升决策树（GBDT）和LightGBM（LGB）——在三个真实世界的数据集上进行实验：银行营销数据集、信用卡客户违约数据集和成人普查数据集。对于逻辑回归（LR），使用了L2惩罚系数为0.8、学习率为0.001、批处理大小为64的配置，确保在联邦和非联邦运行中收敛行为保持一致。对于基于决策树的算法（RF、GBDT和LGB），将树的数量设置为50，最大深度为6，学习率为0.1。这些设置经过精心选择，以平衡模型复杂度、训练时间和泛化能力。

表 \ref{RQ1} 展示了在三个数据集上的实验结果，详细列出了每种算法-数据集组合在联邦（Fed）和非联邦（No\_Fed）模式下的四种性能指标——准确率（acc）、召回率（recall）、精确率（precision）和AUC。发现一致表明，联邦变体（Fed）在准确率、召回率、精确率和AUC方面略低于非联邦版本（No\_Fed）。尽管这种差异在所有基础估计器和数据集上都有观察到，但重要的是要强调，在实际应用中，这种差异非常小。

仔细观察数据可以揭示这种微妙的性能差距。例如，在成人普查数据集中，使用GBDT作为基础估计器，联邦方法达到了0.862的准确率、0.188的召回率、0.922的精确率和0.854的AUC。相比之下，非联邦方法报告了略高的0.873、0.205、0.933和0.869的准确率、召回率、精确率和AUC。差距分别为0.011、0.017、0.011和0.015。从数值上看，这些指标的平均差异为0.0135，仍然非常小，表明性能的妥协微不足道。

此外，在所有数据集、四种指标和四种基础估计器上平均，差异为0.0174——进一步证明虽然性能下降是持续观察到的，但这种下降的幅度是适度的。这些观察结果强调了VFPU算法在实际应用中的潜在可行性，在这些应用中，数据隐私和安全问题可能超过预测性能的微小下降。

实验证据因此表明，将联邦学习集成到PU学习中仍然保留了稳健的分类效果。尽管非联邦方法保持了轻微的优势，但这种差异不足以掩盖联邦学习提供的隐私和数据保密优势。因此，对于在敏感领域——如医疗保健或金融——操作的从业者和研究人员来说，VFPU代表了一个引人注目的选择，因为在这些领域，数据访问受到严格监管。该方法使多个参与方能够在不共享原始数据的情况下进行协作建模，从而在模型准确性和隐私要求合规性之间取得了吸引人的平衡。

总体而言，这些实验强调了虽然联邦和非联邦PU学习之间存在适度的性能差距，但VFPU算法仍然提供了稳健的结果。这为数据隐私法规不可妥协的领域提供了一个实用且有效的解决方案，确认了在准确率、召回率、精确率和AUC方面轻微的降低是增强数据安全和保密性的合理权衡。

\subsection{实验二：分析不同基分类器器对 VFPU 性能的影响}

在这一部分，对集成在VFPU框架中的不同基估计器进行了深入评估，这些估计器包括VFPU\_LR、VFPU\_GBDT、VFPU\_RF和VFPU\_LGB，它们被用于解决UDD-PU问题。为了全面评估它们的性能，进行了一系列实验，重点关注四个关键评估指标：精确度（Precision）、召回率（Recall）、F-score以及精确度-召回率曲线。本次评估的主要目标是分析这些指标随着可靠正样本数量增加的变化趋势，并根据这些观察到的趋势，确定方法的最佳基估计器。

在实验中，采用随机抽样策略从一个未标记的数据集中选择可靠的正样本子集。这种方法不仅模拟了现实情况下可能已知少量正实例的条件，还严格测试了每个基估计器在利用这些有限样本时的鲁棒性。实验结果详见图 \ref{RQ2.1} 至 图 \ref{RQ2.3}。

对于基于逻辑回归（LR）的算法，配置了以下特定超参数：应用了L2惩罚，系数设置为0.8，学习率为0.001，小批量大小为64。这些参数基于初步实验精心选择，以确保收敛速度和模型泛化能力之间的平衡。另一方面，对于所有基于树的算法——即梯度提升决策树（GBDT）、随机森林（RF）和LightGBM（LGB）——将树的数量设置为50，树深限制为6以避免过拟合，并使用0.1的学习率。这种在三个数据集上的统一设置，使得在一致的实验条件下公平比较它们的性能成为可能。

图 \ref{RQ2.1} 展示了在银行营销数据集上的实验结果。在图 \ref{RQ2.1.sub1} 至 图 \ref{RQ2.1.sub3} 中，x轴表示分类器获得的可靠正样本数量，范围从大约100到2293个可靠样本。这些子图中的y轴分别对应于准确度、召回率和F-score的评估指标；在此背景下，y轴上的值越高表示分类性能越好。此外，图 \ref{RQ2.1.sub4} 展示了精确度-召回率曲线，其中x轴为精确度，y轴为召回率。曲线上更接近图右上角的模型表明其性能更强，特别是在数据分布不平衡的情况下。




对图 \ref{RQ2.1} 的探索表明，VFPU\_GBDT估计器在银行营销数据集上的表现优于其他模型。例如，如图 \ref{RQ2.1.sub1} 所示，当利用1500个可靠正样本时，VFPU\_LR、VFPU\_GBDT、VFPU\_RF、VFPU\_LGB和基于随机抽样的模型分别实现了44.43\%、51.94\%、49.81\%、43.72\%和4.73\%的精确度。相应的召回率记录为14.78\%、17.28\%、15.24\%、14.55\%和4.61\%，而这些模型的F-score分别为0.22、0.26、0.23、0.22和0.05。尽管VFPU\_RF估计器在某些情况下显示出相对可比较的精确度，但随着可靠样本数量的增加，其性能（特别是在召回率和F-score方面）下降得更快。相比之下，VFPU\_LR和VFPU\_LGB模型虽然在不同样本大小下表现稳定，但并未达到VFPU\_GBDT在精确度和召回率方面表现出的整体性能。因此，图 \ref{RQ2.1.sub1} 清楚地表明，VFPU\_GBDT不仅提供了更高的精确度，而且在召回率之间保持了平衡的权衡，从而在评估的模型中实现了最高的F-score。

此外，图 \ref{RQ2.1.sub4} 中的精确度-召回率曲线进一步验证了VFPU\_GBDT的鲁棒性。通过在各种阈值设置下绘制精确度对召回率的曲线，该曲线有效地捕捉了分类器的性能动态，特别是在类不平衡是关键问题的场景中。VFPU\_GBDT曲线更接近图的右上象限，表明其在多个阈值下的强大性能——这是不平衡分类任务中高性能模型的标志。

图 \ref{RQ2.2}和 图 \ref{RQ2.3} 提供了VFPU\_GBDT估计器有效性的进一步支持证据。这些图报告了在信用卡违约和成人普查数据集上进行的类似实验。尽管数据集在内在特性和分布属性上有所不同，但这些情况下的实验结果反映了与图 \ref{RQ2.1} 中观察到的相似趋势。VFPU\_GBDT在不同数据集上的一致优越性增强了其在VFPU框架中作为基估计器时的可靠性和有效性。

总结来说，三个基准数据集上的实验结果一致表明，VFPU\_GBDT优于VFPU\_LR、VFPU\_RF、VFPU\_LGB以及基线随机抽样技术。VFPU\_GBDT的优越性能，表现为更高的精确度、召回率和平衡的F-score，使其成为在解决UDD-PU问题时VFPU算法最可靠和推荐的基估计器。因此，在所有后续实验中，采用GBDT作为VFPU方法的基估计器，利用其在挑战性条件下实现准确和平衡分类的明显优势。

\subsection{实验三：基线对比实验}

在本节中，对所提出的针对UDD-PU问题的方法进行了全面探讨，特别是在垂直联邦学习（VFL）的设定下，为评估该方法的有效性设计了严谨的分析。为此，开展了两个不同的实验。第一个实验旨在识别最有效的解决正-未标记（PU）问题的半监督学习方法。这些方法虽广泛应用于UDD-PU问题的研究，但通常是在非联邦环境下考虑。第二个实验则基于第一个实验的结果，将前四种半监督技术在实现UDD-PU问题的VFL环境中进行比较。

在第一个实验中，对比了No\_Fed\_VFPU\_GBDT方法与另外九种在非联邦环境下运行的知名半监督学习方法。该对比结果在表 \ref{RQ3.1} 中进行了全面展示。以下段落进一步介绍了每种方法的背景及其在本研究中的具体实现细节。

\begin{quote}
	\textbf{\_GBDT:} 此方法涉及直接将梯度提升决策树（GBDT）分类器应用于正-未标记（PU）数据集。在这种方法中，未标记的数据（记为U）被当作负样本，而现有的标记数据（P）被视为正样本。这一基线方法为评估在没有特殊处理隐藏正样本的情况下，传统技术在PU学习中所面临的内在挑战提供了参考。
\end{quote}

\begin{quote}
	\textbf{Bagging\_GBDT:} Bagging\_GBDT代表了一种利用装袋（bagging）技术进行PU学习的集成学习方法。在这种方法中，通过对未标记数据集的反复采样生成多个训练集。每个训练集都包含正样本和未标记样本的混合，从而生成一系列多样化的子集，并在其上分别训练独立的GBDT分类器。最终的预测结果由所有分类器的预测平均值决定。该方法旨在通过整合多个模型来降低方差并提高预测的鲁棒性。
\end{quote}

\begin{quote}
	\textbf{2Step\_GBDT:} 2Step\_GBDT方法引入了一个两阶段的训练过程。在第一阶段，使用完整的PU数据集训练GBDT分类器，此时所有未标记样本暂时被当作负样本。随后，该分类器被用来识别一部分具有高正样本可能性的未标记样本。在第二阶段，利用这一精炼后的样本子集对分类器进行再训练，以提高其区分隐藏正样本与真实负样本的能力。此迭代细化过程对于在正样本被大量未标记样本掩盖的情况下提升分类性能至关重要。
\end{quote}

\begin{quote}
	\textbf{Pseudo-labeling:} Pseudo-labeling是一种著名的半监督学习技术，它利用模型对未标记数据的预测生成伪标签。接着，将这些伪标签与原有的标记数据结合，用于重新训练模型或提升现有模型的学习过程。伪标签方法的核心思想是，通过将高置信度的预测视为真实标签，使模型不断迭代改进，从而逐步将未标记数据信息整合进训练过程。
\end{quote}

\begin{quote}
	\textbf{MixMatch:} MixMatch是当前领先的半监督学习方法，通过对未标记样本进行增强后猜测标签，并利用MixUp技术混合标记和未标记数据而实现。在实验中，将迭代参数$T$设置为0.5，将增强次数$K$设置为2。该方法旨在通过有效利用未标记数据生成更平滑的决策边界，从而减少过拟合并提升模型的泛化能力。
\end{quote}

\begin{quote}
	\textbf{FixMatch:} FixMatch是伪标签方法的增强版本，它将对弱增强未标记数据的预测结果转换为硬性的一热编码伪标签，然后利用这些伪标签作为对强增强未标记数据的学习信号。在的实现中，采用一组超参数，包括置信阈值$\tau = 0.95$，参数$\nu = 7$，以及批次大小$B = 64$。FixMatch的主要优势在于其利用一致性正则化的能力，从而更为有效地利用未标记数据集。
\end{quote}

\begin{quote}
	\textbf{CoMatch:} CoMatch通过同时引入训练数据的两种互补表示扩展了FixMatch的思想。它同时学习类别概率和低维嵌入，两者相互作用以通过平滑约束来提升伪标签的质量。同时，CoMatch利用基于图的对比学习来正则化嵌入结构。为了保证一致性和便于比较，遵循与FixMatch相同的超参数设置 \textsuperscript{\cite{sohn2020fixmatch}}。这一方法在底层数据分布复杂且呈多模态时尤为有效。
\end{quote}

\begin{quote}
	\textbf{AdaMatch:} AdaMatch最初为领域适应任务提出，并被改进用于半监督学习。其核心特性包括相对阈值和分布对齐机制。相对阈值通过对标记数据置信度分数的指数移动平均（EMA）自适应估计 \textsuperscript{\cite{tarvainen2017mean}}。在实验中，置信阈值设置为$\tau = 0.9$。AdaMatch的自适应策略有助于更好地平衡标记数据和未标记数据的贡献，从而使其成为处理样本不平衡数据集任务的有力候选方法。
\end{quote}

\begin{quote}
	\textbf{SoftMatch:} SoftMatch旨在在训练过程中同时保持伪标签的数量和质量。它通过使用截断高斯函数对样本按照其置信度分数进行加权来实现这一目标。此外，SoftMatch采用均匀对齐方法来增强对代表性较弱类别的学习。在实验中，将参数$m$设置为0.999，并将估计方差${{\hat \sigma }_t}$除以4，对应于高斯函数的$2\sigma$区间。该方法旨在缓解噪声伪标签所带来的常见挑战，确保只有最为可靠的信息被纳入训练过程中。
\end{quote}


通过对各方法工作原理和超参数设置的详细说明，旨在提供对这些方法各自优势和局限性的深入理解。这一详尽的比较不仅突显了No\_Fed\_VFPU\_GBDT方法在揭示隐藏正样本方面的鲁棒性，同时也为未来在常规和联邦学习框架下解决UDD-PU问题的研究提供了基准。


在第一次实验中，使用分类器对所有未标记样本进行了打分，这些分数代表了某个样本被预测为正类的概率。打分过程采用了经过校准的模型，以计算每个未标记实例属于正类的可能性。获取这些概率分数后，将所有未标记样本按降序排序，并将分数最高的样本标记为顶级样本。表 \ref{RQ3.1} 中所示的$ num $表示从该排名顶部选取的未标记样本数量。

对于本次实验中使用的逻辑回归（LR）算法，严格设置了L2惩罚项系数为0.4，学习率为0.0002，批量大小为32。这些超参数设置是基于初步实验结果选择的，表明它们在收敛稳定性与计算效率之间提供了较为平衡的权衡。对于基于决策树的算法，特别是采用梯度提升的方法，将树的数量设置为500，并将最大树深固定为12。此外，决策树算法的学习率设置为0.02。这些超参数配置对于确保模型能够充分表达数据中复杂模式，同时降低过拟合风险至关重要。

此外，对于Match系列算法——即FixMatch、CoMatch、AdaMatch和SoftMatch，采用了\textsuperscript{\cite{oliver2018realistic}}中的Wide ResNet-28模型。该模型因其在半监督环境中具有强大的特征提取能力而受到认可。然而，选择这一深度学习架构引入了一定的复杂性，尤其是在数据极度不平衡的情况下（如PU问题中常见），这可能导致模型过拟合。

表 \ref{RQ3.1} 显示，提出的No\_Fed\_VFPU\_GBDT方法在所有测试数据集上以及对于各个不同的$num$值均持续优于其他九种半监督方法。例如，在Census数据集中，当$num=1000$时，的方法实现了最高的推荐准确率99\%。这一显著性能与基线方法形成了鲜明对比：\_GBDT、2Step\_GBDT和Bagging\_GBDT分别仅达到64\%、62\%和55\%的准确率。同时，基于深度学习的方法——MixMatch、FixMatch、CoMatch、AdaMatch和SoftMatch——的推荐准确率明显较低，分别为35.94\%、37.06\%、33.39\%、37.28\%和35.86\%。

Match系列算法尽管是半监督学习领域最新的进展，但表现不佳可以归因于两个关键因素。首先，这些方法本质上需要大量标记数据，涵盖正类和负类。然而，在PU问题情境下，负样本并未被明确标记，这使得这些算法处于明显的不利地位。其次，使用Wide ResNet-28模型这一相对复杂的深度学习网络，在面对类分布极度不平衡的数据集时，可能无意中导致过拟合。这种过拟合会削弱模型的泛化能力，从而导致整体性能较低。

相比之下，PU学习方法，包括VFPU\_GBDT、\_GBDT、Bagging\_GBDT和2Step\_GBDT，专门为解决在主要由未标记样本构成的数据集中揭示隐藏正样本这一挑战而设计。这些方法利用数据的内在结构，并采用定制的策略来迭代细化对潜在正实例的识别。因此，如表 \ref{RQ3.1}所示，表现最好的四种方法分别为\_GBDT、Bagging\_GBDT、2Step\_GBDT和VFPU\_GBDT。它们的出色性能突显了PU学习策略在负样本不可直接获得且数据存在显著不平衡的情景中的有效性。

通过对打分机制、超参数设置以及底层模型架构的详细讨论，丰富了分析内容，从而全面理解了实验设置及各方法的相对优劣。这一详细论述凸显了提出的No\_Fed\_VFPU\_GBDT方法在有效揭示隐藏正样本方面的优势，为未来在常规PU学习和联邦PU学习框架下的研究提供了宝贵的启示。

在第二个实验中，将第一个实验中表现最佳的四种方法适配到垂直联邦学习（VFL）环境中，分别标记为VF\_GBDT、VF\_Bagging\_GBDT、VF\_2Step\_GBDT和VFPU\_GBDT。此外，为了评估这些方法在VFL环境中部署时的时间复杂度和计算开销，在$num = 2400$的各种数据集上仔细记录了每种方法的训练时间。训练时间表示为runtime(s)，其中s代表秒，详细内容见表 \ref{RQ3.2}。

表 \ref{RQ3.2} 与表 \ref{RQ3.1} 类似，展示了VFL设置下不同方法所达到的准确率百分比的比较分析。结果清晰地表明，VFPU\_GBDT方法在推荐准确率方面始终优于其他三种方法。例如，在Census数据集上，当$num=1000$时，VFPU\_GBDT达到了显著高的98.70\%的推荐准确率，这明显高于VF\_GBDT、VF\_Bagging\_GBDT和VF\_2Step\_GBDT的准确率，它们分别为24.20\%、21.10\%和24.30\%。在Credit数据集上，尽管VFPU\_GBDT展示了更高的准确率，但它带来了更高的计算成本：本章的方法记录的运行时间为107075.9s，而VF\_GBDT、VF\_Bagging\_GBDT和VF\_2Step\_GBDT的运行时间分别为12025.47s、15791.59s和46954.19s。

值得注意的是，按runtime(s)指标衡量，VFPU\_GBDT的耗时约为其他方法的10倍。这种增加的时间消耗主要是由于VFPU\_GBDT在选择可靠正样本时采用了更为谨慎和迭代的策略。该算法采用多次迭代，每次迭代只选择一小部分样本，确保只有最可靠和准确预测的正样本被选中。这种谨慎的选择过程引入了额外的计算开销。然而，这种训练时间与推荐准确率之间的权衡被认为是可接受的，因为准确率的显著提高证明了额外训练时间的合理性。

图  \ref{fig:GBDT} 提供了表 \ref{RQ3.2} 中讨论的银行营销数据集实验结果的可视化表示。在该图中，x轴表示被选为可靠正样本的评分最高的未标记样本数量，而y轴表示这些被选择样本中真正为正样本的百分比。图中清晰地说明，随着$num$从100增加到1000，VFPU\_GBDT识别的隐藏正样本数量迅速减少。这种观察到的减少可归因于几个因素。最初，与正类表现出强烈相似性或与负类有明显差异的未标记数据样本被迅速识别和选择。然而，随着选择过程的继续，剩余的未标记数据往往在正负类之间表现出特征重叠，这给分类器带来干扰。这种干扰导致错误分类，从而降低了准确推荐的百分比。虽然其他方法在不同$num$值下表现相对稳定，但这种表面上的稳定性并不一定是有利的。这些方法始终较低的准确推荐百分比表明它们在可靠识别隐藏正样本方面能力有限。此外，考虑到未标记数据集中只有约2500个真正的正样本，当选择的正样本数量超过这个阈值时，VFPU\_GBDT的准确率自然会下降。

总之，实验结果提供了强有力的证据，表明VFPU\_GBDT算法在VFL环境中推荐可靠正样本方面非常有效。尽管需要额外的计算时间，但推荐准确率的显著提升使VFPU\_GBDT相比其他半监督方法成为更优方案。这项实验突显了在联邦学习环境中应用VFPU\_GBDT算法解决未标记数据缺乏的PU（UDD-PU）学习推荐问题的显著优势，强调了它在高准确率至关重要的实际应用中的潜力。
```

将上面三个章节划分为：

实验设计与基线模型介绍

实验结果分析



要求：只是调整段落，尽量不要修改原文内容