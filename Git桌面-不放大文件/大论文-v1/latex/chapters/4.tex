\chapter{基于联邦半监督学习的样本参与方生成方法}
\thispagestyle{others}
\pagestyle{others}
\xiaosi

\section{本章引言}
联邦学习允许多个参与方在不暴露各自私有数据的前提下共同训练机器学习模型。特别是，纵向联邦学习（VFL）通过对齐不同参与方的特征来构建联合模型。然而，VFL通常要求各参与方共享较大的对齐样本集，而这一假设在实际应用中常常难以成立。原因在于，只有少量数据是对齐的，剩余的大部分数据无法有效参与到训练中。

为了解决因样本对齐不足导致联合样本稀缺的问题，生成联合样本成为一种潜在的解决方案。目前，已有一些基于VFL的样本生成技术。例如，基于生成对抗网络（GANs）的纵向联邦数据生成方法，以及基于马尔可夫随机场（MRFs）\textsuperscript{\cite{MRFs}}的合成表格数据生成框架。尽管这些生成方法能够通过合成样本增加样本的数量，但需要注意的是，机器学习模型的效果不仅仅依赖样本的数量，样本的质量同样至关重要。通过纵向联邦生成方法得到的联合样本通常是合成的虚拟数据，缺乏真实样本的质量保障。特别是在某些参与方样本缺失较为严重时，即使其他方拥有未对齐的额外样本，这些样本也无法有效加入联合样本集，导致可以用于训练的样本数量极为有限，进而影响纵向联邦生成模型的表现。

除了生成联合样本，另一种可能的解决方式是保留其他参与方的未对齐样本，并利用这些样本为缺少样本的参与方生成数据。通过对齐这些未对齐样本和缺失样本，可以有效增加联合样本的数量。这是本文所探讨的核心技术问题之一。当前，已有一些生成方法可用于为样本稀缺的参与方创建样本，诸如基于生成对抗网络（GANs）、自动编码器（AEs）和去噪扩散概率模型（DDPMs）\textsuperscript{\cite{TabDDPM}}等方法。这些方法通过学习潜在数据分布来合成高质量的数据。然而，在纵向联邦学习的场景下，每一方的数据与其他方的数据通常存在一定的相关性。虽然基于深度学习的生成方法在单方数据上能够表现良好，但它们通常忽视了不同参与方之间的数据相关性，未能充分利用多方数据的关系，从而影响生成样本的质量。

针对上述问题，本章提出了一种基于纵向联邦半监督学习的样本生成方法（FedPSG-PUM），旨在提升在对齐样本有限时VFL的性能。FedPSG-PUM通过估计缺失特征的表示来生成样本。在高相关性的特征上，FedPSG-PUM通过预测未标记样本的伪标签来扩展训练集；而在低相关性的特征上，则采用生成模型或者填补模型合成数据。随后，FedPSG-PUM在这些增强的样本数据上联合训练多个分类器，从而提升整体VFL模型的效果。此外，FedPSG-PUM通过确保各参与方之间不交换原始数据或模型参数，来保护数据隐私，符合联邦学习环境中的安全要求。

本章的结构安排如下：4.2 节将对问题进行分析定义，4.3节将系统性地阐述基于半监督学习的纵向联邦参与方样本生成方法框架，并详细介绍  FedPSG-PUM  的执行流程和算法设计。4.3 节在多个真实数据集上进行实验，验证 VFPU 方法的有效性，并对实验结果进行深入分析。最后，4.4 节对本章的研究工作进行总结。

\section{问题分析与定义}
考虑一个典型的两方纵向联邦学习（Vertical Federated Learning, VFL）场景，其中涉及两个参与方通过各自独立的特征集进行合作学习，在保证数据隐私和安全的前提下，共同训练一个机器学习模型\textsuperscript{\cite{yang2019federated}}。参与方包括 Party A 和 Party B，其中只有一方拥有标签。首先，Party A 拥有数据集：
\begin{equation}
	\mathcal{D}^A := \{X^A_i\}_{i=1}^{n^A}
\end{equation}
式中，$X^A_i$ 是第 $i$ 个样本的特征向量，$n^A$ 是样本数量。Party A 的数据仅包含特征，不包含标签。接着，Party B 拥有数据集：
\begin{equation}
	\mathcal{D}^B := \{(X^B_i, Y^B_i)\}_{i=1}^{n^B}
\end{equation}
式中，$X^B_i$ 是第 $i$ 个样本的特征向量，$Y^B_i \in \{0,1\}^C$ 是对应的独热编码（one-hot encoding）真实标签，$C$ 表示类别数，$n^B$ 是样本数量。Party B 拥有标签，这在 VFL 中至关重要，因为标签通常用于监督学习任务。然而，Party B 缺乏足够的特征来单独构建一个准确的模型，因此需要利用 Party A 提供的补充特征，如图 \ref{fig:Missing}\subref{MissingTwo} 所示。
%调整图片与上方文字之间的间距
\vspace{-0.1cm}
\begin{figure}[!h]
	\centering
	\subfigure[]{
		\label{MissingOne}
		\includegraphics[width=0.45\textwidth]{chapters/imgs/MissingOne}}
	\hspace{0.01\textwidth}  % 适当增加间距
	\subfigure[]{
		\label{MissingTwo}
		\includegraphics[width=0.45\textwidth]{chapters/imgs/MissingTwo}}
	
	\bicaption[\xiaosi \songti 纵向联邦样本未对齐缺失情况]%
	{\centering \wuhao 纵向联邦样本未对齐缺失情况。(a) B 方缺失情况；(b) 双方缺失情况}%
	{\centering \wuhao Vertical Federated Learning with Unaligned Samples. (a) Missing data in party B; (b) Missing data in both parties}    
	\label{fig:Missing}
\end{figure}
%调整图片与下方文字之间的间距
\vspace{-0.35cm}

需要强调的是，$\mathcal{D}^A$ 和 $\mathcal{D}^B$ 分别由 Party A 和 Party B 私有保存，双方不能互相暴露其数据集。

在 VFL 中，Party A 和 Party B 的数据集 $\mathcal{D}^A$ 和 $\mathcal{D}^B$ 包含了不同样本的特征。为了进行联合学习，需要将具有相同身份的样本对齐。假设通过隐私保护的加密实体匹配技术，双方已经完成了样本对齐，得到了对齐样本集：
\begin{equation}
	\mathcal{D}_{al} := \{X^A_{i_{al}}, X^B_{i_{al}}, Y^B_{i_{al}}\}_{i=1}^{n_{al}}
\end{equation}
式中，$n_{al}$ 是对 齐样本的数量。Party A 拥有对齐样本的特征：
\begin{equation}
	\mathcal{D}^A_{al} := \{X^A_{i_{al}}\}_{i=1}^{n_{al}}
\end{equation}
Party B 拥有对齐样本的特征和标签：
\begin{equation}
	\mathcal{D}^B_{al} := \{X^B_{i_{al}}, Y^B_{i_{al}}\}_{i=1}^{n_{al}}
\end{equation}
如果将 $\mathcal{D}^A$ 和 $\mathcal{D}^B$ 连接起来，并使具有相同身份的样本对齐，我们将得到一个如图 \ref{fig:Missing}\subref{MissingTwo} 所示的单一数据集。这个数据集是垂直分割的，每个方拥有该数据集的一个垂直分区（或部分视图），这正是“纵向联邦学习”一词的由来。然而，两方之间通常只存在有限数量的对齐样本。除了对齐样本外，每个方还拥有一些非对齐样本，即没有来自另一方对应样本的数据。对于 Party A，非对齐样本表示为：
\begin{equation}
	\mathcal{D}^A_{nl} := \{X^A_{i_{nl}}\}_{i=1}^{n^A_{nl}}
\end{equation}
对于 Party B，非对齐样本表示为：
\begin{equation}
	\mathcal{D}^B_{nl} := \{X^B_{i_{nl}}, Y^B_{i_{nl}}\}_{i=1}^{n^B_{nl}}
\end{equation}
从单一表格数据集（见图 \ref{fig:Missing}\subref{MissingTwo}）的角度来看，每个方对于另一方的非对齐样本都没有对应的特征（或标签）。我们将这些特征（或标签）视为“缺失”。图 \ref{fig:Missing}\subref{MissingTwo} 中的各方样本未对齐的情况可以划分为两个图 \ref{fig:Missing}\subref{MissingOne} 所示的情况，对于B方缺失和对于A方缺失。所以，只需解决其中一个问题即可。

传统的 VFL 方法仅使用对齐样本 $\mathcal{D}_{al}$ 来构建联邦机器学习模型，而将非对齐样本 $\mathcal{D}^A_{nl}$ 和 $\mathcal{D}^B_{nl}$ 弃置不用。这种做法在对齐样本数量较少时，可能会限制模型的性能，因为大量潜在有用的数据被忽略。

本章提出了一种新的方法  FedPSG-PUM ，旨在充分利用非对齐样本 $\mathcal{D}^A_{nl}$ 和 $\mathcal{D}^B_{nl}$，以提升纵向联邦学习（VFL）模型的性能。该方法结合了 纵向联邦半监督学习 和 表格数据生成技术，通过将对齐样本 $\mathcal{D}_{al}$ 视为有标签数据（其中 $X^A_{al}$ 的“标签”可看作 $X^B_{al}$ 的特征值），而将非对齐样本 $\mathcal{D}^A_{nl}$ 视为无标签数据，利用半监督学习从对齐样本中学习以增强模型的泛化能力，同时采用表格数据生成技术填补与 Party A 相关性较弱的特征缺失值，并与纵向联邦学习相结合优化数据补全。相比传统 VFL 方法， FedPSG-PUM  不仅利用了对齐样本 $\mathcal{D}_{al}$，还充分利用了非对齐样本 $\mathcal{D}^A_{nl}$ 和 $\mathcal{D}^B_{nl}$，显著提高了数据利用率；通过纵向联邦半监督学习，模型能从无标签数据中提取有用信息，进一步提升泛化能力；而表格数据生成技术的引入则使得缺失特征的填补更加合理，从而优化了数据填补策略并提高了模型整体性能。总之， FedPSG-PUM  在传统 VFL 框架基础上引入创新技术，充分利用非对齐样本，在对齐样本有限的情况下显著提升了 VFL 模型的准确性和泛化能力。
\section{基于半监督学习的纵向联邦参与方样本生成方法方法框架}
如图 \ref{fig: FedPSG-PUM } 所示， FedPSG-PUM  方法的核心包含三个主要流程，这三个流程共同协作以实现跨方数据的高效处理和特征生成。首先，在 Process I 中，算法通过计算跨方特征之间的相关性，评估和量化各个特征之间的相互依赖关系。这一过程的目标是确保在纵向联邦学习框架中，不同方的特征能够高效对齐，并通过特征相关性分析揭示不同数据源之间可能存在的潜在依赖结构，从而为后续的建模步骤提供更加精确和有针对性的特征信息。接下来，在 Process II 中，方法采用纵向联邦半监督学习算法来进行数据预测。在这一阶段，算法通过结合来自多个方的信息，并利用半监督学习的策略，有效地预测出缺失或未标记的数据。这一过程不仅保证了数据的完整性，还通过有效利用部分标记数据和大量未标记数据，增强了模型的预测能力和鲁棒性。通过这种方式， FedPSG-PUM  方法能够在数据不完全或部分缺失的情况下，依然保持较高的预测精度。最后，在 Process III 中， FedPSG-PUM  方法利用生成模型生成数据。通过对已预测数据和其他相关特征的建模，生成模型能够创造出与真实数据相似的合成数据。这些生成的数据不仅能够补充现有数据的不足，还可以用来进一步优化模型的训练过程，提升模型在实际应用中的泛化能力。生成的数据也有助于应对训练数据中可能出现的偏差或不均衡问题，进一步增强模型的稳定性和可靠性。下面的小节我将分别介绍这三个流程。

%调整图片与上方文字之间的间距
\vspace{-0.1cm}
\begin{figure}[H]  % 创建一个浮动图形环境，[h]表示尽量将图片放在当前位置(here)
	\centering     % 使图片居中显示
	\includegraphics[width=0.9\textwidth]{chapters/imgs/FedPSG-PUM }  
	% 插入图片，宽度设为页面宽度的90%，图片路径为chapters/imgs/Figure 1 in JEPG format
	
	\bicaption[\xiaosi  FedPSG-PUM 算法总体流程]{\wuhao  FedPSG-PUM 算法总体流程}{\wuhao The overall process of the proposed  FedPSG-PUM  algorithm}
	% 使用bicaption命令创建双语标题
	% [\xiaosi VFPU算法总体流程] - 目录中显示的标题，使用小四号字体
	% {\wuhao VFPU算法总体流程} - 中文标题，使用五号字体 
	% {\wuhao The overall process...} - 英文标题，使用五号字体
	
	\label{fig: FedPSG-PUM }  % 为图片设置标签，可以在文中使用\ref{fig:VFPU}引用此图
\end{figure}
%调整图片与下方文字之间的间距
\vspace{-0.35cm}

\subsection{计算跨方特征相关性}
在纵向联邦学习（Vertical Federated Learning, VFL）框架中，不同参与方（Parties）拥有相同样本但不同特征的异构数据。为了有效利用对齐样本的特征信息，需要量化跨参与方特征之间的统计关联性。本节提出了一种基于隐私保护的Spearman秩相关分析方法，用于构建跨方特征相关性排序体系。

设协调方（Coordinator）$ C $ 作为可信第三方，负责生成同态加密（Homomorphic Encryption, HE）密钥对 $ \{\text{pk}, \text{sk}\} $，式中：$ \text{pk} $ 为公钥（Public Key），用于加密数据；$ \text{sk} $ 为私钥（Secret Key），用于解密数据。

协调方 $ C $ 将公钥 $ \text{pk} $ 分发给参与方 A（Party A）和参与方 B（Party B），以便它们对数据进行加密计算，而不直接暴露原始数据，具体计算流程如下：

定义特征列秩向量，设参与方 A 的特征空间为 $ \Phi^A = \{\varphi^A_1, \varphi^A_2, ..., \varphi^A_{m_A}\} $，$ m_A $ 表示 A 方的特征维数，即 A 方拥有 $ m_A $ 个特征。$ \varphi^A_p \in \mathbbm{R}^{n_{al}} $ 表示 A 方第 $ p $ 个特征在对齐样本集 $ \mathcal{D}^A_{al} $ 上的观测向量，$ \varphi^A_p = [\varphi^A_{p1}, \varphi^A_{p2}, ..., \varphi^A_{pn_{al}}] $ 表示该特征在所有对齐样本上的取值，$ n_{al} $ 为对齐样本的数量。

同理，参与方 B 的特征空间为 $ \Phi^B = \{\varphi^B_1, \varphi^B_2, ..., \varphi^B_{m_B}\} $，$ m_B $ 表示 B 方的特征维数，即 B 方拥有 $ m_B $ 个特征。$ \varphi^B_q \in \mathbbm{R}^{n_{al}} $ 表示 B 方第 $ q $ 个特征在对齐样本集 $ \mathcal{D}^B_{al} $上的观测向量。$ \varphi^B_q = [\varphi^B_{q1}, \varphi^B_{q2}, ..., \varphi^B_{qn_{al}}] $ 表示该特征在所有对齐样本上的取值，$ n_{al} $ 为对齐样本的数量。

为了计算特征间的相关性，需要首先将特征值转换为秩次。对于任意特征列$\varphi^A_p$，计算其秩向量（Rank Vector）：
\begin{equation}
	R^A_p = [r^A_{p1}, r^A_{p2}, ..., r^A_{pn_{al}}]
\end{equation}
这里$r^A_{pi}$表示样本$i$在特征$\varphi^A_p$上的秩次（Rank），即该样本在该特征列中的排序位置，若存在相同值，则采用平均秩（Average Rank）处理。这种转换可以有效减轻异常值对相关性分析的影响，提高方法的稳健性。类似地，B方的特征列$\varphi^B_q$也可以计算出对应的秩向量：
\begin{equation}
	R^B_q = [r^B_{q1}, r^B_{q2}, ..., r^B_{qn_{al}}]
\end{equation}
基于上述定义，设计了一个安全高效的跨方特征相关性计算流程。首先进行加密秩传输，A方使用公钥$\text{pk}$对秩向量$R^A_p$进行同态加密，得到：
\begin{equation}
	[R^A_p] = \{\text{Enc}(r^A_{p1}), \text{Enc}(r^A_{p2}), ..., \text{Enc}(r^A_{pn_{al}})\}
\end{equation}
并将加密后的秩向量发送给B方。通过同态加密技术，A方可以安全地将自己的特征秩信息分享给B方，而不泄露原始数据。类似地，B方也对自己的秩向量$R^B_q$进行同态加密，得到：
\begin{equation}
	[R^B_q] = \{\text{Enc}(r^B_{q1}), \text{Enc}(r^B_{q2}), ..., \text{Enc}(r^B_{qn_{al}})\}
\end{equation}
接下来进行秩差计算，对于任意特征对$(f^A_p, f^B_q)$，B方计算加密秩差向量：
\begin{equation}
	[D_{pq}] = \left[ \text{Enc}(r^A_{p1} - r^B_{q1}), ..., \text{Enc}(r^A_{pn_{al}} - r^B_{qn_{al}}) \right]
\end{equation}
式中，$d_{pq}^i = r^A_{pi} - r^B_{qi}$表示样本$i$在A方特征$f^A_p$和B方特征$f^B_q$上的秩次之差。这里利用了同态加密的一个重要特性：支持加法运算，使B方可以在加密状态下直接计算秩差，而无需解密原始数据，从而保证了计算过程的隐私安全。计算完成后，B方将加密秩差向量$[D_{pq}]$发送给协调方$C$。在获得加密的秩差向量后，协调方$C$使用私钥$\text{sk}$解密$[D_{pq}]$，得到：
\begin{equation}
	d_{pq}^i = r^A_{pi} - r^B_{qi}, \quad i = 1, ..., n_{al}
\end{equation}
协调方然后基于这些秩差值计算Spearman相关系数，该系数是衡量两个变量单调关系强度的非参数度量：
\begin{equation}
	\rho_{pq} = 1 - \frac{6\sum_{i=1}^{n_{al}} (d_{pq}^i)^2}{n_{al}(n_{al}^2 - 1)}
\end{equation}
$\rho_{pq}$表示A方特征$f^A_p$与B方特征$f^B_q$之间的Spearman相关系数。相较于Pearson相关系数，Spearman相关系数对数据分布不敏感，能够捕获非线性单调关系，更适合异构数据场景。通过计算所有特征对的相关系数，最终可以构建完整的跨方相关性矩阵：
\begin{equation}
	\mathbf{M} \in \mathbbm{R}^{m_A \times m_B}, \quad \mathbf{M}(p,q) = \rho_{pq}
\end{equation}
$\mathbf{M}(p,q)$存储A方第$p$个特征列与B方第$q$个特征列的Spearman相关系数，该矩阵全面反映了两方特征空间之间的关联结构。在获得特征间相关性矩阵后，进一步定义特征关联强度的概念。对于B方的每个特征$f^B_q$，计算其与A方所有特征的平均关联强度：
\begin{equation}
	\mu_q = \frac{1}{m_A} \sum_{p=1}^{m_A} \rho_{pq}, \quad q=1,...,m_B
\end{equation}
$\mu_q$表示B方特征$f^B_q$对A方特征空间的综合依赖程度。这一指标综合考虑了B方特征与A方所有特征的关联性，可以有效评估该特征在跨方联合建模中的重要程度。关联强度高的特征通常包含更多与对方特征空间相关的信息，在后续的联邦建模中具有更高的价值。最后，基于特征关联强度生成排序列表。具体而言，构建特征重要性序列：
\begin{equation}
	\mathcal{L}_B = \{(\mu_q, f^B_q)\}_{q=1}^{m_B}
\end{equation}
按$\mu_q$降序排列，得到排序后的特征列表：
\begin{equation}
	\mathcal{L}_B^{sorted}
\end{equation}
这一排序结果为后续的联邦学习过程提供了重要指导，尤其在特征补全任务中具有关键价值。通过该列表，可以识别出与A方特征高度相关的B方特征，优先使用联邦半监督学习方法补充这些维度，从而最大化信息利用效率，提高模型性能。这种基于特征关联性的排序机制，有效解决了纵向联邦学习中的特征选择与优先级确定问题，为资源有限情况下的模型构建提供了理论依据。
\subsection{纵向联邦半监督方法预测数据}
如图 \ref{fig: FedPSG-PUM } 所示，在计算跨方相关性列表之后，研究进入 Process II 阶段。在该阶段，我们从 B 方 中选择一部分与 A 方 具有较高相关性的列，以此作为生成过程的基础。具体而言，该选择过程基于前一阶段计算得到的跨方相关性列表，确保所选列能够最大程度地保留和反映 A 方 的特征信息，从而提高后续生成过程的准确性和有效性。在 Process II 阶段，列的选择标准通常依赖于相关性阈值设定，即仅保留那些与 A 方 相关性超过某一特定阈值的列。

在这一过程中，本方法将B方的高相关性特征逐列拆分，每一列特征单独作为一个标签列。随后，A方的数据与基于纵向联邦半监督学习方法生成的B方部分数据共同构成训练数据集，从而形成一个典型的纵向联邦半监督学习框架。如图所示，$X^A$ 表示A方的数据，而 ${{X}^{{{B}_{predict}}}}$ 代表通过纵向联邦半监督学习方法推测得到的B方部分数据。此外，$f_{q}^{B}$ 表示B方的第 $q$ 个特征列，在本方法中，该特征列被视为 $X^A$ 和 ${{X}^{{{B}_{predict}}}}$ 进行纵向联邦学习时的标签。

在该框架下，A方和B方的数据仍然保持隐私保护，即A方无法直接访问B方的原始数据，B方也无法直接获取A方的数据。然而，通过联邦学习的协作训练机制，A方可以利用自身数据和部分推测得到的B方数据进行模型训练，以优化对B方特征的预测能力。与此同时，B方的高相关性特征被逐列拆分，使得每一列特征都可以单独作为监督信号，从而有效地提升模型的学习能力。

将数据缺失问题建模为纵向联邦半监督学习（Vertical Federated Semi-Supervised Learning, VFSSL）框架，其中特征集$X^A$与$X^{B_{\text{predict}}}$包含有标签和无标签两类数据。尽管Liu等人\textsuperscript{\cite{liu2023multi}}提出的VFPU（Vertical Federated Positive-Unlabeled Learning）算法为纵向联邦半监督学习提供了解决方案，但其主要局限于仅含正样本与未标记样本的PU学习场景。针对本研究中$f_q^B$特征列可能涉及的二分类、多分类及回归等多任务需求，本文创新性地提出改进型VFPU-M（Multi-task VFPU）方法。该方法通过纵向联邦协同训练构建特征预测模型，利用基学习器对未对齐数据进行多轮预测与置信度评估，动态筛选高可信度样本扩充训练集，迭代优化直至收敛（如图\ref{fig: FedPSG-PUM }所示）。相较于传统VFPU，VFPU-M不仅突破单一任务限制，还能通过联邦机制有效融合跨域无标签数据的分布特征，显著提升多任务场景下的模型泛化能力。实验验证表明，该方法在分类与回归任务中均取得优于基准方法的性能表现，证实了其跨任务适应性和特征补全有效性。

在本阶段的研究工作中，主要需要执行两个核心算法，以确保数据处理和模型训练的有效性。这两个算法分别为：算法1——基于纵向联邦半监督学习（Vertical Federated Semi-Supervised Learning, VFSSL）的方法用于数据生成的过程，以及算法2——VFPU-M（Vertical Federated PU Learning with Model Adaptation）算法。在后续章节中，我们将对这两个算法的理论基础、实现细节及其在本研究中的具体应用进行详细介绍。

算法4-1提出了一种基于纵向联邦半监督学习（Vertical Federated Semi-supervised Learning, VFSL）的缺失数据生成方法。该方法通过挖掘参与方A与B之间对齐样本的统计关联特性，在联邦学习框架下构建特征补全模型，实现在保护各方数据隐私的前提下，高效补全B方未对齐样本的缺失特征。如算法4-1所述，其核心流程包含联邦模型协同训练、跨域特征关联分析以及隐私保护下的数据生成三个关键环节，详细阐述了从未对齐样本中生成可信特征值的完整实现过程。

算法的输入包括以下几个关键元素：A 方对齐数据：$X_{al}^A \in \mathbbm{R}^{n_{al} \times d_A}$，表示 A 方与 B 方样本空间对齐的特征矩阵，其中 $n_{al}$ 为对齐样本的数量，$d_A$ 为 A 方特征维度。A 方未对齐数据：$X_{nl}^A \in \mathbbm{R}^{n_{nl} \times d_A}$，表示 A 方未对齐部分的特征矩阵，其中 $n_{nl}$ 为未对齐样本的数量。B 方相关系数列表：$\mathcal{L}_B = \{(\mu_q, \phi^B_q)\}_{q=1}^{d_B}$，其中 $\mu_q$ 表示 B 方特征列 $\phi^B_q$ 与 A 方数据的皮尔逊相关系数，$d_B$ 为 B 方特征维度。相关性阈值：$\tau$，用于筛选与 A 方数据具有显著相关性的 B 方特征列。该阈值的选取通常基于统计显著性检验，以确保筛选出的特征在统计上具有可靠性。

\vspace{-0.2cm} 
\begin{table}[H]
	\centering
	\renewcommand{\arraystretch}{1.0}
	{\songti \wuhao
		\begin{tabular}{p{\textwidth}}
			\toprule[1.5pt]
			\makecell[l]{\songti\wuhao  算法 4-1 纵向联邦半监督方法生成数据过程}\\
			\midrule[0.75pt]
			\makecell[l]{\wuhao \textbf{输入:} A方对齐数据集 $X_{al}^A$, 未标记数据集 $X_{nl}^A$,B 方特性相关性列表 $\mathcal{L}_B$}\\
			\makecell[l]{\wuhao \quad 对齐数据集样本数量 $n_{al}$，标记数据集的样本数量 $n_{nl}$，相关性阈值 $\tau$}\\
			\makecell[l]{\wuhao \textbf{输出:} $X^{B_{predict}}$: 最终通过预测方法生成的B方数据}\\
			\makecell[l]{\wuhao \textbf{Process:}}\\
			\makecell[l]{\wuhao 1: Initialize $X^{B_{predict}} = \emptyset$, $\mathcal{L}_B^{\text{predict}} = \{(\mu_q, \phi^B_q) \in \mathcal{L}_B \mid u_q > \tau\}$}\\
			\makecell[l]{\wuhao 2: \textbf{for} $(\mu_q, \phi^B_q) \in \mathcal{L}_B^{\text{predict}}$ \textbf{do}}\\
			\makecell[l]{\wuhao 3: \quad $X_{al}^{B_{predict}} = \{x_{i}^{B_{predict}}\}_{i=1}^{n_{al}}$}\\
			\makecell[l]{\wuhao 4: \quad $X_{nl}^{B_{predict}} = \{x_{i}^{B_{predict}}\}_{i=n_{al}+1}^{n_{al}+n_{nl}}$}\\
			\makecell[l]{\wuhao 5: \quad $p = \text{VFPU-M}(X_{al}^A, X_{nl}^A, X_{al}^{B_{predict}}, X_{nl}^{B_{predict}}, \phi^B_q)$}\\
			\makecell[l]{\wuhao 6: \quad $X^{B_{predict}} = X^{B_{predict}} \cup \{p\}$}\\
			\makecell[l]{\wuhao 7: \textbf{end for}}\\
			\makecell[l]{\wuhao 8: 得到 $X^{B_{predict}}$}\\
			\bottomrule[1.5pt]
		\end{tabular}
	}
	\label{tab:algo-vfpu}
\end{table}
\vspace{-0.56cm}

算法的核心目标是利用 A 方数据预测 B 方未对齐样本的特征值，并生成完整的 B 方数据矩阵 $X^{B_{predict}}$。整个过程可分为以下三个主要步骤：

初始化阶段：目标数据集 $X^{B_{predict}}$ 为空集，表示尚未生成任何 B 方数据。通过相关性筛选，从 $\mathcal{L}_B$ 中选取所有相关性系数大于阈值 $\tau$ 的特征列，构造预测特征集合：
\begin{equation}
	\mathcal{L}_B^{\text{predict}} = \{(\mu_q, \phi^B_q) \in \mathcal{L}_B \mid \mu_q > \tau\}
\end{equation}
该筛选过程通常采用假设检验方法，以确保仅保留统计上显著相关的特征，从而提高数据生成的可靠性。特征级联邦数据生成：对于每个满足相关性筛选条件的特征列 $(\mu_q, \phi^B_q) \in \mathcal{L}_B^{\text{predict}}$，执行以下步骤，数据分区  将 B 方特征列 $\phi^B_q$ 的预测数据划分为：对齐部分：$X_{al}^{B_{predict}} \in \mathbbm{R}^{n_{al}}$，对应于 A 方对齐样本的 B 方特征值。未对齐部分：$X_{nl}^{B_{predict}} \in \mathbbm{R}^{n_{nl}}$，需要通过联邦学习方法进行预测。这种数据分区方式与 A 方数据结构保持一致，有助于后续联邦建模的执行。联邦预测建模：采用 VFPU-M（Vertical Federated Prediction with Unlabeled Missing data）算法进行特征预测，该算法将在后续章节详细介绍。其函数形式如下：
\begin{equation}
	p = \text{VFPU-M}(X_{al}^A, X_{nl}^A, X_{al}^{B_{predict}}, X_{nl}^{B_{predict}}, \phi^B_q)
\end{equation}
式中：对齐部分 $X_{al}^{B_{predict}}$ 直接使用 B 方已有的特征值。未对齐部分 $X_{nl}^{B_{predict}}$ 通过 VFPU-M 进行预测，生成伪标签数据。该过程确保了 B 方数据的补全，同时符合联邦学习的隐私保护要求。

数据合成：将 VFPU-M 预测得到的伪标签向量 $p$ 合并至目标数据集 $X^{B_{predict}}$，完成当前特征列的数据生成。迭代执行：通过遍历所有满足相关性筛选条件的特征列，最终生成完整的 B 方数据矩阵：
\begin{equation}
	X^{B_{predict}} \in \mathbbm{R}^{n_B \times |\mathcal{L}_B^{\text{predict}}|}
\end{equation}
该矩阵不仅保留了与 A 方数据的统计相关性，同时符合纵向联邦学习的隐私保护约束。

下面将介绍VFPU-M算法，如算法 4-2 所示，这是一种面向半监督联邦学习的创新方法，旨在处理这样一种场景：在两个参与方中，只有一部分数据（“对齐数据”）具有可靠的标签信息，而另一部分（“非对齐数据”）则缺乏标签，需要通过伪标签（Pseudo-Labeling）的方式来挖掘潜在信息。VFPU-M 在维护数据私密性的同时，通过迭代地对高置信度无标签样本进行伪标签生成并加入后续训练，有效提升了联邦模型在异构数据上的学习能力。

VFPU-M算法的核心思想是将拥有有限可靠标签的对齐数据和大量无标签的非对齐数据同时纳入训练过程，并在保证原始数据隐私的基础上，不断对高置信度的无标签样本赋予伪标签，使其得以融入有标签数据集中，从而迭代式地壮大可监督训练集。在具体实现中，算法首先对对齐数据构成的有标签数据集记为$\mathcal{D}_L^{(0)}$，并将各参与方非对齐的剩余数据聚合至无标签数据集$\mathcal{D}_U^{(0)}$。接下来，VFPU-M初始化一个联邦模型$f_{\theta}$，模型的参数$\theta$在分布式环境下进行更新，参与方只共享必要的模型梯度或参数信息，不会直接交换任何原始数据。每一轮迭代中，算法都在现有的有标签数据集上训练模型，最小化以下损失函数：
\begin{equation}
	\min_{\theta} \sum_{(\mathbf{x}_j,\, y_j) \in \mathcal{D}_L^{(t)}} \ell \bigl(f_{\theta}(\mathbf{x}^A_j,\mathbf{x}^B_j),\, y_j\bigr),
\end{equation}
式中，$\ell(\cdot)$可以是交叉熵损失、均方误差或其他根据任务需求设定的目标函数。通过这一过程，模型的预测能力在隐私保护的分布式框架下得到稳定提升。

\vspace{-0.1cm}
\begin{table}[H]
	\centering
	\renewcommand{\arraystretch}{0.7}
	\begin{tabular}{p{\textwidth}}
		\toprule[1.5pt]
		\makecell[l]{\songti\wuhao 算法 4-2 VFPU-M 算法} \\
		\midrule[0.5pt]
		\makecell[l]{\wuhao \textbf{输入:} $X_{al}^A$, $X_{nl}^A$: 参与方A的对齐/非对齐数据; $X_{al}^B$, $X_{nl}^B$: 参与方B的对齐/非对齐数据; } \\
		\makecell[l]{\wuhao \qquad $y$: 标签; $\alpha$: 置信度阈值; $T$: 迭代次数; $k$: 选取比例} \\
		\makecell[l]{\wuhao \textbf{输出:} $\mathbf{y}^{\text{pseudo}}$} \\
		\makecell[l]{\wuhao 1: $\mathcal{D}_{L}^{(0)} = \{X_{al}^A, X_{al}^B, y\}$, 
			$\mathcal{D}_{U}^{(0)} = \{X_{nl}^A, X_{nl}^B\}$} \\
		\makecell[l]{\wuhao 2: \textbf{for} $t = 1$ \textbf{to} $T$ \textbf{do}} \\
		\makecell[l]{\wuhao 3: \quad $\theta^{(t)} \leftarrow \arg\min_\theta \sum_{(\mathbf{x}^A,\mathbf{x}^B,y)\in\mathcal{D}_L^{(t)}} \ell(f_\theta(\mathbf{x}^A,\mathbf{x}^B), y)$} \\
		\makecell[l]{\wuhao 4: \quad 对 $\forall (\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{D}_U^{(t)}$，计算置信度:
			$s_j = \begin{cases} 
				\max_{c} \mathbbm{P}(y=c|f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)) & \text{分类} \\
				1 - \frac{|\hat{y}_j - \mu_t|}{\sigma_t} & \text{回归}
			\end{cases}$} \\
		\makecell[l]{\wuhao 5: \quad $\mathcal{C}^{(t)} = \{(\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{D}_U^{(t)} | s_j \geq \alpha\}$; } \\
		\makecell[l]{\wuhao 6: \quad 按置信度排序选取前 $k$ 比例: $\mathcal{S}^{(t)} = \text{TopK}(\mathcal{C}^{(t)}, k)$}\\
		\makecell[l]{\wuhao 7: \quad $\forall (\mathbf{x}^A_j,\mathbf{x}^B_j) \in \mathcal{S}^{(t)}, \hat{y}_j = \begin{cases}
				\arg\max_c P(y=c|f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j)) & \text{分类} \\
				f_{\theta^{(t)}}(\mathbf{x}^A_j,\mathbf{x}^B_j) & \text{回归}
			\end{cases}$} \\
		\makecell[l]{\wuhao 8: \quad $\mathcal{D}_L^{(t+1)} \leftarrow \mathcal{D}_L^{(t)} \cup \{(\mathbf{x}^A_j,\mathbf{x}^B_j,\hat{y}_j)\}_{j\in\mathcal{S}^{(t)}}$; 
			$\mathcal{D}_U^{(t+1)} \leftarrow \mathcal{D}_U^{(t)} \setminus \mathcal{S}^{(t)}$} \\
		\makecell[l]{\wuhao 9: \textbf{end for}} \\
		\makecell[l]{\wuhao 10: $\mathbf{y}^{\text{pseudo}} = \left[ y, \bigcup_{t=1}^{T} \{\hat{y}_j\}_{j \in \mathcal{S}^{(t)}} \right]$} \\
		\makecell[l]{\wuhao 11: \textbf{return} $\mathbf{y}^{\text{pseudo}}$} \\		\toprule[1.5pt]
	\end{tabular}
	\label{tab:algo-vfpu-m} 
\end{table}
\vspace{-0.6cm}
在完成训练后，算法会利用更新后的模型$f_{\theta^{(t)}}$对无标签数据集$\mathcal{D}_U^{(t)}$中的所有样本进行推断，并计算每个样本对应的置信度分数。对于分类任务，常用的做法是取模型输出的所有类别预测概率中最大的那一项作为置信度，这一数值越高表明模型对该样本的预测越有把握。而在回归任务中，则可以根据当前预测输出的整体分布情况，以
\begin{equation}
	1 - \frac{|\hat{y}_j - \mu_t|}{\sigma_t}
\end{equation}
来衡量某个样本的预测距离是否接近分布中心，从而得到相应的置信度度量。随后，VFPU-M会预先设定一个置信度阈值$\alpha$，并从高于该阈值的候选样本中进一步挑选前$k$比例的高置信度样本，以降低噪声标签引入的风险。对于这些被选中的无标签样本，算法在本地生成对应的伪标签：如果是分类任务，则将预测概率最高的类别视为伪标签；若为回归任务，则直接采用当前模型的数值输出。通过这种方式，算法兼顾了可靠性与实用性，不会大规模地将未知真实性的数据强行纳入模型训练，而是倾向于选择那些与模型预测高度一致的样本来生成伪标签，从而减少噪声标签的累积效应。

在得到高置信度样本的伪标签后，这些样本便会从无标签数据集中移除，并被加入到新的有标签数据集中，以便在下一轮训练中继续完善模型。由此可见，VFPU-M在每轮迭代中都实现了有标签数据集的动态扩充，并不断强化模型的半监督学习能力。随着迭代进行，越来越多的高置信度样本得到有效利用，使联邦模型逐步学习到更全面、更丰富的数据模式，对于数据异构性和标签稀缺性都具有较好的适应能力。

与其他半监督联邦学习方法相比，VFPU-M具有以下突出的优势。其一，在标签缺乏的场景下，算法能够借助高置信度伪标签循序渐进地增强对无标签数据的利用效率，有效提升模型性能的同时不会过度牺牲鲁棒性。其二，VFPU-M既支持分类任务也支持回归任务，通过简单调整置信度度量与伪标签生成策略即可轻松适配多种应用需求。其三，该算法在任何分布式或跨机构场景中都能显著降低数据泄露风险，各参与方只需交换必要的模型更新信息而无需分享原始数据，切合当下对隐私与安全的严苛要求。其四，由于VFPU-M采用迭代式的联邦训练与筛选机制，当数据中存在较大异质性时，算法可以逐步利用对齐与非对齐数据的混合信息，从而平衡不同分布、不同来源数据对模型的综合贡献。

总的来说，VFPU-M算法为半监督学习与联邦学习的紧密结合提供了一种新颖而高效的范式。它在吸收对齐数据中已有标签信息的同时，充分利用非对齐无标签数据所蕴含的潜在价值，借助高置信度伪标签的迭代式筛选与生成，达到在分布式环境中同步提升模型精度与鲁棒性的目标。在未来的研究中，可以继续探讨如何动态更新置信度阈值$\alpha$、引入更先进的自适应策略，以及在多方恶意节点存在或标签噪声更为复杂的条件下增强算法的稳定性。通过与其他联邦学习或半监督学习技术有机结合，VFPU-M有望进一步拓展应用广度，在更多跨领域合作中发挥关键作用，为数据隐私与机器学习性能的双重需求提供行之有效的解决方案。

为更好地应对A方特征与目标特征间低相关性（即$\mu_q \leq \tau$）给半监督学习带来的预测性能下降问题， FedPSG-PUM 引入了生成模型技术，通过捕捉低相关性特征的分布规律来合成数据，从而实现对缺失特征的合理补全。将其在B方进行本地生成模型的训练，并将训练好的生成模型或者填补模型用于生成B方缺少样本中的相关属性值。可采用的生成模型例如：CTGAN、TableGAN、CTABGAN、VAE和TabDDPM等；可采用的填补模型例如:GAIN、VGAIN、VF\_GAIN等。
\section{实验过程及结果分析}
本节描述了 FedPSG-PUM 方法的实验设计和评估。首先，提供了数据集和实验设置 的概述。随后，提出了一组用于指导实验的研究问题，然后根据每个研究问题展示 并讨论实验结果。
\subsection{数据集介绍与实验准备} \label{subsec:data_experiment}
本文选取了四个来自UCI机器学习库中的数据集进行方法的验证，具体包括银行营销数据集（Bank）、德国信贷数据集（Credit）、字母识别数据集（Letter）\textsuperscript{\cite{serbian}}和在线新闻传播度数据集（News）\textsuperscript{\cite{news}}。其中，银行营销数据集包含45,211个样本，记录了葡萄牙某银行直邮营销活动的16项特征，用于预测客户定期存款订阅行为；德国信贷数据集涵盖1,000条贷款记录，通过20个混合类型特征（含14个分类属性和6个数值属性）评估借款人信用等级；字母识别数据集收录了20,000个手写英文字母样本，提取了16个几何与拓扑特征用于分类任务；在线新闻传播度数据集则包含39,644篇新闻的60项指标，涉及文本内容、社交媒体互动及时间维度，旨在预测传播热度。这些数据集均经过领域专家验证，完成了缺失值填充、类别编码、特征标准化（z-score）等预处理，数值型特征与分类变量分别采用标准化和one-hot编码处理，并按"6:3:1"比例划分为训练集、验证集和测试集。后续实验将简称为Bank、Credit、Letter、News四个数据集，通过多领域数据的交叉验证，全面评估模型在连续/离散特征、样本规模及二分类/多分类任务中的泛化性能。

在针对Bank和Credit数据集的实验中，各参与方按照特征所有权进行了纵向数据划分：其中，参与方A负责管理客户相关属性，而参与方B专门处理银行相关属性。具体来说，在Bank数据集中（不含ID列），参与方A和B各自持有8个属性列；而对于Credit数据集（不含ID列），参与方A拥有9个属性列，参与方B则管理余下的11个属性列。此外，实验还利用Letter和News数据集模拟纵向联邦学习的典型场景，这两个数据集的属性列均按照字段顺序平均分配给参与方A和B进行管理。

在验证本方法有效性的系列实验中，重点研究了图 \ref{fig:Missing}\subref{MissingOne} 所示的B方样本缺失的场景，本方法同样适用图 \ref{fig:Missing}\subref{MissingTwo} 所示的双方样本都缺失的扩展场景。实验评估中，在B方样本缺失的前提条件下，设置了参与方B不同级别的样本缺失率：当缺失率为0.2时，表示B方80\%的样本能与A方形成匹配，剩余20\%样本在A方无对应数据。其中，$\tau$ 表示用于预测的相关性阈值，用于控制为B方缺失样本利用联邦半监督的方法生成数据列的数量，$\tau$越高，表示用预测的方式生成数据的列越少，MisR-B则特指B方相对于A方的样本缺失率。
\subsection{实验设计与基线模型介绍}
实验一：FedPSG-PUM 不同的设置，在实验一中，采用均方根误差（Root Mean Square Error，RMSE）作为样本生成效果的评估指标，该指标用于量化生成样本数据与真实数据之间的平均偏离程度。本实验基于第\ref{subsec:data_experiment}小节所述的Bank和Credit数据集设计了三种实验配置，其中Bank数据集代表大样本量场景，Credit数据集对应小样本量场景。在模型参数设置方面，对于GAN类模型（联邦和非联邦架构）及本文提出的生成模型统一使用Adam优化器，学习率为0.001，训练迭代次数为10000次，每轮迭代包含10个epoch；联邦半监督VFPU-M算法的样本选取比例$k=0.01$，最大迭代次数为$T=500$；逻辑回归（LR）模型采用L2正则化系数为0.8，批处理大小为64，学习率为0.001；集成树模型（GBDT、RF和LGB）的树数量统一设为500，最大深度为6，学习率为0.1。

实验设置1：在FedPSG-PUM方法框架中，固定B方低相关属性列的填补模型（采用VF-GAIN作为数据填补模型），通过调节相关性系数阈值$\tau$的取值，评估模型性能以确定最优参数配置。

实验设置2：本部分实验旨在通过固定相关系数阈值$\tau$并采用不同基学习器模型，验证所提方法的有效性并确定最优基学习器。具体而言，$\tau$值依据实验设置1的优化结果设定为5，并选用四类基学习器进行对比分析：VFPU\_LR（基于逻辑回归）、VFPU\_GBDT（基于梯度提升决策树）、VFPU\_RF（基于随机森林）及VFPU\_LGB（基于LightGBM）。实验过程中，FedPSG-PUM方法持续采用VF-GAIN作为核心数据填补模型。

在超参数配置方面，针对不同模型特性进行差异化设置：(1) 对于基于逻辑回归（Logistic Regression, LR）的算法，采用L2正则化（惩罚系数0.8）以平衡模型复杂度，设置学习率为0.001、小批量训练样本数为64，该参数组合通过预实验优化确定，可在保证收敛速度的同时维持良好泛化能力；(2) 对于基于树的集成算法（包括GBDT、RF和LGB），统一设置基学习器数量为500以控制模型规模，为防止过拟合将最大树深限制为6层，同时梯度提升学习率设定为0.1。所有参数配置均通过交叉验证进行校准，确保实验结果的可靠性。

实验设置3：本部分实验旨在探究置信度阈值$\alpha$对模型性能的影响机制，通过系统调节伪标签数据的选择严格度来优化半监督学习效果。基于前序实验的优化结果，本阶段固定相关系数阈值τ=5（实验设置1的最优参数）并采用VFPU\_GBDT作为基学习器（实验设置2的优选模型）。置信度阈值$\alpha$的取值区间设定为[0.5, 0.9]，以0.05为步长进行精细调节，共形成9个对比实验组。该参数范围的设定基于以下考量：(1) 当<0.5时，模型可能引入大量低置信度伪标签，导致噪声数据污染训练过程；(2) 当$\alpha$>0.9时，筛选条件过于严苛，可能遗漏具有潜在价值的未标记样本；(3) 0.05的步长设计在保证实验效率的同时，可有效捕捉模型性能随置信度变化的敏感区间。通过该实验设计，揭示置信度阈值对伪标签质量与数量的权衡机制，并据此确定FedPSG-PUM框架的最优$\alpha$配置。

在超参数配置方面，针对不同模型特性进行差异化设置：(1) 对于基于逻辑回归（Logistic Regression, LR）的算法，采用L2正则化（惩罚系数0.4）以平衡模型复杂度，设置学习率为0.002、小批量训练样本数为128，该参数组合通过预实验优化确定，可在保证收敛速度的同时维持良好泛化能力；(2) 对于基于树的集成算法（包括GBDT、RF和LGB），统一设置基学习器数量为500以控制模型规模，为防止过拟合将最大树深限制为6层，同时梯度提升学习率设定为0.1。所有参数配置均通过交叉验证进行校准，确保实验结果的可靠性。

实验二：基线对比实验，为了验证FedPSG-PUM方法在参与方样本生成方面的有效性，在实验一的基础上设计了对比实验，将FedPSG-PUM与参与方B的本地生成方法进行性能比较。在基线模型选择方面，选取了数据生成领域具有代表性的先进模型作为对比方法，包括：CTGAN、TableGAN、CTAB-GAN、TVAE 和最新提出的TabDDPM。验通过系统调整参与方B的缺失率(MisR-B)参数构建多组对比条件。在评估体系设计上，采用均方根误差(RMSE)作为模型性能的量化评估指标。分别在Bank、Credit以及Letter、News四个数据集上进行了两组实验，FedPSG-PUM分别结合TabDDPM与VF-GAIN两种策略。

在模型参数设置方面，FedPSG-PUM方法的关键参数包括：特征相关性系数阈值$\tau=0.6$，缺失值填补模块采用VF-GAIN模型，预测器模块选用VFPU\_GBDT基学习器，并设定置信度阈值$\alpha=0.7$；针对生成对抗网络架构（含联邦与非联邦设置），统一配置Adam优化器（学习率为0.001）、训练轮次为10000次，每轮包含10个训练周期；联邦半监督VFPU-M算法设置样本动态选取比例$k=10\%$，全局迭代上限$T=500$；逻辑回归模型采用L2正则化（系数为0.8），批处理规模为64，学习率为0.001；集成学习模型（GBDT、RF、LGB）统一配置决策树数量$n\_{\text{tree}}=500$，最大深度$d\_{\text{max}}=6$，学习率为0.01。

实验三：样本生成效果对比，为系统评估FedPSG-CAG方法在数据缺失参与方样本生成方面的有效性，本研究设计如下验证方案：首先基于生成后的B方样本与A方原始样本构建联合样本集，继而开展纵向联邦学习模型的训练。通过系统比较不同缺失样本处理方式对模型性能的影响，评估所构建联合训练集在支撑不同纵向联邦分类模型训练中的有效性。

本实验构建的A-B跨机构联合样本集由以下两部分组成：A方原始数据与B方经不同生成方法补偿后的数据；双方原始数据的隐私保护对齐结果。实验设计包含三类样本生成策略：(1) 采用FedPSG-PUM方法框架实现缺失样本生成，集成VF-GAIN作为核心填补模型。该模型设置特征相关性阈值$\tau=0.6$与置信度阈值$\alpha=0.7$，基学习器选用VFPU\_GBDT算法。(2) 在B方本地部署TabDDPM模型生成缺失样本，该模型经实验2验证已达到当前生成式建模领域的SOTA性能，可作为基准生成方法进行横向对比。(3) 直接基于A、B双方原始数据进行隐私保护对齐，不进行任何样本生成操作，将这种处理B方缺少样本的方式记为“N-GM”。(4) 在N-GM生成的基准联合集基础上，采用VertiGAN\textsuperscript{\cite{VertiGAN}}方法生成等量于B方缺失样本的合成数据，该方法作为当前纵向联邦样本生成领域的SOTA方法参与对比，将这种处理方式记为A∞B-GM。

本实验采用Bank数据集进行验证，其中B方特征缺失率设置为三个梯度（$\text{MisR-B} \in [0.2,0.5,0.8]$）。实验架构包含五类纵向联邦分类模型：逻辑回归（VF-LR）、支持向量机（VF-SVM）、梯度提升决策树（VF-GBDT）、随机森林（VF-RF）以及深度网络FinalNet，涵盖参数模型与非参数模型、浅层学习与深度学习的多元技术路线。所有模型的性能通过准确率（ACC）、AUC-ROC和F1-score三个指标进行综合评价，其中测试集固定为原始联合样本集的30\%，剩余70\%原始数据与不同生成方法获得的补偿数据共同构成动态训练集。各分类器的超参数经网格搜索优化后设定为：VF-LR（学习率0.01，迭代1000次，批次64）；VF-SVM（正则化参数C=1）；VF-GBDT（树数20，学习率0.1，最大深度6，子采样率0.2）；VF-RF（树数100，最大深度3，最小分裂样本2，叶节点最小样本1）；FinalNet（学习率0.001，迭代1000次，批次64，隐层维度128，L2正则系数0.0001）。


\subsection{实验结果分析}

实验一：FedPSG-PUM 不同的设置，如图 \ref{Chapter4Exp1Setting1} 所示，当$\tau \in [0.5,0.6]$时，在不同样本缺失率（$\text{MisR-B} \in [0.2,0.5,0.8]$）条件下，FedPSG-PUM的RMSE指标均达到最优水平。相比之下，当$\tau = 1.0$时，FedPSG-CAG的RMSE数值表现较差——该参数配置下，B方中缺失样本的所有属性均由纵向联邦填补模型生成。实验结果表明，采用联邦半监督学习预测高相关属性列数据，再结合纵向联邦填补剩余属性的混合策略具有显著优势。

\vspace{-0.1cm}
\begin{figure}[H]
	\centering
	\subfigure[]{
		\label{Chapter4Exp1Setting1a}
		\includegraphics[width=0.45\textwidth]{chapters/imgs/Chapter4Exp1Setting1a}}
	\hspace{0.01\textwidth}  % 适当增加间距
	\subfigure[]{
		\label{Chapter4Exp1Setting1b}
		\includegraphics[width=0.45\textwidth]{chapters/imgs/Chapter4Exp1Setting1b}}
	
	\bicaption[\xiaosi \songti 使用 FedPSG-PUM 在不同相关性阈值（$\tau$）下获得的 RMSE 线图]%
	{\centering \wuhao FedPSG-PUM 方法在不同缺失率下和不同相关性阈值（$\tau$）下的 RMSE 指标 。 (a) Bank数据集；(b) Credit数据集}%
	{\centering \wuhao The RMSE line graph generated using FedPSG-PUM for different correlation thresholds ($\tau$). (a) Bank Dataset; (b) Credit Dataset}    
	\label{Chapter4Exp1Setting1}
\end{figure}
%调整图片与下方文字之间的间距
\vspace{-0.35cm}

进一步分析发现，基于属性相关性为缺失样本优先生成高相关属性特征，这种分层次处理策略产生的合成数据具有更低的RMSE值，其数据分布更接近真实样本。然而，图 \ref{Chapter4Exp1Setting1} 显示当$\tau < 0.6 $时，随着$\tau$减小，说明用联邦半监督方法预测的列增多，RMSE呈现单调上升趋势。这些结果表明，使用联邦半监督方法为B方预测更多相关属性列数据并非一定更优。实际上，一些非高相关属性更适合通过联邦填补生成。联邦填补能够充分利用多方之间的数据协作来提高数据生成的精确性。因此，生成部分高相关属性，并结合联邦填补来生成剩余属性，可以在一定程度上帮助确保生成样本的质量。

\vspace{-0.1cm}
\begin{table}[H]
	\centering
	\bicaption[\xiaosi FedPSG-PUG 在 Bank 和 Credit 数据集上使用不同基学习器获得到的 RMSE]
	{\wuhao FedPSG-PUM 在 Bank 和 Credit 数据集上使用不同基学习器获得到的 RMSE}
	{\wuhao  RMSE obtained by FedPSG-PUM with different base estimators for Bank and Credit Dataset}
	\label{Chapter4Exp1Setting2}
	\resizebox{\textwidth}{!}{
		{\wuhao \songti
			\begin{tblr}{
					cell{1}{1} = {c=2}{},
					cell{2}{1} = {r=3}{},
					cell{5}{1} = {r=3}{},
					colspec = {Q[c] Q[c] Q[c] Q[c] Q[c] Q[c]}, % 左对齐+居中
					hline{1,8} = {1.5pt}, % 顶部和底部 1.5pt
					hline{2,5} = {0.75pt} % 中间分隔线 0.75pt
				}
				\diagbox{Datasets \& MisR-B}{Base Estimator} &     & VFPU\_LR & VFPU\_RF & VFPU\_GBDT & VFPU\_LGB \\
				Bank                   & 0.2 & 0.3146   & 0.2640   & 0.2097     & 0.3887    \\
				& 0.5 & 0.3233   & 0.2727   & 0.2335     & 0.3974    \\
				& 0.8 & 0.3400   & 0.2894   & 0.2311     & 0.4141    \\
				Creditk                & 0.2 & 0.3596   & 0.3591   & 0.3487     & 0.3666    \\
				& 0.5 & 0.3947   & 0.3942   & 0.3681     & 0.4017    \\
				& 0.8 & 0.4289   & 0.4284   & 0.4153     & 0.4359    
			\end{tblr}
		}
	}
\end{table}
\vspace{-0.4cm}

表 \ref{Chapter4Exp1Setting2} 展示了不同基学习器在固定相关系数阈值$\tau=5$下的性能对比。从实验数据可以观察到，基学习器的选择对FedPSG-PUM方法的预测精度产生了显著影响，且这种影响在不同缺失率环境下表现出一致性。对Bank数据集的分析表明，VFPU\_GBDT在所有缺失率水平（0.2、0.5、0.8）下均表现出明显优势，平均RMSE值比次优模型VFPU\_RF低20.5\%。特别是在低缺失率($\text{MisR-B}=0.2$)条件下，VFPU\_GBDT的RMSE仅为0.2097，较VFPU\_RF（0.2640）降低了20.6\%，较传统VFPU\_LR（0.3146）降低了33.3\%。值得注意的是，随着缺失率提高至0.8，VFPU\_GBDT依然保持了相对稳定的性能（RMSE为0.2311），仅比低缺失率环境下增加了10.2\%。在Credit数据集上，各基学习器之间的性能差异虽然相对减小，但VFPU\_GBDT仍然在所有缺失率条件下取得最优结果。具体而言，当$\text{MisR-B}=0.2$时，VFPU\_GBDT的RMSE为0.3487，相比VFPU\_RF（0.3591）和VFPU\_LR（0.3596）分别降低了2.9\%和3.0\%；当缺失率增至0.5时，这一优势进一步扩大至约6.6\%；在高缺失率（0.8）情况下，VFPU\_GBDT仍保持了约3.0\%的性能优势。综合两个数据集的实验结果，可以得出结论：基于梯度提升决策树的VFPU\_GBDT在不同数据集和各缺失率条件下均表现出最优性能，基于以上分析，确定VFPU\_GBDT作为FedPSG-PUM方法的最优基学习器，并将在后续实验中继续采用该配置。

%调整图片与上方文字之间的间距
\vspace{-0.1cm}
\begin{figure}[!h]
	\centering
	\subfigure[]{
		\label{Chapter4Exp1Setting3a}
		\includegraphics[width=0.45\textwidth]{chapters/imgs/Chapter4Exp1Setting3a}}
	\hspace{0.01\textwidth}  % 适当增加间距
	\subfigure[]{
		\label{Chapter4Exp1Setting3b}
		\includegraphics[width=0.45\textwidth]{chapters/imgs/Chapter4Exp1Setting3b}}
	
	\bicaption[\xiaosi \songti 使用 FedPSG-PUM 在不同置信度阈值（$\alpha$）下获得的 RMSE 线图]%
	{\centering \wuhao FedPSG-PUM 方法在不同缺失率下和不同置信度阈值（$\alpha$）下的 RMSE 指标 。 (a) Bank数据集；(b) Credit数据集}%
	{\centering \wuhao The RMSE line graph generated using FedPSG-PUM for different confidence thresholds ($\alpha$). (a) Bank Dataset; (b) Credit Dataset}    
	\label{Chapter4Exp1Setting3}
\end{figure}
%调整图片与下方文字之间的间距
\vspace{-0.4cm}

图 \ref{Chapter4Exp1Setting3} 展示了不同置信度阈值$\alpha$和B方缺失率(MisR-B)组合下的RMSE评估结果。实验结果表明，置信度阈值$\alpha$对模型性能具有一定影响，呈现"U型"的分布特征。随着$\alpha$从0.5逐步提高至0.7，RMSE值持续下降，当$\alpha$超过0.7后，RMSE值开始显著回升。具体而言，在Bank数据集的三种缺失率场景(0.2、0.5和0.8)下，$\alpha=0.7$均产生最优性能，RMSE分别达到0.2097、0.2335和0.2311，较两端端点平均降低约29.8\%的误差。Credit数据集同样呈现相似趋势，在缺失率为0.2和0.5的条件下，$\alpha=0.7$时分别获得0.3487和0.3681的最优RMSE；仅在高缺失率(0.8)场景下，$\alpha=0.75$略优于$\alpha=0.7$，但差异仅为3.4\%。当$\alpha$<0.7时，模型纳入更多低置信度样本扩大训练集规模，但同时引入噪声标签降低学习质量；当$\alpha$>0.7时，筛选条件过于严格，高质量伪标签数量减少，导致模型泛化能力受限。综上所述，实验结果有力支持将置信度阈值$\alpha$设定为0.7，作为FedPSG-PUM框架的最优置信度阈值,并将在后续实验中继续采用该配置。

实验二：基线对比实验，第一组实验在Bank和Credit两个数据集上进行。如表 \ref{Chapter4Exp2Table1} 所示，在单方本地生成模型中，TabDDPM在各缺失率条件下表现最优，其RMSE值分别为Bank数据集（0.4227、0.4728、0.5236）和Credit数据集（0.4478、0.5363、0.575），这验证了扩散模型在表格数据生成任务上的优越性。FedPSG-PUM方法在所有条件下均显著优于单方模型，且性能提升幅度显著。

\vspace{-0.1cm}
\begin{table}[H]
	\centering
	\bicaption[\xiaosi 在Bank和Credit数据集上不同方法在生成B方缺失样本时得到的RMSE]
	{\wuhao 不同方法在生成B方缺失样本时得到的RMSE在Bank和Credit数据集上}
	{\wuhao RMSE of different methods for Party B's missing samples in Bank and Credit datasets}
	\label{Chapter4Exp2Table1}
	\resizebox{\textwidth}{!}{
		{\wuhao \songti
			\begin{tabular}{ccccccc}
				\toprule[1.5pt]
				\multirow{2}{*}{\diagbox{Methods}{Dataset \& MisR-B}} 
				& \multicolumn{3}{c}{Bank} 
				& \multicolumn{3}{c}{Credit} \\
				\cmidrule[0.75pt](lr){2-4} \cmidrule[0.75pt](lr){5-7}
				& 0.2 & 0.5 & 0.8 & 0.2 & 0.5 & 0.8 \\
				\midrule[0.75pt]
				CTGAN           & 0.5099 & 0.5213 & 0.7554 & 0.5456 & 0.6385 & 0.6600 \\
				TableGAN        & 0.5951 & 0.6865 & 0.7312 & 0.6008 & 0.6975 & 0.7838 \\
				CTAB-GAN        & 0.4773 & 0.5644 & 0.6454 & 0.5533 & 0.6674 & 0.6976 \\
				TVAE            & 0.4265 & 0.4862 & 0.6970 & 0.4305 & 0.5534 & 0.6740 \\
				TabDDPM         & 0.4227 & 0.4728 & 0.5236 & 0.4478 & 0.5363 & 0.5750 \\
				FedPSG-PUM(TabDDPM) & 0.2143 & 0.2208 & 0.2436 & 0.3513 & 0.3745 & 0.4353 \\
				FedPSG-PUM(VF-GAIN) & 0.2097 & 0.2115 & 0.2311 & 0.3487 & 0.3681 & 0.4153 \\
				\bottomrule[1.5pt]
			\end{tabular}
		}
	}
\end{table}
\vspace{-0.4cm}

以Bank数据集为例，FedPSG-PUM(VF-GAIN)在MisR-B=0.2时的RMSE仅为0.2097，相比最佳基线模型TabDDPM（0.4227）降低了50.4\%，体现了联邦学习框架在样本生成任务中的显著优势。随着缺失率MisR-B从0.2增加到0.8，所有模型性能均有所下降，但FedPSG-PUM方法的性能降幅明显小于单方模型。例如，在Bank数据集上，TabDDPM的RMSE增加了23.9\%（0.4227→0.5236），而FedPSG-PUM(VF-GAIN)仅增加了10.2\%（0.2097→0.2311）。在FedPSG-PUM框架下，基于VF-GAIN的实现略优于基于TabDDPM的实现，特别是在高缺失率条件下差异更为明显，这表明VF-GAIN在联邦环境中能更有效地捕获数据分布特征。

\vspace{-0.1cm}
\begin{table}[H]
	\centering
	\bicaption
	[\xiaosi 在Letter和News数据集上不同方法在生成B方缺失样本时得到的RMSE]
	{\wuhao 在Letter和News数据集上不同方法在生成B方缺失样本时得到的RMSE}
	{\wuhao RMSE of different methods for Party B's missing samples in Letter and News Dataset}
	\label{Chapter4Exp2Table2}
	\resizebox{\textwidth}{!}{
		{\wuhao \songti
			\begin{tabular}{ccccccc}
				\toprule[1.5pt]
				\multirow{2}{*}{\diagbox{Methods}{Dataset \& MisR-B}} 
				& \multicolumn{3}{c}{Letter} 
				& \multicolumn{3}{c}{News} \\
				\cmidrule[0.75pt](lr){2-4} \cmidrule[0.75pt](lr){5-7}
				& 0.2 & 0.5 & 0.8 & 0.2 & 0.5 & 0.8 \\
				\midrule[0.75pt]
				CTGAN            & 0.5328 & 0.5664 & 0.6218 & 0.5209 & 0.5626 & 0.6034 \\
				TableGAN         & 0.5398 & 0.6148 & 0.7068 & 0.4722 & 0.5204 & 0.6234 \\
				CTAB-GAN        & 0.5226 & 0.5610 & 0.6559 & 0.4815 & 0.5220 & 0.6572 \\
				TVAE            & 0.5203 & 0.5614 & 0.6634 & 0.5018 & 0.5492 & 0.6348 \\
				TabDDPM         & 0.4921 & 0.5413 & 0.5833 & 0.4550 & 0.5024 & 0.5671 \\
				FedPSG-PUM(TabDDPM) & 0.3298 & 0.3674 & 0.3865 & 0.4116 & 0.4492 & 0.4560 \\
				FedPSG-PUM(VF-GAIN) & 0.2941 & 0.3423 & 0.3542 & 0.4333 & 0.4553 & 0.4650 \\
				\bottomrule[1.5pt]
			\end{tabular}
		}
	}
\end{table}
\vspace{-0.4cm}

第二组实验在Letter和News两个数据集上进行，表 \ref{Chapter4Exp2Table2} 显示了在这两个数据集上的RMSE结果。综合来看，单方本地生成方法中TabDDPM依然相对表现优异（如Letter数据集在MisR-B=0.5时可达0.5413；News数据集在MisR-B=0.8时为0.5671），但相比第一组实验，其他生成模型（如TVAE、CTAB-GAN 等）有时在局部指标上也可获得较为接近的性能。联邦协作方式下，FedPSG-PUM(VF-GAIN)和FedPSG-PUM(TabDDPM)再度显现出更为优异的能力，其中FedPSG-PUM(VF-GAIN)在MisR-B=0.2时于Letter数据集得到0.2941的RMSE、在News数据集MisR-B=0.5时取得0.4553，平均而言较单方方法提升幅度超过10\%-20\%。


FedPSG-PUM 的优势在于结合了纵向联邦半监督方法和填补：利用A方与B方间对齐的样本维度信息，在一定程度上缓解了单方数据不足带来的泛化性能损失；基于联邦半监督VFPU-M算法，对于可信度较高的样本可进行跨方协同训练，从而充分学习潜在的特征分布；VF-GAIN填补模块在补全缺失值时，结合了生成对抗网络与变分推断的优势，进一步提高了缺失数据恢复的精准度。正由于此，FedPSG-PUM(VF-GAIN)与FedPSG-PUM(TabDDPM)在多组实验设置下均呈现较低的RMSE，其中以FedPSG-PUM(VF-GAIN)的平均误差下降幅度更为显著。尤其在高缺失率（MisR-B = 0.8）情形下，FedPSG-PUM(VF-GAIN)在四个数据集的综合RMSE均优于其他方法。

实验三：样本生成效果对比，本实验对FedPSG-CAG、TabDDPM、A∞B-GM和N-GM四种数据处理方法生成的联合样本量进行统计分析，得出以下结论：（1）基于样本生成的FedPSG-CAG、TabDDPM与A∞B-GM三类方法均实现了完整的样本对齐：FedPSG-CAG和TabDDPM通过为B方生成与A方未对齐样本相匹配的补偿数据，使联合样本量达到A方原始样本总量；而A∞B-GM虽然采用VertiGAN生成与B方缺失量相当的合成数据，但由于其生成过程严格遵循A方样本分布特征，最终联合样本量仍由A方数据规模决定。（2）N-GM方法在联合数据集构建过程中表现出显著差异性。该方法采用严格样本对齐机制，当A方样本无法与B方缺失样本形成对应关系时，系统将主动丢弃A方未对齐样本。这种选择性保留机制导致最终联合样本规模受限于B方原始样本基数，因此其构建的联合数据集样本量呈现最小值，显著低于其他三种生成增强方法。

如图 \ref{Chapter4Exp3Bank} 所示，在Bank数据集中，无论B方特征缺失比例如何，采用FedPSG-PUM生成B方缺失样本并构建的联合样本集在所有评估指标（ACC、AUC、F1）上均取得了最佳表现，且这一结果对VF-LR、VF-SVM、VF-GBDT、VF-RF和FinalNet五种纵向联邦分类模型皆适用。与之相比，TabDDPM、A∞B-GM和N-GM三种方法的模型性能依次下降。基于实验结果可从以下两个方面进行分析：  

（1）样本数量角度：FedPSG-PUM、TabDDPM与A∞B-GM三种方法均可生成与A方样本数目相当的B方补偿样本，使联合数据集规模相同；而N-GM仅能对齐B方已有样本，导致其最终联合样本量最少。如图 \ref{Chapter4Exp3Bank} 所示，在两个数据集中，无论缺失比例如何，N-GM构建的联合数据集在各项评估指标上均表现最差。这一结果说明，当其他条件相同的情况下，联合样本量对纵向联邦模型的分类性能具有关键影响。随着B方特征缺失比例上升，N-GM生成的联合样本量急剧下降，导致五种纵向联邦模型的评估指标均明显降低，尤其对于深度神经网络框架FinalNet而言，因其对样本量更加敏感，指标降幅更为显著。这表明在深度学习等复杂模型的纵向联邦训练中，充足的样本量至关重要，而FedPSG-PUM在提升联合样本数量方面具有显著优势。

\vspace{-0.1cm}
\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{chapters/imgs/Chapter4Exp3Bank}
	\bicaption[\xiaosi 样本生成效果对比（Bank数据集）]
	{\wuhao 样本生成效果对比（Bank数据集）}
	{\wuhao Sample generation effect comparison (Bank Dataset)}
	\label{Chapter4Exp3Bank}
\end{figure}
\vspace{-0.5cm}

（2）样本质量角度：尽管FedPSG-PUM、TabDDPM与A∞B-GM这三类方法均实现了与A方数据规模相当的联合样本集，但它们所生成的样本质量存在差异。FedPSG-PUM和TabDDPM均保留了A方的全部真实数据，联合数据中真实样本所占比例较高；而A∞B-GM需要在A方分布的基础上通过VertiGAN生成全新样本，相应地，其联合样本的真实性略逊于前两种方法。进一步而言，FedPSG-PUM不仅能有效学习B方本地高相关属性的分布特征，还可利用多方数据间的关联信息生成更优质的补偿样本，因而在TabDDPM方法之上实现了进一步提升。实验证明，即使在B方高缺失比例条件下，FedPSG-PUM仍能够提供更高质量的训练数据，从而在多种纵向联邦模型中展现更优性能。这也表明纵向联邦学习不仅需要充分的样本数量，还需兼顾样本质量，二者对于模型性能提升同样重要。
\section{本章小结}
本章主要介绍了基于联邦半监督学习的样本参与方生成方法（FedPSG-PUM），旨在有效解决纵向联邦学习中由于样本未对齐导致的特征缺失问题。首先，通过问题分析与定义，明确了纵向联邦学习场景下样本未对齐问题的特征缺失本质，提出了基于联邦半监督学习与表格数据生成相结合的总体解决思路。

接下来，详细阐述了FedPSG-PUM方法的整体框架，包括跨方特征相关性分析、纵向联邦半监督学习预测缺失数据、以及基于生成模型补全低相关性特征等三个主要流程。在跨方特征相关性分析阶段，本章采用了隐私保护下的Spearman秩相关方法，通过同态加密技术保护数据隐私，系统性地计算了跨方特征相关性矩阵。在纵向联邦半监督学习预测阶段，提出了多任务联邦半监督算法VFPU-M，以高效生成高相关性的缺失特征。对于相关性较低的特征，本章引入生成模型（如VF-GAIN和TabDDPM）进一步提高缺失数据生成质量。

在实验验证与分析环节，本章基于UCI机器学习库中四个真实数据集（Bank、Credit、Letter、News）开展了广泛的实验研究与性能评估。实验结果表明，相较于现有方法（如单方生成模型TabDDPM与联邦样本生成方法VertiGAN），FedPSG-PUM在数据生成质量与联合训练模型性能两个方面均表现出明显优势。在不同的缺失率条件下，FedPSG-PUM方法构建的联合样本集不仅在数量上满足联邦训练需求，在质量上也更贴近真实数据分布，从而显著提升了纵向联邦分类模型的泛化性能和鲁棒性。

综上所述，FedPSG-PUM方法通过融合联邦半监督学习与生成模型技术，有效解决了纵向联邦学习场景下的特征缺失问题，实现了非对齐数据的高效利用。实验验证充分证明了其在数据隐私保护前提下的优越性与实用性，为纵向联邦学习框架的进一步研究与应用提供了理论基础和方法支持。