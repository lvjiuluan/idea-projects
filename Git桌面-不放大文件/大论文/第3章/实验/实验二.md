```
\subsubsection{RQ2: Impact of different base estimators on VFPU}

To evaluate the effectiveness of different base estimators, namely VFPU\_LR, VFPU\_GBDT, VFPU\_RF, and VFPU\_LGB, we conducted an experiment with four evaluation metrics including Precision, Recall, F-score and precision-recall. In this experiment, we observed the trends of these metrics as the number of reliable positive samples increases. Based on these trends, we select the optimal base estimator. The experimental results are illustrated in \autoref{RQ2.1} to \autoref{RQ2.3}. In this experiment, a random sampling technique was utilized to select a reliable subset of positive samples from the unlabeled dataset.

For the LR algorithm, we configured the L2 penalty term coefficient to 0.8, the learning rate to 0.001, and the batch size to 64. For the tree-based algorithms, we set the number of trees to 50, the tree depth to 6, and the learning rate to 0.1. These settings were applied consistently across all three datasets.

As shown in \autoref{RQ2.1}, all results are based on the Bank Marketing dataset. In \hyperref[RQ2.1.sub1]{Fig. 2 (1)} to \hyperref[RQ2.1.sub3]{Fig. 2 (3)}, the x-axis represents the number of reliable positive samples identified by the classifier, ranging from about 100 to 2293. The y-axis represents the accuracy, recall and F-score, respectively, and the larger the value is, the better the classifier works. \hyperref[RQ2.1.sub4]{Figure 2 (4)} depicts the precision-recall curve, the x-axis and y-axis represent precision and recall, respectively, and the closer the curve is to the upper right corner, the better the classifier works. \autoref{RQ2.2} and \autoref{RQ2.3} follow the same structure as \autoref{RQ2.1} but utilize the Default of Credit Card Clients and the Adult Census datasets, respectively.

\autoref{RQ2.1} illustrates that the VFPU\_GBDT estimator outperforms other models in precision, recall, and F-score across all sample sizes on the Bank Marketing dataset. For instance, in \hyperref[RQ2.1.sub1]{Fig. 2 (1)-(3)}, given 1500 reliable positive samples, the precisions of VFPU\_LR, VFPU\_GBDT, VFPU\_RF, VFPU\_LGB, and Random are 44.43\%, 51.94\%, 49.81\%, 43.72\%, and 4.73\%, respectively. Correspondingly, their recalls are 14.78\%, 17.28\%, 15.24\%, 14.55\%, and 4.61\%, while their F-scores are 0.22, 0.26, 0.23, 0.22, and 0.05, respectively. While the VFPU\_RF estimator is a close competitor in precision, its performance declines more rapidly and lags behind VFPU\_GBDT in recall and F-score. The VFPU\_LR and VFPU\_LGB models exhibit lower overall precision and marginally lower recall, remaining relatively stable with changing sample sizes. Overall, \hyperref[RQ2.1.sub1]{Fig. 2 (1)-(3)} show that the VFPU\_GBDT estimator presents superior performance with a balanced outcome in both precision and recall, evidenced by the highest F-scores. \hyperref[RQ2.1.sub4]{Fig. 2 (4)} presents the Precision-Recall curves for different base estimators created by plotting Precision against Recall at various thresholds. This curve is particularly useful when handling imbalanced datasets. A higher-performing model closely follows the curve along the right-hand and top borders of the Precision-Recall space. Evidently, the VFPU\_GBDT curve has a closer proximity to the upper right quadrant, indicating its superior performance compared to the other base estimators.
Further evidence supporting RQ2 is found in \autoref{RQ2.2} and \autoref{RQ2.3}. These figures based on different datasets present results analogous to those in \autoref{RQ2.1}, and their overall trends and conclusions remain consistent. 

In conclusion, VFPU\_GBDT consistently outperforms VFPU\_LR, VFPU\_RF, VFPU\_LGB, and the random sampling technique across all datasets. Therefore, GBDT stands out as the most reliable base estimator for the VFPU algorithm in addressing our UDD-PU problem. The following experiments use GBDT as the base esitmator for our method VFPU.

```

# 扩写后

```
\subsubsection{RQ2: Impact of different base estimators on VFPU}

In this section, we present an in-depth evaluation of different base estimators, namely VFPU\_LR, VFPU\_GBDT, VFPU\_RF, and VFPU\_LGB, which have been integrated into our VFPU framework to address the UDD-PU problem. To comprehensively assess their performance, we conducted a series of experiments that focus on four key evaluation metrics: Precision, Recall, F-score, and the precision-recall curve. The primary objective of this evaluation is to analyze the trends in these metrics as the number of reliable positive samples increases, and, based on these observed trends, to identify the optimal base estimator for our method.

In our experiments, we employed a random sampling strategy to select a reliable subset of positive samples from an otherwise unlabeled dataset. This approach not only simulates realistic conditions under which few positive instances might be known a priori but also rigorously tests the robustness of each base estimator in leveraging these limited samples. The results of our experiments are detailed in \autoref{RQ2.1} through \autoref{RQ2.3}.

For the Logistic Regression (LR) based algorithm, specific hyperparameters were configured as follows: we applied an L2 penalty with a coefficient set to 0.8, a learning rate of 0.001, and a mini-batch size of 64. These parameters were carefully chosen based on preliminary experimentation to ensure a balance between convergence speed and model generalization. On the other hand, for all tree-based algorithms—namely the Gradient Boosting Decision Trees (GBDT), Random Forest (RF), and LightGBM (LGB)—we set the number of trees to 50, limited the tree depth to 6 to avoid overfitting, and used a learning rate of 0.1. This uniform setting across the three datasets enabled a fair comparison of their performance under consistent experimental conditions.

\autoref{RQ2.1} presents the experimental results on the Bank Marketing dataset. In \hyperref[RQ2.1.sub1]{Fig. 2 (1)} to \hyperref[RQ2.1.sub3]{Fig. 2 (3)}, the x-axis represents the number of reliable positive samples obtained by the classifier, spanning from approximately 100 to 2293 reliable samples. The y-axis in each of these sub-figures corresponds to the evaluation metrics of accuracy, recall, and F-score, respectively; in this context, a higher value on the y-axis indicates better classification performance. Additionally, \hyperref[RQ2.1.sub4]{Figure 2 (4)} demonstrates the precision-recall curve, where the x-axis is the precision and the y-axis is the recall. A model whose curve is closer to the upper-right boundary of the plot indicates a stronger performance, particularly in scenarios characterized by imbalanced data distributions.

An exploration of \autoref{RQ2.1} reveals that the VFPU\_GBDT estimator outperforms the other models across the Bank Marketing dataset. For example, as evidenced in \hyperref[RQ2.1.sub1]{Fig. 2 (1)-(3)}, when 1500 reliable positive samples are utilized, VFPU\_LR, VFPU\_GBDT, VFPU\_RF, VFPU\_LGB, and a model based on random sampling achieve precisions of 44.43\%, 51.94\%, 49.81\%, 43.72\%, and 4.73\%, respectively. Corresponding recall values recorded are 14.78\%, 17.28\%, 15.24\%, 14.55\%, and 4.61\%, while the F-scores for these models are 0.22, 0.26, 0.23, 0.22, and 0.05, respectively. Although the VFPU\_RF estimator shows relatively comparable precision in some instances, its performance degrades more rapidly as the number of reliable samples increases, particularly in terms of recall and F-score. In contrast, the VFPU\_LR and VFPU\_LGB models, while stable across varying sample sizes, do not match the overall performance in terms of both precision and recall exhibited by VFPU\_GBDT. Consequently, \hyperref[RQ2.1.sub1]{Fig. 2 (1)-(3)} clearly demonstrate that VFPU\_GBDT not only delivers superior precision but also maintains a balanced trade-off with recall, resulting in the highest F-scores among the evaluated models.

Moreover, the precision-recall curve in \hyperref[RQ2.1.sub4]{Fig. 2 (4)} further validates the robustness of VFPU\_GBDT. By plotting Precision against Recall at various threshold settings, this curve effectively captures the performance dynamics of the classifier, especially in datasets where class imbalance is a critical concern. The closeness of the VFPU\_GBDT curve to the upper right quadrant of the plot is indicative of its strong performance across multiple thresholds—this characteristic is hallmark in high-performing models in imbalanced classification tasks.

Further supportive evidence for the effectiveness of the VFPU\_GBDT estimator is provided in \autoref{RQ2.2} and \autoref{RQ2.3}. These figures report analogous experiments conducted on the Default of Credit Card Clients and the Adult Census datasets, respectively. Despite the datasets differing in intrinsic characteristics and distribution properties, the experimental outcomes in these cases reflect trends similar to those observed in \autoref{RQ2.1}. The consistent superiority of VFPU\_GBDT across diverse datasets reinforces its reliability and effectiveness when employed as the base estimator within the VFPU framework.

In summary, the experimental results across all three benchmark datasets consistently indicate that VFPU\_GBDT outperforms VFPU\_LR, VFPU\_RF, VFPU\_LGB, as well as the baseline random sampling technique. The superior performance of VFPU\_GBDT, as manifested by its higher precision, recall, and the balanced F-scores, makes it the most reliable and recommended base estimator for the VFPU algorithm when solving the UDD-PU problem. Therefore, in all subsequent experiments, we adopt GBDT as the base estimator for our VFPU method, leveraging its demonstrated advantages in achieving accurate and balanced classifications under challenging conditions.
```

# 翻译

```
### \subsubsection{RQ2: VFPU中不同基估计器的影响}

在这一部分，我们对集成在我们VFPU框架中的不同基估计器进行了深入评估，这些估计器包括**VFPU_LR**、**VFPU_GBDT**、**VFPU_RF**和**VFPU_LGB**，它们被用于解决UDD-PU问题。为了全面评估它们的性能，我们进行了一系列实验，重点关注四个关键评估指标：**精确度（Precision）**、**召回率（Recall）**、**F-score**以及**精确度-召回率曲线**。本次评估的主要目标是分析这些指标随着可靠正样本数量增加的变化趋势，并根据这些观察到的趋势，确定我们方法的最佳基估计器。

在实验中，我们采用**随机抽样策略**从一个未标记的数据集中选择可靠的正样本子集。这种方法不仅模拟了现实情况下可能已知少量正实例的条件，还严格测试了每个基估计器在利用这些有限样本时的鲁棒性。实验结果详见**\autoref{RQ2.1}**至**\autoref{RQ2.3}**。

对于基于**逻辑回归（LR）**的算法，我们配置了以下特定超参数：应用了**L2惩罚**，系数设置为**0.8**，学习率为**0.001**，小批量大小为**64**。这些参数基于初步实验精心选择，以确保收敛速度和模型泛化能力之间的平衡。另一方面，对于所有基于树的算法——即**梯度提升决策树（GBDT）**、**随机森林（RF）**和**LightGBM（LGB）**——我们将树的数量设置为**50**，树深限制为**6**以避免过拟合，并使用**0.1**的学习率。这种在三个数据集上的统一设置，使得在一致的实验条件下公平比较它们的性能成为可能。

**\autoref{RQ2.1}**展示了在**银行营销数据集**上的实验结果。在**\hyperref[RQ2.1.sub1]{图2(1)}**至**\hyperref[RQ2.1.sub3]{图2(3)}**中，x轴表示分类器获得的可靠正样本数量，范围从大约**100**到**2293**个可靠样本。这些子图中的y轴分别对应于**准确度**、**召回率**和**F-score**的评估指标；在此背景下，y轴上的值越高表示分类性能越好。此外，**\hyperref[RQ2.1.sub4]{图2(4)}**展示了**精确度-召回率曲线**，其中x轴为精确度，y轴为召回率。曲线上更接近图右上角的模型表明其性能更强，特别是在数据分布不平衡的情况下。

对**\autoref{RQ2.1}**的探索表明，**VFPU_GBDT**估计器在银行营销数据集上的表现优于其他模型。例如，如**\hyperref[RQ2.1.sub1]{图2(1)-(3)}**所示，当利用**1500**个可靠正样本时，**VFPU_LR**、**VFPU_GBDT**、**VFPU_RF**、**VFPU_LGB**和基于随机抽样的模型分别实现了**44.43\%**、**51.94\%**、**49.81\%**、**43.72\%**和**4.73\%**的精确度。相应的召回率记录为**14.78\%**、**17.28\%**、**15.24\%**、**14.55\%**和**4.61\%**，而这些模型的F-score分别为**0.22**、**0.26**、**0.23**、**0.22**和**0.05**。尽管**VFPU_RF**估计器在某些情况下显示出相对可比较的精确度，但随着可靠样本数量的增加，其性能（特别是在召回率和F-score方面）下降得更快。相比之下，**VFPU_LR**和**VFPU_LGB**模型虽然在不同样本大小下表现稳定，但并未达到**VFPU_GBDT**在精确度和召回率方面表现出的整体性能。因此，**\hyperref[RQ2.1.sub1]{图2(1)-(3)}**清楚地表明，**VFPU_GBDT**不仅提供了更高的精确度，而且在召回率之间保持了平衡的权衡，从而在评估的模型中实现了最高的F-score。

此外，**\hyperref[RQ2.1.sub4]{图2(4)}**中的精确度-召回率曲线进一步验证了**VFPU_GBDT**的鲁棒性。通过在各种阈值设置下绘制精确度对召回率的曲线，该曲线有效地捕捉了分类器的性能动态，特别是在类不平衡是关键问题的场景中。**VFPU_GBDT**曲线更接近图的右上象限，表明其在多个阈值下的强大性能——这是不平衡分类任务中高性能模型的标志。

**\autoref{RQ2.2}**和**\autoref{RQ2.3}**提供了**VFPU_GBDT**估计器有效性的进一步支持证据。这些图报告了在**信用卡违约**和**成人普查**数据集上进行的类似实验。尽管数据集在内在特性和分布属性上有所不同，但这些情况下的实验结果反映了与**\autoref{RQ2.1}**中观察到的相似趋势。**VFPU_GBDT**在不同数据集上的一致优越性增强了其在VFPU框架中作为基估计器时的可靠性和有效性。

总结来说，三个基准数据集上的实验结果一致表明，**VFPU_GBDT**优于**VFPU_LR**、**VFPU_RF**、**VFPU_LGB**以及基线随机抽样技术。**VFPU_GBDT**的优越性能，表现为更高的精确度、召回率和平衡的F-score，使其成为在解决UDD-PU问题时VFPU算法最可靠和推荐的基估计器。因此，在所有后续实验中，我们采用**GBDT**作为VFPU方法的基估计器，利用其在挑战性条件下实现准确和平衡分类的明显优势。
```

```
### \subsubsection{RQ2: VFPU中不同基估计器的影响}

在这一部分，我们对集成在我们VFPU框架中的不同基估计器进行了深入评估，这些估计器包括VFPU_LR、VFPU_GBDT、VFPU_RF和VFPU_LGB，它们被用于解决UDD-PU问题。为了全面评估它们的性能，我们进行了一系列实验，重点关注四个关键评估指标：精确度（Precision）、召回率（Recall）、F-score以及精确度-召回率曲线。本次评估的主要目标是分析这些指标随着可靠正样本数量增加的变化趋势，并根据这些观察到的趋势，确定我们方法的最佳基估计器。

在实验中，我们采用随机抽样策略从一个未标记的数据集中选择可靠的正样本子集。这种方法不仅模拟了现实情况下可能已知少量正实例的条件，还严格测试了每个基估计器在利用这些有限样本时的鲁棒性。实验结果详见\autoref{RQ2.1}至\autoref{RQ2.3}。

对于基于逻辑回归（LR）的算法，我们配置了以下特定超参数：应用了L2惩罚，系数设置为0.8，学习率为0.001，小批量大小为64。这些参数基于初步实验精心选择，以确保收敛速度和模型泛化能力之间的平衡。另一方面，对于所有基于树的算法——即梯度提升决策树（GBDT）、随机森林（RF）和LightGBM（LGB）——我们将树的数量设置为50，树深限制为6以避免过拟合，并使用0.1的学习率。这种在三个数据集上的统一设置，使得在一致的实验条件下公平比较它们的性能成为可能。

\autoref{RQ2.1}展示了在银行营销数据集上的实验结果。在\hyperref[RQ2.1.sub1]{图2(1)}至\hyperref[RQ2.1.sub3]{图2(3)}中，x轴表示分类器获得的可靠正样本数量，范围从大约100到2293个可靠样本。这些子图中的y轴分别对应于准确度、召回率和F-score的评估指标；在此背景下，y轴上的值越高表示分类性能越好。此外，\hyperref[RQ2.1.sub4]{图2(4)}展示了精确度-召回率曲线，其中x轴为精确度，y轴为召回率。曲线上更接近图右上角的模型表明其性能更强，特别是在数据分布不平衡的情况下。

对\autoref{RQ2.1}的探索表明，VFPU_GBDT估计器在银行营销数据集上的表现优于其他模型。例如，如\hyperref[RQ2.1.sub1]{图2(1)-(3)}所示，当利用1500个可靠正样本时，VFPU_LR、VFPU_GBDT、VFPU_RF、VFPU_LGB和基于随机抽样的模型分别实现了44.43\%、51.94\%、49.81\%、43.72\%和4.73\%的精确度。相应的召回率记录为14.78\%、17.28\%、15.24\%、14.55\%和4.61\%，而这些模型的F-score分别为0.22、0.26、0.23、0.22和0.05。尽管VFPU_RF估计器在某些情况下显示出相对可比较的精确度，但随着可靠样本数量的增加，其性能（特别是在召回率和F-score方面）下降得更快。相比之下，VFPU_LR和VFPU_LGB模型虽然在不同样本大小下表现稳定，但并未达到VFPU_GBDT在精确度和召回率方面表现出的整体性能。因此，\hyperref[RQ2.1.sub1]{图2(1)-(3)}清楚地表明，VFPU_GBDT不仅提供了更高的精确度，而且在召回率之间保持了平衡的权衡，从而在评估的模型中实现了最高的F-score。

此外，\hyperref[RQ2.1.sub4]{图2(4)}中的精确度-召回率曲线进一步验证了VFPU_GBDT的鲁棒性。通过在各种阈值设置下绘制精确度对召回率的曲线，该曲线有效地捕捉了分类器的性能动态，特别是在类不平衡是关键问题的场景中。VFPU_GBDT曲线更接近图的右上象限，表明其在多个阈值下的强大性能——这是不平衡分类任务中高性能模型的标志。

\autoref{RQ2.2}和\autoref{RQ2.3}提供了VFPU_GBDT估计器有效性的进一步支持证据。这些图报告了在信用卡违约和成人普查数据集上进行的类似实验。尽管数据集在内在特性和分布属性上有所不同，但这些情况下的实验结果反映了与\autoref{RQ2.1}中观察到的相似趋势。VFPU_GBDT在不同数据集上的一致优越性增强了其在VFPU框架中作为基估计器时的可靠性和有效性。

总结来说，三个基准数据集上的实验结果一致表明，VFPU_GBDT优于VFPU_LR、VFPU_RF、VFPU_LGB以及基线随机抽样技术。VFPU_GBDT的优越性能，表现为更高的精确度、召回率和平衡的F-score，使其成为在解决UDD-PU问题时VFPU算法最可靠和推荐的基估计器。因此，在所有后续实验中，我们采用GBDT作为VFPU方法的基估计器，利用其在挑战性条件下实现准确和平衡分类的明显优势。

```

```
在这一部分，对集成在VFPU框架中的不同基估计器进行了深入评估，这些估计器包括VFPU_LR、VFPU_GBDT、VFPU_RF和VFPU_LGB，它们被用于解决UDD-PU问题。为了全面评估它们的性能，进行了一系列实验，重点关注四个关键评估指标：精确度（Precision）、召回率（Recall）、F-score以及精确度-召回率曲线。本次评估的主要目标是分析这些指标随着可靠正样本数量增加的变化趋势，并根据这些观察到的趋势，确定方法的最佳基估计器。

在实验中，采用随机抽样策略从一个未标记的数据集中选择可靠的正样本子集。这种方法不仅模拟了现实情况下可能已知少量正实例的条件，还严格测试了每个基估计器在利用这些有限样本时的鲁棒性。实验结果详见\autoref{RQ2.1}至\autoref{RQ2.3}。

对于基于逻辑回归（LR）的算法，配置了以下特定超参数：应用了L2惩罚，系数设置为0.8，学习率为0.001，小批量大小为64。这些参数基于初步实验精心选择，以确保收敛速度和模型泛化能力之间的平衡。另一方面，对于所有基于树的算法——即梯度提升决策树（GBDT）、随机森林（RF）和LightGBM（LGB）——将树的数量设置为50，树深限制为6以避免过拟合，并使用0.1的学习率。这种在三个数据集上的统一设置，使得在一致的实验条件下公平比较它们的性能成为可能。

\autoref{RQ2.1}展示了在银行营销数据集上的实验结果。在\hyperref[RQ2.1.sub1]{图2(1)}至\hyperref[RQ2.1.sub3]{图2(3)}中，x轴表示分类器获得的可靠正样本数量，范围从大约100到2293个可靠样本。这些子图中的y轴分别对应于准确度、召回率和F-score的评估指标；在此背景下，y轴上的值越高表示分类性能越好。此外，\hyperref[RQ2.1.sub4]{图2(4)}展示了精确度-召回率曲线，其中x轴为精确度，y轴为召回率。曲线上更接近图右上角的模型表明其性能更强，特别是在数据分布不平衡的情况下。

对\autoref{RQ2.1}的探索表明，VFPU_GBDT估计器在银行营销数据集上的表现优于其他模型。例如，如\hyperref[RQ2.1.sub1]{图2(1)-(3)}所示，当利用1500个可靠正样本时，VFPU_LR、VFPU_GBDT、VFPU_RF、VFPU_LGB和基于随机抽样的模型分别实现了44.43\%、51.94\%、49.81\%、43.72\%和4.73\%的精确度。相应的召回率记录为14.78\%、17.28\%、15.24\%、14.55\%和4.61\%，而这些模型的F-score分别为0.22、0.26、0.23、0.22和0.05。尽管VFPU_RF估计器在某些情况下显示出相对可比较的精确度，但随着可靠样本数量的增加，其性能（特别是在召回率和F-score方面）下降得更快。相比之下，VFPU_LR和VFPU_LGB模型虽然在不同样本大小下表现稳定，但并未达到VFPU_GBDT在精确度和召回率方面表现出的整体性能。因此，\hyperref[RQ2.1.sub1]{图2(1)-(3)}清楚地表明，VFPU_GBDT不仅提供了更高的精确度，而且在召回率之间保持了平衡的权衡，从而在评估的模型中实现了最高的F-score。

此外，\hyperref[RQ2.1.sub4]{图2(4)}中的精确度-召回率曲线进一步验证了VFPU_GBDT的鲁棒性。通过在各种阈值设置下绘制精确度对召回率的曲线，该曲线有效地捕捉了分类器的性能动态，特别是在类不平衡是关键问题的场景中。VFPU_GBDT曲线更接近图的右上象限，表明其在多个阈值下的强大性能——这是不平衡分类任务中高性能模型的标志。

\autoref{RQ2.2}和\autoref{RQ2.3}提供了VFPU_GBDT估计器有效性的进一步支持证据。这些图报告了在信用卡违约和成人普查数据集上进行的类似实验。尽管数据集在内在特性和分布属性上有所不同，但这些情况下的实验结果反映了与\autoref{RQ2.1}中观察到的相似趋势。VFPU_GBDT在不同数据集上的一致优越性增强了其在VFPU框架中作为基估计器时的可靠性和有效性。

总结来说，三个基准数据集上的实验结果一致表明，VFPU_GBDT优于VFPU_LR、VFPU_RF、VFPU_LGB以及基线随机抽样技术。VFPU_GBDT的优越性能，表现为更高的精确度、召回率和平衡的F-score，使其成为在解决UDD-PU问题时VFPU算法最可靠和推荐的基估计器。因此，在所有后续实验中，采用GBDT作为VFPU方法的基估计器，利用其在挑战性条件下实现准确和平衡分类的明显优势。
```

```
在这一部分，对集成在VFPU框架中的不同基估计器进行了深入评估，这些估计器包括VFPU\_LR、VFPU\_GBDT、VFPU\_RF和VFPU\_LGB，它们被用于解决UDD-PU问题。为了全面评估它们的性能，进行了一系列实验，重点关注四个关键评估指标：精确度（Precision）、召回率（Recall）、F-score以及精确度-召回率曲线。本次评估的主要目标是分析这些指标随着可靠正样本数量增加的变化趋势，并根据这些观察到的趋势，确定方法的最佳基估计器。

在实验中，采用随机抽样策略从一个未标记的数据集中选择可靠的正样本子集。这种方法不仅模拟了现实情况下可能已知少量正实例的条件，还严格测试了每个基估计器在利用这些有限样本时的鲁棒性。实验结果详见\autoref{RQ2.1}至\autoref{RQ2.3}。

对于基于逻辑回归（LR）的算法，配置了以下特定超参数：应用了L2惩罚，系数设置为0.8，学习率为0.001，小批量大小为64。这些参数基于初步实验精心选择，以确保收敛速度和模型泛化能力之间的平衡。另一方面，对于所有基于树的算法——即梯度提升决策树（GBDT）、随机森林（RF）和LightGBM（LGB）——将树的数量设置为50，树深限制为6以避免过拟合，并使用0.1的学习率。这种在三个数据集上的统一设置，使得在一致的实验条件下公平比较它们的性能成为可能。

\autoref{RQ2.1}展示了在银行营销数据集上的实验结果。在\hyperref[RQ2.1.sub1]{图2(1)}至\hyperref[RQ2.1.sub3]{图2(3)}中，x轴表示分类器获得的可靠正样本数量，范围从大约100到2293个可靠样本。这些子图中的y轴分别对应于准确度、召回率和F-score的评估指标；在此背景下，y轴上的值越高表示分类性能越好。此外，\hyperref[RQ2.1.sub4]{图2(4)}展示了精确度-召回率曲线，其中x轴为精确度，y轴为召回率。曲线上更接近图右上角的模型表明其性能更强，特别是在数据分布不平衡的情况下。

对\autoref{RQ2.1}的探索表明，VFPU\_GBDT估计器在银行营销数据集上的表现优于其他模型。例如，如\hyperref[RQ2.1.sub1]{图2(1)-(3)}所示，当利用1500个可靠正样本时，VFPU\_LR、VFPU\_GBDT、VFPU\_RF、VFPU\_LGB和基于随机抽样的模型分别实现了44.43\%、51.94\%、49.81\%、43.72\%和4.73\%的精确度。相应的召回率记录为14.78\%、17.28\%、15.24\%、14.55\%和4.61\%，而这些模型的F-score分别为0.22、0.26、0.23、0.22和0.05。尽管VFPU\_RF估计器在某些情况下显示出相对可比较的精确度，但随着可靠样本数量的增加，其性能（特别是在召回率和F-score方面）下降得更快。相比之下，VFPU\_LR和VFPU\_LGB模型虽然在不同样本大小下表现稳定，但并未达到VFPU\_GBDT在精确度和召回率方面表现出的整体性能。因此，\hyperref[RQ2.1.sub1]{图2(1)-(3)}清楚地表明，VFPU\_GBDT不仅提供了更高的精确度，而且在召回率之间保持了平衡的权衡，从而在评估的模型中实现了最高的F-score。

此外，\hyperref[RQ2.1.sub4]{图2(4)}中的精确度-召回率曲线进一步验证了VFPU\_GBDT的鲁棒性。通过在各种阈值设置下绘制精确度对召回率的曲线，该曲线有效地捕捉了分类器的性能动态，特别是在类不平衡是关键问题的场景中。VFPU\_GBDT曲线更接近图的右上象限，表明其在多个阈值下的强大性能——这是不平衡分类任务中高性能模型的标志。

\autoref{RQ2.2}和\autoref{RQ2.3}提供了VFPU\_GBDT估计器有效性的进一步支持证据。这些图报告了在信用卡违约和成人普查数据集上进行的类似实验。尽管数据集在内在特性和分布属性上有所不同，但这些情况下的实验结果反映了与\autoref{RQ2.1}中观察到的相似趋势。VFPU\_GBDT在不同数据集上的一致优越性增强了其在VFPU框架中作为基估计器时的可靠性和有效性。

总结来说，三个基准数据集上的实验结果一致表明，VFPU\_GBDT优于VFPU\_LR、VFPU\_RF、VFPU\_LGB以及基线随机抽样技术。VFPU\_GBDT的优越性能，表现为更高的精确度、召回率和平衡的F-score，使其成为在解决UDD-PU问题时VFPU算法最可靠和推荐的基估计器。因此，在所有后续实验中，采用GBDT作为VFPU方法的基估计器，利用其在挑战性条件下实现准确和平衡分类的明显优势。
```

