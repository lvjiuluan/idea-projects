```
\subsubsection{Vertical federated learning with positive and unlabeled data}
The objective of the VFPU algorithm is to securely and efficiently identify reliable positive samples from the unlabeled data. The core of the algorithm lies in the combination of some PU learning techniques with the vertical federated framework. The PU techniques incorporated in VFPU include the two-step technique \cite{liu2003building} and the PU bagging method \cite{mordelet2014bagging}. This section provides a detailed explanation of VFPU, as outlined in Algorithm \ref{alg:cap}. 



\begin{enumerate}[label=(\arabic*)]
	\item Establishing initial sample sets
	
	Overall, the VFPU algorithm executes $M$ iterations, each consisting of $T$ rounds of random sampling, training and predicting.  In each iteration $m\in \{1,...,M\}$, the set of positive samples ${{P}_{m}}$ and the set of unlabeled samples ${{U}_{m}}$ are determined based on the labels provided by Party C as follows:
	\begin{equation}
		\begin{split}
			&{{P}_{m}}=\{i|\mathsf{\mathcal{Y}}_{i}^{C}=1,\ i\in {{\mathsf{\mathcal{I}}}_{C}}\};\\
			&{{U}_{m}}=\{i|\mathsf{\mathcal{Y}}_{i}^{C}=-1,\ i\in {{\mathsf{\mathcal{I}}}_{C}}\},
		\end{split}
	\end{equation}
	where ${{\mathsf{\mathcal{I}}}_{C}}$ is the ID space, ${{\mathsf{\mathcal{Y}}}^{C}}$ is the label space of party C, and $i$ is the sample ID.
	\item Sampling, training and predicting
	
	As shown in \autoref{fig:VFPU}, during the $t\text{-th} \ (\text{t}\in \{1,2,...,T\})$ round of sampling in the $m\text{-th}$ iteration, a pseudo-negative sample set $N_{m}^{t}$ is generated from ${{U}_{m}}$ using bootstrapping \cite{mordelet2014bagging}. Mathematically, this can be expressed as:
	\begin{equation}
		%				\small
		N_{m}^{t}=\{ \text{Randomly select} \ |P_{m}| \ \text{elements from} \ U_{m} \},
	\end{equation}
	where $|{{P}_{m}}|$ is the number of samples as contained in ${{P}_{m}}$.
	
	Since the actual categories of the unlabeled samples are unknown, $N_{m}^{t}$ is regarded as a set of pseudo-negative samples, potentially containing both genuine negative and positive samples. By drawing $|{{P}_{m}}|$ elements from ${{U}_{m}}$, we can create $N_{m}^{t}$ with the same size as ${{P}_{m}}$.
	
	${{P}_{m}}$ and $N_{m}^{t}$ are combined into a binary classification training set during the training process. This set is used to train the vertical federated learning model, which learns to distinguish between positive and negative samples and applies this knowledge to future prediction tasks. 
	
	Bootstrapping is a technique that randomly selects samples from a dataset with replacement. Employing this technique allows VFPU to create diverse and balanced training sets, thus improving the model's generalization capabilities, reducing potential biases and enhancing the overall performance of the recommendation model.
	
	Samples not selected during the bootstrapping procedure are called out-of-bag samples. The out-of-bag score represents the predicted probability of the out-of-bag sample being classified as positive. Therefore, to obtain the set of out-of-bag samples $O_{m}^{t}$, we need to exclude samples in $N_{m}^{t}$ from ${{U}_{m}}$, which can be expressed mathematically as:
	\begin{equation}
		O_{m}^{t}={{U}_{m}}-N_{m}^{t}.
	\end{equation}
	
	Party C then encrypts and sends   $N_{m}^{t}$,  ${{P}_{m}}$, and $O_{m}^{t}$ t to other parties. Here in our example, the other party is Party B. Then, Party B and Party C establish their training and testing data based on the three sets of sample IDs they have received. Specifically, we have:
	\begin{equation}
		\begin{split}
			&\mathsf{\mathcal{D}}_{train}^{K}=\{(i,{{x}_{i}},{{y}_{i}})|i\in {{P}_{m}}\ or\ i\in N_{m}^{t}\};\\
			&\mathsf{\mathcal{D}}_{test}^{K}=\{(i,{{x}_{i}},{{y}_{i}})|i\in O_{m}^{t}\},
		\end{split}
	\end{equation}
	where $\mathsf{\mathcal{D}}_{train}^{K}$ represents the binary training data and $\mathsf{\mathcal{D}}_{test}^{K}$ denotes the testing data and $K\in \{B,C\}$. ${{x}_{i}}\in \mathsf{\mathcal{X}}$ and ${{y}_{i}}\in \mathsf{\mathcal{Y}}$.
	
	
	Once party B and party C have prepared their respective training and testing datasets, the binary classification problem transforms into a vertical federated training and predicting task. A base estimator, serving as a machine learning model for each party, is adapted for use within the VFL framework. It is crucial to grasp general training process of VFL \cite{yang2019federated}. Overall, it comprises four steps, illustrating how the base estimator is trained on the multi-party training data while preserving privacy. The four steps are as follows:
	\begin{itemize}
		\item Step 1: The server creates encryption pairs and sends a public key to parties B and C.
		\item Step 2: Parties B and C encrypt and exchange intermediate results for gradient and loss calculations.
		\item Step 3: Parties B and C compute encrypted gradients, add an additional mask, and calculate the encrypted loss. Encrypted values are then sent to the server.
		\item Step 4: The server decrypts and sends the decrypted gradients and loss back to party B and party C. Parties B and C unmask the gradients and update the model parameters accordingly.
	\end{itemize}
	
	Various privacy-preserving machine-learning algorithms have been proposed for the VFL framework in support of the general training process \cite{yang2019federated}, including logistic regression (LR) \cite{he2021secure,yang2019parallel}, random forest (RF) \cite{yao2022efficient}, gradient boosting decision tree (GBDT) \cite{he2021secure}, XGBoost (XGB) \cite{xu2021efficient,wang2022feverless} and LightGBM (LGB) \cite{feng2019securegbm}. In this paper, we will apply different base estimators to evaluate the performance of the recommendation model. 
	
	\begin{algorithm}[H]
		\caption{The proposed VFPU algorithm.}
		\label{alg:cap}
		\algrenewcommand\algorithmicrequire{\textbf{Input:}}
		\algrenewcommand\algorithmicensure{\textbf{Output:}}
		\begin{algorithmic}[1]
			\Require Parties $B,C$. Aligned datasets ${{\mathsf{\mathcal{D}}}_{B}}\text{,}{{\mathsf{\mathcal{D}}}_{C}}$  and ID sets ${{\mathsf{\mathcal{I}}}_{B}}\text{,}\ {{\mathsf{\mathcal{I}}}_{C}}$. Maximum number of iterations $M$, number of random sampling iterations $T$ and $\theta$ where $\theta$ is the sampling rate of reliable positive samples.
			\Ensure $R$, a set of reliable positive samples.
			\Procedure{Party C executes}{}
			\For {$m=1,2,\ldots,M$}
			\State ${{P}_{m}}=\{i|\mathsf{\mathcal{Y}}_{i}^{C}=1, \ i\in {{\mathsf{\mathcal{I}}}_{C}}\}$
			\State ${{U}_{m}}=\{i|\mathsf{\mathcal{Y}}_{i}^{C}=-1, \ i\in {{\mathsf{\mathcal{I}}}_{C}}\}$
			\For {$t=1,2,\ldots,T$}
			\State $N_{m}^{t}=\{Randomly\ select\ |{{P}_{m}}|\ elements\ from\ {{U}_{m}} \}$
			\State $O_{m}^{t}={{U}_{m}}-N_{m}^{t}$
			\State Encrypt and send $N_{m}^{t}$, ${P_m}$, and $O_{m}^{t}$ to other parties.
			\State Notify parties to set training data and testing data.
			\State $S_m^t$ = Base\_Estimator\_Learning()
			\EndFor
			\State ${{\mathsf{\mathcal{P}}}_{m}}(u)={\sum\nolimits_{t=1}^{T}{S_{m}^{t}}}(u)/{\sum\nolimits_{t=1}^{T}{I(u\in O_{m}^{t})\text{,}\ \ \forall \text{u}\in }}\;{{U}_{m}}$
			\State ${{R}_{m}}=\{Chose\ Top\ |{{U}_{m}}|\times \theta \ IDs\ from\ {{\mathsf{\mathcal{P}}}_{m}}\}$
			\State $\mathsf{\mathcal{Y}}_{r}^{C}=1\text{,}\ \ \forall r\in {{R}_{m}}$
			\EndFor
			\State $R=\bigcup\limits_{m=1}^{M}{{{R}_{m}}}$
			\EndProcedure
			
			\Function{Base\_Estimator\_Learning}{}():
			\State Server creates encryption pairs, sends public keys to $B$ \& $C$
			\State $B$ \& $C$ encrypt, exchange gradients \& losses.
			\State  $B$ \& $C$ add masks, send encrypted values to server.
			\State Server decrypts, sends back values. $B$ \& $C$ unmask, update models.
			\State \Return Predicted probabilities of positive class on testing data.
			\EndFunction
		\end{algorithmic}
	\end{algorithm}
	
	\item Identifying reliable positive samples
	
	During the $m\text{-th}$ iteration, the process of sampling, training, and predicting is carried out $T$ times. Upon completion of these $T$ rounds, sufficient information is collected to determine the set of probabilities, represented as ${{\mathsf{\mathcal{P}}}_{m}}$, for all unlabeled samples in ${{U}_{m}}$. These probabilities correspond to the likelihood of each sample being regarded as the positive class and can be employed for subsequent decision-making processes, such as pinpointing reliable positive samples and updating training sets.
	
	To derive the entire set ${{\mathsf{\mathcal{P}}}_{m}}$, it is necessary to compute the probability ${{\mathsf{\mathcal{P}}}_{m}}(u)$ for each unlabeled sample $u(u\in {{U}_{m}})$. ${{\mathsf{\mathcal{P}}}_{m}}(u)$ is calculated by summing up the out-of-bag scores of $u$ across all the $T$ rounds and dividing the sum by the total number of occurrences of $u$ remaining as an out-of-bag sample in the $m\text{-th}$ iteration. The subsequent formula can be obtained:
	\begin{equation}
		{{\mathsf{\mathcal{P}}}_{m}}(u)=\frac{\sum\nolimits_{t=1}^{T}{S_{m}^{t}}(u)}{\sum\nolimits_{t=1}^{T}{I(u\in O_{m}^{t})}}.
	\end{equation}
	Note that $S_{m}^{t}(u)$ = 0 if $u$ was not an out-of-bag sample in the $t\text{-th}$ round of sampling during the $m\text{-th}$ iteration. The indicator function $\sum\nolimits_{t=1}^{T}{I(u\in O_{m}^{t})}$ returns 1 if the sample $u$ is in the out-of-bag set $O_{m}^{t}$, and 0 otherwise. 
	
	Based on the probabilities ${{\mathsf{\mathcal{P}}}_{m}}(u)$, we rank all the unlabeled samples decreasingly. Then, the top-ranked samples can be selected as reliable positive samples since they are more probable to be true positive samples. The set of reliable positive samples identified in the $m\text{-th}$ iteration can be denoted as ${{R}_{m}}$ and we have that:
	\begin{equation}
		{{R}_{m}}=\{Chose\ Top\ |{{U}_{m}}|\times \theta \ IDs\ from\ {{\mathsf{\mathcal{P}}}_{m}}\}
	\end{equation}
	This calculation can be performed in two steps:
	\begin{itemize}
		\item Step 1: Sort the samples in ${{\mathsf{\mathcal{P}}}_{m}}$ in a non-increasing order based on their probabilities.
		
		\item Step 2: Select the top $|{{U}_{m}}|\times \theta$ samples from the sorted list, where $\theta $ is a manually set ratio representing the sampling rate of reliable positive samples.
	\end{itemize}
	
	Subsequently, we update the labels of the samples in party C's dataset by adding the selected reliable positive samples to the set of positive samples. As a result, the number of samples in the unlabeled dataset ${{U}_{m}}$ decreasees. Specifically, we can formularize it as follows:
	\begin{equation}
		\mathsf{\mathcal{Y}}_{r}^{C}=1,\ \ r\in {{R}_{m}}
	\end{equation}	
	where each sample $r$ in the set ${{R}_{m}}$ is assigned a label of 1 (positive class).
	\item Final results and application to recommend
	
	After completing all the $M$ iterations of the algorithm, the final set of reliable positive samples $R$ is obtained by taking the union of all ${{R}_{m}}$ sets from each iteration. With this set of reliable positive samples, Party A can now tailor recommendations to each sample in $R$, thereby improving the accuracy and relevance of the recommendation system. This final step is crucial in ensuring the effectiveness of the algorithm in identifying the most relevant samples for enhancing the performance of the recommendation system.
\end{enumerate}
```

# 无算法

```
第1部分
\subsubsection{Vertical federated learning with positive and unlabeled data}
The objective of the VFPU algorithm is to securely and efficiently identify reliable positive samples from the unlabeled data. The core of the algorithm lies in the combination of some PU learning techniques with the vertical federated framework. The PU techniques incorporated in VFPU include the two-step technique \cite{liu2003building} and the PU bagging method \cite{mordelet2014bagging}. This section provides a detailed explanation of VFPU, as outlined in Algorithm \ref{alg:cap}. 



\begin{enumerate}[label=(\arabic*)]
	第2部分
	\item Establishing initial sample sets
	
	Overall, the VFPU algorithm executes $M$ iterations, each consisting of $T$ rounds of random sampling, training and predicting.  In each iteration $m\in \{1,...,M\}$, the set of positive samples ${{P}_{m}}$ and the set of unlabeled samples ${{U}_{m}}$ are determined based on the labels provided by Party C as follows:
	\begin{equation}
		\begin{split}
			&{{P}_{m}}=\{i|\mathsf{\mathcal{Y}}_{i}^{C}=1,\ i\in {{\mathsf{\mathcal{I}}}_{C}}\};\\
			&{{U}_{m}}=\{i|\mathsf{\mathcal{Y}}_{i}^{C}=-1,\ i\in {{\mathsf{\mathcal{I}}}_{C}}\},
		\end{split}
	\end{equation}
	where ${{\mathsf{\mathcal{I}}}_{C}}$ is the ID space, ${{\mathsf{\mathcal{Y}}}^{C}}$ is the label space of party C, and $i$ is the sample ID.
	第3部分
	第3.1部分
	\item Sampling, training and predicting
	
	As shown in \autoref{fig:VFPU}, during the $t\text{-th} \ (\text{t}\in \{1,2,...,T\})$ round of sampling in the $m\text{-th}$ iteration, a pseudo-negative sample set $N_{m}^{t}$ is generated from ${{U}_{m}}$ using bootstrapping \cite{mordelet2014bagging}. Mathematically, this can be expressed as:
	\begin{equation}
		N_{m}^{t}=\{ \text{Randomly select} \ |P_{m}| \ \text{elements from} \ U_{m} \},
	\end{equation}
	where $|{{P}_{m}}|$ is the number of samples as contained in ${{P}_{m}}$.
	
	Since the actual categories of the unlabeled samples are unknown, $N_{m}^{t}$ is regarded as a set of pseudo-negative samples, potentially containing both genuine negative and positive samples. By drawing $|{{P}_{m}}|$ elements from ${{U}_{m}}$, we can create $N_{m}^{t}$ with the same size as ${{P}_{m}}$.
	
	${{P}_{m}}$ and $N_{m}^{t}$ are combined into a binary classification training set during the training process. This set is used to train the vertical federated learning model, which learns to distinguish between positive and negative samples and applies this knowledge to future prediction tasks. 
	
	Bootstrapping is a technique that randomly selects samples from a dataset with replacement. Employing this technique allows VFPU to create diverse and balanced training sets, thus improving the model's generalization capabilities, reducing potential biases and enhancing the overall performance of the recommendation model.
	
	Samples not selected during the bootstrapping procedure are called out-of-bag samples. The out-of-bag score represents the predicted probability of the out-of-bag sample being classified as positive. Therefore, to obtain the set of out-of-bag samples $O_{m}^{t}$, we need to exclude samples in $N_{m}^{t}$ from ${{U}_{m}}$, which can be expressed mathematically as:
	\begin{equation}
		O_{m}^{t}={{U}_{m}}-N_{m}^{t}.
	\end{equation}
	
	Party C then encrypts and sends   $N_{m}^{t}$,  ${{P}_{m}}$, and $O_{m}^{t}$ t to other parties. Here in our example, the other party is Party B. Then, Party B and Party C establish their training and testing data based on the three sets of sample IDs they have received. Specifically, we have:
	\begin{equation}
		\begin{split}
			&\mathsf{\mathcal{D}}_{train}^{K}=\{(i,{{x}_{i}},{{y}_{i}})|i\in {{P}_{m}}\ or\ i\in N_{m}^{t}\};\\
			&\mathsf{\mathcal{D}}_{test}^{K}=\{(i,{{x}_{i}},{{y}_{i}})|i\in O_{m}^{t}\},
		\end{split}
	\end{equation}
	where $\mathsf{\mathcal{D}}_{train}^{K}$ represents the binary training data and $\mathsf{\mathcal{D}}_{test}^{K}$ denotes the testing data and $K\in \{B,C\}$. ${{x}_{i}}\in \mathsf{\mathcal{X}}$ and ${{y}_{i}}\in \mathsf{\mathcal{Y}}$.
	第3.2部分
	
	Once party B and party C have prepared their respective training and testing datasets, the binary classification problem transforms into a vertical federated training and predicting task. A base estimator, serving as a machine learning model for each party, is adapted for use within the VFL framework. It is crucial to grasp general training process of VFL \cite{yang2019federated}. Overall, it comprises four steps, illustrating how the base estimator is trained on the multi-party training data while preserving privacy. The four steps are as follows:
	\begin{itemize}
		\item Step 1: The server creates encryption pairs and sends a public key to parties B and C.
		\item Step 2: Parties B and C encrypt and exchange intermediate results for gradient and loss calculations.
		\item Step 3: Parties B and C compute encrypted gradients, add an additional mask, and calculate the encrypted loss. Encrypted values are then sent to the server.
		\item Step 4: The server decrypts and sends the decrypted gradients and loss back to party B and party C. Parties B and C unmask the gradients and update the model parameters accordingly.
	\end{itemize}
	
	Various privacy-preserving machine-learning algorithms have been proposed for the VFL framework in support of the general training process \cite{yang2019federated}, including logistic regression (LR) \cite{he2021secure,yang2019parallel}, random forest (RF) \cite{yao2022efficient}, gradient boosting decision tree (GBDT) \cite{he2021secure}, XGBoost (XGB) \cite{xu2021efficient,wang2022feverless} and LightGBM (LGB) \cite{feng2019securegbm}. In this paper, we will apply different base estimators to evaluate the performance of the recommendation model. 
	
	第4部分
	\item Identifying reliable positive samples
	
	During the $m\text{-th}$ iteration, the process of sampling, training, and predicting is carried out $T$ times. Upon completion of these $T$ rounds, sufficient information is collected to determine the set of probabilities, represented as ${{\mathsf{\mathcal{P}}}_{m}}$, for all unlabeled samples in ${{U}_{m}}$. These probabilities correspond to the likelihood of each sample being regarded as the positive class and can be employed for subsequent decision-making processes, such as pinpointing reliable positive samples and updating training sets.
	
	To derive the entire set ${{\mathsf{\mathcal{P}}}_{m}}$, it is necessary to compute the probability ${{\mathsf{\mathcal{P}}}_{m}}(u)$ for each unlabeled sample $u(u\in {{U}_{m}})$. ${{\mathsf{\mathcal{P}}}_{m}}(u)$ is calculated by summing up the out-of-bag scores of $u$ across all the $T$ rounds and dividing the sum by the total number of occurrences of $u$ remaining as an out-of-bag sample in the $m\text{-th}$ iteration. The subsequent formula can be obtained:
	\begin{equation}
		{{\mathsf{\mathcal{P}}}_{m}}(u)=\frac{\sum\nolimits_{t=1}^{T}{S_{m}^{t}}(u)}{\sum\nolimits_{t=1}^{T}{I(u\in O_{m}^{t})}}.
	\end{equation}
	Note that $S_{m}^{t}(u)$ = 0 if $u$ was not an out-of-bag sample in the $t\text{-th}$ round of sampling during the $m\text{-th}$ iteration. The indicator function $\sum\nolimits_{t=1}^{T}{I(u\in O_{m}^{t})}$ returns 1 if the sample $u$ is in the out-of-bag set $O_{m}^{t}$, and 0 otherwise. 
	
	Based on the probabilities ${{\mathsf{\mathcal{P}}}_{m}}(u)$, we rank all the unlabeled samples decreasingly. Then, the top-ranked samples can be selected as reliable positive samples since they are more probable to be true positive samples. The set of reliable positive samples identified in the $m\text{-th}$ iteration can be denoted as ${{R}_{m}}$ and we have that:
	\begin{equation}
		{{R}_{m}}=\{Chose\ Top\ |{{U}_{m}}|\times \theta \ IDs\ from\ {{\mathsf{\mathcal{P}}}_{m}}\}
	\end{equation}
	This calculation can be performed in two steps:
	\begin{itemize}
		\item Step 1: Sort the samples in ${{\mathsf{\mathcal{P}}}_{m}}$ in a non-increasing order based on their probabilities.
		
		\item Step 2: Select the top $|{{U}_{m}}|\times \theta$ samples from the sorted list, where $\theta $ is a manually set ratio representing the sampling rate of reliable positive samples.
	\end{itemize}
	
	Subsequently, we update the labels of the samples in party C's dataset by adding the selected reliable positive samples to the set of positive samples. As a result, the number of samples in the unlabeled dataset ${{U}_{m}}$ decreasees. Specifically, we can formularize it as follows:
	\begin{equation}
		\mathsf{\mathcal{Y}}_{r}^{C}=1,\ \ r\in {{R}_{m}}
	\end{equation}	
	where each sample $r$ in the set ${{R}_{m}}$ is assigned a label of 1 (positive class).
	
	
	第5部分
	\item Final results and application to recommend
	
	After completing all the $M$ iterations of the algorithm, the final set of reliable positive samples $R$ is obtained by taking the union of all ${{R}_{m}}$ sets from each iteration. With this set of reliable positive samples, Party A can now tailor recommendations to each sample in $R$, thereby improving the accuracy and relevance of the recommendation system. This final step is crucial in ensuring the effectiveness of the algorithm in identifying the most relevant samples for enhancing the performance of the recommendation system.
\end{enumerate}
```

# 扩充后

```
第1部分
\subsubsection{Vertical federated learning with positive and unlabeled data}

The objective of the Vertical Federated PU learning (VFPU) algorithm is to securely and efficiently identify reliable positive samples from unlabeled data within a vertically partitioned data setting.  This scenario arises frequently in real-world applications where different organizations hold distinct features of the same data subjects but are unable to directly share the raw data due to privacy concerns or regulatory restrictions.  For instance, a bank might have financial transaction records, while an e-commerce platform possesses online shopping history, both relating to the same customers. Identifying positive samples, such as customers likely to default on a loan or respond to a specific marketing campaign, is crucial but challenging due to the lack of complete labeled data and the distributed nature of the features.

VFPU addresses this challenge by ingeniously combining established Positive and Unlabeled (PU) learning techniques with the vertical federated learning framework.  Specifically, it leverages the power of the two-step technique proposed by Liu et al. \cite{liu2003building} and the robustness of the PU bagging method introduced by Mordelet and Vert \cite{mordelet2014bagging}. These methods are adapted and integrated into a secure protocol that allows collaborative training without compromising data privacy.

Algorithm \ref{alg:cap} provides a detailed outline of the VFPU procedure.  The two-step technique, employed in the first stage, initially identifies a set of reliable negative samples from the unlabeled data. This is achieved by leveraging the positive samples and assuming that the unlabeled data contains both positive and negative instances.  By carefully analyzing the feature distributions, a reliable negative set is extracted, allowing for a more accurate representation of the underlying data distribution.  The subsequent step then utilizes these reliable negative samples along with the original positive samples to train a preliminary classification model. This model serves as a foundation for the second stage.

The PU bagging method, incorporated in the second stage, further enhances the robustness and performance of VFPU.  By generating multiple bootstrap samples from the combined positive and reliable negative sets, and training individual classifiers on each sample,  PU bagging effectively addresses the potential bias introduced by the initial selection of reliable negatives.  The final prediction is obtained by aggregating the predictions of these individual classifiers, leading to a more stable and accurate identification of positive samples within the unlabeled data.  This ensemble approach also contributes to the overall resilience of VFPU against noisy or incomplete data, which is a common characteristic of real-world datasets.

Furthermore, the vertical federated learning framework ensures data privacy throughout the entire process.  Each participating party retains control over its own data and only shares intermediate results, such as model parameters or encrypted gradients, during the training process.  This decentralized approach avoids the need for a central data repository and minimizes the risk of data breaches.  The combination of robust PU learning techniques and the privacy-preserving nature of vertical federated learning makes VFPU a promising solution for various real-world applications involving positive and unlabeled data in distributed settings.  This method paves the way for more effective collaboration and knowledge discovery while upholding data privacy standards.

第2部分
\item Establishing initial sample sets

The VFPU algorithm operates iteratively, employing a two-layered approach to enhance the robustness and reliability of the positive sample identification process.  The outer loop consists of $M$ iterations, providing multiple opportunities to refine the selection of reliable positive samples.  Within each iteration $m \in \{1, ..., M\}$,  an inner loop executes $T$ rounds of random sampling, training, and predicting. This nested structure contributes to the stability and accuracy of the algorithm, particularly when dealing with noisy or imbalanced data, which is a common occurrence in real-world scenarios.

At the beginning of each iteration $m$, the algorithm establishes two fundamental sample sets based on the labels provided by Party C.  Party C, within the vertical federated learning framework, is designated as the party holding the labels or the partial labels for the training data. This designation is crucial as it guides the initial partitioning of the data. The two sets are defined as follows:

\begin{equation}
\begin{split}
&{{P}_{m}}=\{i|\mathsf{\mathcal{Y}}_{i}^{C}=1,\ i\in {{\mathsf{\mathcal{I}}}_{C}}\};\\
&{{U}_{m}}=\{i|\mathsf{\mathcal{Y}}_{i}^{C}=-1,\ i\in {{\mathsf{\mathcal{I}}}_{C}}\},
\end{split}
\end{equation}

where ${{\mathsf{\mathcal{I}}}_{C}}$ represents the ID space of Party C, essentially the set of all sample identifiers available to Party C.  ${{\mathsf{\mathcal{Y}}}^{C}}$ denotes the label space of Party C, containing the corresponding labels for each sample ID.  $i$ refers to a specific sample ID within the ID space. Therefore, ${{P}_{m}}$ represents the set of positive samples in iteration $m$, specifically those samples for which Party C provides a positive label ($\mathsf{\mathcal{Y}}_{i}^{C}=1$).  Conversely, ${{U}_{m}}$ constitutes the set of unlabeled samples in iteration $m$, encompassing those samples for which Party C provides a negative or unlabeled indication ($\mathsf{\mathcal{Y}}_{i}^{C}=-1$).  It is important to note that in the context of PU learning, the unlabeled set ${{U}_{m}}$ is assumed to contain a mixture of both true positive and true negative samples.  The challenge addressed by VFPU is to effectively disentangle these samples and identify the reliable positive instances within ${{U}_{m}}$.  The iterative nature of the algorithm, combined with the subsequent steps involving PU learning techniques, facilitates this disambiguation process.  By repeatedly refining the selection of positive samples across multiple iterations and rounds of sampling, VFPU aims to converge towards a more accurate and robust identification of the true positive samples within the initially unlabeled dataset. This careful partitioning and iterative refinement are essential for achieving high performance in the presence of unlabeled data.

第3部分
第3.1部分
下面是在不改变原有公式、格式和基本含义的前提下，对原文内容进行扩充和详细描述后的版本，以满足学术论文对字数和内容丰富性的要求：

\item Sampling, training and predicting

    As shown in \autoref{fig:VFPU}, during the $t\text{-th} \ (\text{t}\in \{1,2,...,T\})$ round of sampling in the $m\text{-th}$ iteration, a pseudo-negative sample set $N_{m}^{t}$ is generated from $U_{m}$ using bootstrapping \cite{mordelet2014bagging}. Mathematically, this can be expressed as:
    \begin{equation}
        N_{m}^{t}=\{ \text{Randomly select} \ |P_{m}| \ \text{elements from} \ U_{m} \},
    \end{equation}
    where $|P_{m}|$ is the number of samples contained in $P_{m}$. In this process, the random selection is performed with replacement, ensuring that the same element in $U_{m}$ might be chosen multiple times. This strategy not only introduces randomness in the sample generation process but also facilitates the construction of a balanced dataset even under uncertainty regarding the true label distribution within $U_{m}$.

    Since the actual categories of the unlabeled samples are unknown, $N_{m}^{t}$ is regarded as a set of pseudo-negative samples, potentially containing both genuine negative and positive samples. By drawing $|P_{m}|$ elements from $U_{m}$, we can construct $N_{m}^{t}$ with the same size as $P_{m}$, thereby offering a comparable and balanced dataset for the classification task. This balancing act is critical in machine learning as it attempts to mitigate the potentially adverse consequences of class imbalance and provides a robust sample space for subsequent training procedures.

    $P_{m}$ and $N_{m}^{t}$ are combined into a binary classification training set during the training process. This combined training set is used to train the vertical federated learning model, which learns to distinguish between positive and negative samples and applies this knowledge to future prediction tasks. The combination of these two sets ensures that the learning algorithm is exposed to diverse examples, playing a vital role in optimizing the generalization performance of the trained model. In addition, the training procedure benefits from the simultaneous employment of both actual positive samples and pseudo-negative samples, facilitating a robust decision boundary even if the pseudo-negative set may include mislabeled data points.

    Bootstrapping is a technique that randomly selects samples from a dataset with replacement. This statistical method has been widely adopted in machine learning due to its advantages in reducing overfitting and providing a more precise estimation of model performance. Employing this technique allows VFPU to create diverse and balanced training sets, thus improving the model's generalization capabilities, reducing potential biases, and enhancing the overall performance of the recommendation model. Furthermore, this method is particularly beneficial in scenarios where obtaining true negative samples is challenging, as it compensates for the insufficiency of labeled data by synthesizing an alternative pseudo-negative set that approximates the distribution of the actual negatives.

    Samples that are not selected during the bootstrapping procedure are called out-of-bag samples. These samples play a significant role in validating the performance of the model, as they provide an unbiased estimate of the classification error. The out-of-bag score represents the predicted probability of the out-of-bag sample being classified as positive. Therefore, to obtain the set of out-of-bag samples $O_{m}^{t}$, we need to exclude samples in $N_{m}^{t}$ from $U_{m}$, which can be expressed mathematically as:
    \begin{equation}
        O_{m}^{t}=U_{m}-N_{m}^{t}.
    \end{equation}
    This strategy affords an internal mechanism for model evaluation without the need for a separately held-out validation set, thereby leveraging all available data for both model development and performance estimation.

    Party C then encrypts and sends $N_{m}^{t}$, $P_{m}$, and $O_{m}^{t}$ to other parties. In our example, the other party is Party B. Subsequently, Party B and Party C collaboratively establish their training and testing data based on the three sets of sample IDs that have been exchanged. This joint procedure is crucial in a federated learning environment where privacy and data security are of paramount importance. Specifically, we have:
    \begin{equation}
        \begin{split}
            &\mathsf{\mathcal{D}}_{train}^{K}=\{(i,x_{i},y_{i}) \ | \ i\in P_{m}\ or\ i\in N_{m}^{t}\};\\
            &\mathsf{\mathcal{D}}_{test}^{K}=\{(i,x_{i},y_{i}) \ | \ i\in O_{m}^{t}\},
        \end{split}
    \end{equation}
    where $\mathsf{\mathcal{D}}_{train}^{K}$ represents the binary training data and $\mathsf{\mathcal{D}}_{test}^{K}$ denotes the testing data, and $K\in \{B,C\}$. Here, $x_{i}\in \mathsf{\mathcal{X}}$ indicates that the feature vector associated with the sample $i$ is drawn from the feature space $\mathsf{\mathcal{X}}$, while $y_{i}\in \mathsf{\mathcal{Y}}$ confirms that the corresponding label belongs to the label space $\mathsf{\mathcal{Y}}$. This seamless integration of encrypted sample IDs and corresponding features facilitates a secure and cooperative training environment, which is indispensable in scenarios that demand high privacy standards while still ensuring high-quality model outcomes.

    In summary, by incorporating bootstrapping alongside the establishment of out-of-bag evaluations and secure sample sharing mechanisms between federated learning parties, our approach robustly addresses common challenges in dealing with unbalanced and partially labeled datasets. This method not only guarantees a diversified training process but also significantly fortifies the integrity and reliability of the model's prediction results in real-world applications.
    
    第3.2部分
    
  Once Party B and Party C have prepared their respective training and testing datasets, the binary classification problem transforms into a vertical federated training and predicting task. In this context, a base estimator—representing a conventional machine learning model for each participating entity—is adapted for use within the Vertical Federated Learning (VFL) framework. It is imperative to understand the general training process of VFL as described in \cite{yang2019federated}. Overall, this process comprises a sequence of four key steps that collectively illustrate how the base estimator is trained on the multi-party training data while ensuring that the privacy of individual datasets is strictly preserved throughout the collaboration. The four-step process is described as follows:

\begin{itemize}
	\item Step 1: The server initiates the process by generating a series of encryption key pairs. In doing so, the server securely creates these cryptographic materials and then sends the corresponding public key to Parties B and C. This step forms the fundamental basis for all subsequent privacy-preserving operations by establishing a secure channel for information exchange.
	
	\item Step 2: Upon receipt of the public key, Parties B and C proceed to encrypt and exchange intermediate computational results. These results are critical as they pertain to gradient and loss calculations that are central to the learning process. By sharing only encrypted data, each party ensures that raw and sensitive data values are never directly revealed or transmitted, thereby upholding the privacy constraints inherent in the VFL paradigm.
	
	\item Step 3: Following the exchange of encrypted intermediate results, Parties B and C then compute the encrypted gradients necessary for the model's parameter updates. In addition to computing these gradients, both parties incorporate an additional masking mechanism to further obscure the values of the computed gradients. Simultaneously, each party calculates an encrypted version of the model loss. The application of this extra masking step is intended to safeguard against any potential data leakage during subsequent transmissions. Once these encrypted values—involving both the gradients and the loss—are generated, they are securely transmitted to the server for further processing.
	
	\item Step 4: With the encrypted data in hand, the server undertakes the task of decrypting the received gradients and loss. After performing the decryption process, the server sends the decrypted gradients and loss back to Parties B and C. Upon receipt, both parties remove the additional masking that was previously applied. This unmasking step is essential as it recovers the true gradient information required for updating the model parameters. Only after these gradients are successfully unmasked do Parties B and C perform the actual parameter updates on the base estimator, thereby progressing the training process in a synchronized and privacy-preserving manner.
\end{itemize}

Various privacy-preserving machine learning algorithms have been proposed to support the general training process within a VFL framework \cite{yang2019federated}. Notable examples include logistic regression (LR) \cite{he2021secure,yang2019parallel}, random forest (RF) \cite{yao2022efficient}, gradient boosting decision tree (GBDT) \cite{he2021secure}, XGBoost (XGB) \cite{xu2021efficient,wang2022feverless}, and LightGBM (LGB) \cite{feng2019securegbm}. Each of these algorithms is designed to facilitate secure and efficient training while simultaneously preserving data privacy across multiple data owners. In this paper, we leverage different base estimators—each corresponding to one of these algorithms—to comprehensively evaluate the overall performance of the recommendation model. This multi-estimator evaluation not only underscores the flexibility and broad applicability of the VFL framework but also provides insights into how various models behave under privacy-preserving settings. The inclusion of diverse model architectures reinforces the robustness and adaptability of our approach in handling complex and sensitive datasets across disparate data sources.

By meticulously following the outlined four steps and integrating well-established privacy-preserving techniques, the proposed method ensures a strong balance between model performance and data security. The exchange of encrypted data, in combination with collaborative computation and subsequent decryption and unmasking, exemplifies the rigorous measures undertaken to prevent any inadvertent exposure of sensitive information. As such, this process facilitates a secure training environment where parties can jointly benefit from collective data insights while maintaining stringent adherence to privacy protocols, making it particularly suitable for applications involving sensitive or regulated data.
第4部分

\item Identifying reliable positive samples

  During the $m\text{-th}$ iteration, the overall process of sampling, training, and predicting is executed repeatedly for $T$ rounds. Once these $T$ rounds have been completed, a substantial amount of information is accumulated to form a set of probabilities, denoted as ${{\mathsf{\mathcal{P}}}_{m}}$, which is associated with all unlabeled samples in ${{U}_{m}}$. These probabilities reflect the likelihood or confidence of each sample in ${{U}_{m}}$ belonging to the positive class. Such probabilistic scores play a key role in subsequent decision-making procedures, such as identifying a subset of highly reliable positive samples and iteratively updating the training sets for enhanced model performance.

  To compute the complete set ${{\mathsf{\mathcal{P}}}_{m}}$, it is necessary to determine the probability ${{\mathsf{\mathcal{P}}}_{m}}(u)$ for each unlabeled sample $u$ (where $u\in {{U}_{m}}$). The probability ${{\mathsf{\mathcal{P}}}_{m}}(u)$ is derived by summing the out-of-bag scores of the sample $u$ across all $T$ rounds and then normalizing this accumulated score by dividing by the total number of times $u$ appears as an out-of-bag sample during the $m\text{-th}$ iteration. This process is mathematically represented by the following formula:
\begin{equation}
	{{\mathsf{\mathcal{P}}}_{m}}(u)=\frac{\sum\nolimits_{t=1}^{T}{S_{m}^{t}}(u)}{\sum\nolimits_{t=1}^{T}{I(u\in O_{m}^{t})}}.
\end{equation}
  In this expression, $S_{m}^{t}(u)$ designates the out-of-bag score assigned to sample $u$ in the $t\text{-th}$ round during the $m\text{-th}$ iteration. Notably, if $u$ is not present as an out-of-bag sample in a given round, then $S_{m}^{t}(u)$ is defined to be 0. The indicator function $I(u\in O_{m}^{t})$ evaluates to 1 when the sample $u$ is included in the out-of-bag set $O_{m}^{t}$ and returns 0 otherwise. Thus, the denominator $\sum\nolimits_{t=1}^{T}{I(u\in O_{m}^{t})}$ effectively counts the number of rounds in which $u$ contributed to the out-of-bag estimation. This normalization ensures that the probability assigned to each sample is reflective of its average performance across rounds where its prediction was made, thereby increasing the robustness and reliability of the resulting probability estimates.

  Based on the computed probabilities ${{\mathsf{\mathcal{P}}}_{m}}(u)$, a ranking is then performed on all unlabeled samples in ${{U}_{m}}$. This ranking is executed in a non-increasing order, so that samples with higher probabilities (i.e., those more likely to be true positives) appear at the top of the list. With this sorted list, the next step involves selecting a set of reliable positive samples. Formally, let ${{R}_{m}}$ denote the set of reliable positive samples identified in the $m\text{-th}$ iteration. In our approach, the selection is made by choosing the top-ranked samples whose count is determined by the expression $|{{U}_{m}}|\times \theta$, where $\theta$ is a manually set ratio that represents the sampling rate of reliable positive samples. This selection process can be succinctly formulated as follows:
\begin{equation}
	{{R}_{m}}=\{Chose\ Top\ |{{U}_{m}}|\times \theta \ IDs\ from\ {{\mathsf{\mathcal{P}}}_{m}}\}.
\end{equation}
  This two-step selection process can be elaborated as follows:
	\begin{itemize}
		\item Step 1: All samples in ${{\mathsf{\mathcal{P}}}_{m}}$ are sorted in non-increasing order according to their calculated probabilities. This ordering ensures that samples with the highest likelihood of being positive are given priority.

		\item Step 2: From the sorted order, the top $|{{U}_{m}}|\times \theta$ samples are selected, with $\theta$ acting as the tunable parameter that dictates the fraction of the unlabeled dataset to be considered as reliable positive samples.
	\end{itemize}
  By performing this procedure, the most confident samples that are likely to truly belong to the positive class are distinguished from the rest. Consequently, the set ${{R}_{m}}$ encapsulates these selected samples, which are then used to update the training labels maintained by Party C.

  Following the identification process, these newly recognized reliable positive samples are incorporated into the training set maintained by Party C. This update entails assigning a positive label to each sample in ${{R}_{m}}$, thereby gradually reducing the size of the unlabeled dataset ${{U}_{m}}$. In terms of the formal notation, this update is expressed as:
\begin{equation}
	\mathsf{\mathcal{Y}}_{r}^{C}=1,\ \ r\in {{R}_{m}},
\end{equation}
  where each sample $r$ in the set ${{R}_{m}}$ is explicitly assigned a label of 1, signifying its classification as belonging to the positive class. This label update is a critical step in the iterative refinement of the training data, as it leverages the confidence scores derived from the ensemble of out-of-bag predictions to improve the overall quality and reliability of the training set in subsequent iterations.

  In summary, the process of identifying reliable positive samples is a carefully designed mechanism that converts probabilistic predictions into a refined set of high-confidence positive instances. This mechanism not only enhances the quality of the training data but also provides an iterative pathway for improving the performance of the overall recommendation model. By continuously updating the labels of the samples based on their out-of-bag performance, the algorithm effectively mitigates issues related to label uncertainty and data sparsity. Moreover, this enriched and methodical approach lays a robust foundation for subsequent model training and predictive tasks, ensuring that the evolving dataset progressively converges to a state of higher accuracy and consistency.
  第5部分
  \item Final results and application to recommend

After completing all the $M$ iterations of the algorithm, the final set of reliable positive samples $R$ is obtained by taking the union of all ${{R}_{m}}$ sets from each iteration, where $m = 1, 2, \dots, M$ represents the individual iterations performed during the process. This iterative approach ensures that the algorithm systematically refines its selection of positive samples over multiple rounds, progressively enhancing the quality and reliability of the resulting set $R$. Specifically, each ${{R}_{m}}$ contains the positive samples identified in the $m$-th iteration, and the union operation consolidates these intermediate results into a comprehensive final set. This step is computationally straightforward yet critical, as it aggregates the outcomes of all iterations into a single, unified collection that reflects the algorithm’s cumulative efforts in distinguishing reliable positive samples from the broader dataset.

With this carefully curated set of reliable positive samples $R$ in hand, Party A, who may represent a stakeholder such as a service provider or a recommendation system operator, can now leverage this information to tailor recommendations to each sample included in $R$. This personalization process involves analyzing the characteristics or preferences associated with each sample and designing recommendation strategies that align with these insights. By doing so, Party A can significantly improve the accuracy and relevance of the recommendation system, ensuring that the suggestions provided to end-users—whether they are product recommendations, content suggestions, or other personalized outputs—are both precise and contextually appropriate. The ability to fine-tune recommendations based on a dependable set of positive samples underscores the practical utility of the algorithm, bridging the gap between theoretical computation and real-world application.

This final step of utilizing $R$ to enhance the recommendation system is not merely a procedural formality but a cornerstone of the algorithm’s overall effectiveness. The success of the recommendation system hinges on its capacity to identify and prioritize the most relevant samples, a task that the iterative algorithm accomplishes through its structured design. By focusing on reliable positive samples, the system minimizes the inclusion of noise or irrelevant data, which could otherwise degrade the quality of the recommendations. Furthermore, the application of $R$ enables Party A to optimize resource allocation—directing computational and operational efforts toward the samples most likely to yield high user satisfaction and engagement. 

To illustrate the significance of this process, consider that recommendation systems are widely employed across various domains, such as e-commerce platforms, streaming services, and social media networks, where the accuracy of suggestions directly impacts user experience and business outcomes. The creation of $R$ through the union of ${{R}_{m}}$ sets ensures a robust foundation for these applications, providing a scalable and adaptable solution that can accommodate datasets of varying sizes and complexities. Moreover, the iterative nature of the algorithm allows it to adapt to dynamic environments where user preferences or data distributions may evolve over time, making it a versatile tool for long-term deployment.

In practice, the effectiveness of this final step can be evaluated through metrics such as precision, recall, or user satisfaction scores, which quantify the improvement in recommendation quality attributable to the curated set $R$. For instance, a higher precision indicates that a greater proportion of recommended items are relevant to the user, while an improved recall reflects the system’s ability to retrieve a broader range of relevant items from the dataset. These measurable outcomes highlight the algorithm’s contribution to enhancing the performance of the recommendation system, validating the importance of the iterative process and the subsequent application of $R$. Thus, this concluding phase not only completes the algorithmic workflow but also establishes its value as a practical solution for real-world recommendation challenges.
\end{enumerate}
```

给你一段latex撰写的英文论文，帮我翻译成中文，要求保持原始格式不变

# 翻译后的

```
第1部分
\subsubsection{基于正例和未标记数据的纵向联邦学习}

纵向联邦PU学习（VFPU）算法的目标是在纵向划分的数据环境中，安全且高效地从未标记数据中识别可靠的正例样本。这种场景在现实应用中经常出现，其中不同的组织持有相同数据主体的不同特征，但由于隐私问题或法规限制，无法直接共享原始数据。例如，银行可能拥有金融交易记录，而电子商务平台则掌握在线购物历史，这些数据都与相同的客户相关。识别正例样本（如可能违约的贷款客户或可能响应特定营销活动的客户）至关重要，但由于缺乏完整的标注数据以及特征的分布式存储，这一任务极具挑战性。

VFPU 通过巧妙结合既有的正例与未标记（PU）学习技术和纵向联邦学习框架来应对这一挑战。具体而言，它利用了 Liu 等人 \cite{liu2003building} 提出的两步技术，以及 Mordelet 和 Vert \cite{mordelet2014bagging} 提出的 PU bagging 方法的鲁棒性。这些方法经过调整和整合，形成了一种安全协议，使得各方能够在不泄露数据隐私的情况下进行协作训练。

算法 \ref{alg:cap} 详细描述了 VFPU 过程。第一阶段采用两步技术，首先从未标记数据中识别出一组可靠的负例样本。这一过程利用了正例样本，并假设未标记数据中同时包含正例和负例。通过仔细分析特征分布，可以提取出可靠的负例集合，从而更准确地表示数据的真实分布。随后，利用这些可靠的负例样本以及原始的正例样本训练一个初步分类模型，该模型作为第二阶段的基础。

第二阶段引入 PU bagging 方法，以进一步增强 VFPU 的鲁棒性和性能。通过从正例和可靠负例集合中生成多个自助采样（bootstrap）样本，并在每个样本上训练独立的分类器，PU bagging 有效地缓解了初始可靠负例选择可能带来的偏差。最终预测结果通过集成这些独立分类器的预测结果获得，从而在未标记数据中更稳定、准确地识别正例样本。这种集成方法还增强了 VFPU 在处理噪声数据或不完整数据时的适应能力，而这些问题在现实数据集中普遍存在。

此外，纵向联邦学习框架确保了整个过程中的数据隐私。每个参与方都保留对自身数据的控制权，并且在训练过程中仅共享中间结果（如模型参数或加密梯度）。这种去中心化的方法避免了集中式数据存储的需求，并最大程度地降低了数据泄露的风险。VFPU 结合了强大的 PU 学习技术和纵向联邦学习的隐私保护特性，为分布式环境下涉及正例和未标记数据的各种现实应用提供了一种有前景的解决方案。这一方法为更高效的协作和知识发现铺平了道路，同时遵守数据隐私标准。

第2部分
### 建立初始样本集

VFPU 算法采用迭代方式运行，并通过双层方法增强正样本识别过程的稳健性和可靠性。外层循环包含 $M$ 次迭代，为优化可靠正样本的选择提供了多次机会。在每次迭代 $m \in \{1, ..., M\}$ 中，内层循环执行 $T$ 轮随机采样、训练和预测。这种嵌套结构有助于提高算法的稳定性和准确性，尤其是在处理现实场景中常见的噪声数据或不平衡数据时。

在每次迭代 $m$ 开始时，算法基于 C 方提供的标签建立两个基本样本集。在纵向联邦学习框架中，C 方被指定为持有训练数据标签或部分标签的一方。这一指定至关重要，因为它指导了数据的初始划分。这两个集合定义如下：

\begin{equation}
\begin{split}
&{{P}_{m}}=\{i|\mathsf{\mathcal{Y}}_{i}^{C}=1,\ i\in {{\mathsf{\mathcal{I}}}_{C}}\};\\
&{{U}_{m}}=\{i|\mathsf{\mathcal{Y}}_{i}^{C}=-1,\ i\in {{\mathsf{\mathcal{I}}}_{C}}\},
\end{split}
\end{equation}

其中，${{\mathsf{\mathcal{I}}}_{C}}$ 表示 C 方的 ID 空间，即 C 方可用的所有样本标识符的集合。${{\mathsf{\mathcal{Y}}}^{C}}$ 表示 C 方的标签空间，包含每个样本 ID 对应的标签。$i$ 代表 ID 空间中的特定样本 ID。因此，${{P}_{m}}$ 代表迭代 $m$ 中的正样本集，具体而言，即 C 方提供正标签（$\mathsf{\mathcal{Y}}_{i}^{C}=1$）的样本集合。相反，${{U}_{m}}$ 代表迭代 $m$ 中的未标记样本集，包含 C 方提供负标签或未标记（$\mathsf{\mathcal{Y}}_{i}^{C}=-1$）的样本。

需要注意的是，在 PU 学习（Positive-Unlabeled Learning）的背景下，未标记集合 ${{U}_{m}}$ 假设包含真实的正样本和真实的负样本的混合体。VFPU 旨在有效地区分这些样本，并在 ${{U}_{m}}$ 中识别出可靠的正样本。该算法的迭代特性，以及后续涉及 PU 学习技术的步骤，有助于完成这一去歧义过程。通过在多个迭代和采样轮次中不断优化正样本的选择，VFPU 旨在逐步收敛到更准确、更稳健的真实正样本识别结果。这种精细的划分和迭代优化对于在未标记数据的情况下实现高性能至关重要。
第3部分
第3.1部分

采样、训练与预测  

如 \autoref{fig:VFPU} 所示，在第 $m$ 次迭代的第 $t\text{-th} \ (\text{t}\in \{1,2,...,T\})$ 轮采样过程中，使用自助法（bootstrapping）\cite{mordelet2014bagging} 从 $U_{m}$ 生成伪负样本集 $N_{m}^{t}$。数学上可以表示为：
\begin{equation}
    N_{m}^{t}=\{ \text{随机选择} \ |P_{m}| \ \text{个元素自} \ U_{m} \},
\end{equation}
其中，$|P_{m}|$ 是 $P_{m}$ 中包含的样本数量。在此过程中，随机选择是有放回的，这意味着 $U_{m}$ 中的同一元素可能会被多次选中。这种策略不仅在样本生成过程中引入了随机性，还在不确定 $U_{m}$ 内真实标签分布的情况下，有助于构建一个平衡的数据集。

由于未标记样本的实际类别未知，$N_{m}^{t}$ 被视为一组伪负样本，可能同时包含真正的负样本和正样本。通过从 $U_{m}$ 中抽取 $|P_{m}|$ 个元素，我们可以构造出与 $P_{m}$ 规模相同的 $N_{m}^{t}$，从而为分类任务提供一个可比且平衡的数据集。这种平衡对于机器学习至关重要，因为它试图减轻类别不平衡可能带来的不利影响，并为后续的训练过程提供一个稳健的样本空间。

在训练过程中，$P_{m}$ 和 $N_{m}^{t}$ 被合并为一个二元分类训练集。该训练集用于训练纵向联邦学习模型，使其能够区分正样本和负样本，并将此知识应用于未来的预测任务。这两个集合的结合确保了学习算法能够接触到多样化的示例，在优化训练模型的泛化性能方面发挥着至关重要的作用。此外，训练过程同时利用了真实的正样本和伪负样本，即使伪负样本集中可能包含被错误标记的数据点，也能促进模型学习到稳健的决策边界。

自助法（bootstrapping）是一种从数据集中随机选择样本（有放回）的技术。这种统计方法在机器学习中被广泛采用，因为它有助于减少过拟合，并提供对模型性能更精确的估计。采用该技术使 VFPU 能够创建多样化且平衡的训练集，从而提高模型的泛化能力，减少潜在偏差，并增强推荐模型的整体性能。此外，在难以获取真实负样本的情况下，该方法尤为有用，因为它通过合成一个近似于真实负样本分布的伪负样本集，弥补了标注数据不足的问题。

在自助法过程中未被选中的样本称为袋外样本（out-of-bag samples）。这些样本在验证模型性能方面发挥着重要作用，因为它们提供了对分类误差的无偏估计。袋外评分（out-of-bag score）表示袋外样本被分类为正样本的预测概率。因此，为了获得袋外样本集 $O_{m}^{t}$，我们需要从 $U_{m}$ 中排除 $N_{m}^{t}$ 中的样本，数学表达如下：
\begin{equation}
    O_{m}^{t}=U_{m}-N_{m}^{t}.
\end{equation}
这种策略提供了一种内部模型评估机制，而无需单独划分验证集，从而充分利用所有可用数据进行模型开发和性能估计。

然后，C 方对 $N_{m}^{t}$、$P_{m}$ 和 $O_{m}^{t}$ 进行加密，并将其发送给其他方。在我们的示例中，另一方是 B 方。随后，B 方和 C 方基于交换的三组样本 ID 共同建立各自的训练和测试数据集。这一联合过程在联邦学习环境中至关重要，因为隐私和数据安全是首要考虑因素。具体而言，我们有：
\begin{equation}
    \begin{split}
        &\mathsf{\mathcal{D}}_{train}^{K}=\{(i,x_{i},y_{i}) \ | \ i\in P_{m}\ or\ i\in N_{m}^{t}\};\\
        &\mathsf{\mathcal{D}}_{test}^{K}=\{(i,x_{i},y_{i}) \ | \ i\in O_{m}^{t}\},
    \end{split}
\end{equation}
其中，$\mathsf{\mathcal{D}}_{train}^{K}$ 代表二元分类训练数据，$\mathsf{\mathcal{D}}_{test}^{K}$ 代表测试数据，$K\in \{B,C\}$。这里，$x_{i}\in \mathsf{\mathcal{X}}$ 表示样本 $i$ 关联的特征向量来自特征空间 $\mathsf{\mathcal{X}}$，而 $y_{i}\in \mathsf{\mathcal{Y}}$ 表示相应的标签属于标签空间 $\mathsf{\mathcal{Y}}$。这种加密样本 ID 与相应特征的无缝集成，促进了一个安全且协作的训练环境，在需要高隐私标准的场景中至关重要，同时确保了高质量的模型输出。

总之，通过结合自助法、袋外评估机制以及联邦学习方之间的安全样本共享机制，我们的方法有效应对了处理不平衡和部分标注数据集的常见挑战。这种方法不仅保证了多样化的训练过程，还显著增强了模型在实际应用中的预测结果的完整性和可靠性。
第3.2部分

一旦B方和C方准备好了各自的训练和测试数据集，二分类问题就转变为一个垂直联邦训练和预测任务。在这种情况下，一个基础估计器——代表每个参与实体的传统机器学习模型——被调整为可在垂直联邦学习（VFL）框架内使用。理解VFL的一般训练过程至关重要，如\cite{yang2019federated}中所描述。总体而言，这个过程包括四个关键步骤，这些步骤共同展示了如何在多方训练数据上训练基础估计器，同时确保在整个合作过程中严格保护各方数据集的隐私。四个步骤的描述如下：

\begin{itemize}
	\item 第一步：服务器通过生成一系列加密密钥对来启动该过程。在此过程中，服务器安全地创建这些加密材料，并将相应的公钥发送给B方和C方。这一步为后续的所有隐私保护操作奠定了基础，建立了一个安全的信息交换通道。
	
	\item 第二步：在收到公钥后，B方和C方对中间计算结果进行加密并交换这些结果。这些结果至关重要，因为它们涉及到梯度和损失的计算，这些计算对于学习过程至关重要。通过仅共享加密数据，每方确保不会直接透露或传输原始的敏感数据值，从而遵守了VFL范式中固有的隐私约束。
	
	\item 第三步：在交换加密的中间结果后，B方和C方计算必要的加密梯度，用于模型参数的更新。除了计算这些梯度外，双方还引入了额外的掩码机制，以进一步隐藏计算出的梯度值。同时，每方还计算了加密版本的模型损失。应用这一额外的掩码步骤是为了防止在后续传输过程中可能发生的数据泄露。一旦这些涉及梯度和损失的加密值生成，它们会被安全地传输到服务器进行进一步处理。
	
	\item 第四步：在收到加密数据后，服务器负责解密接收到的梯度和损失。在完成解密过程后，服务器将解密后的梯度和损失发送回B方和C方。收到后，双方将移除之前应用的额外掩码。这个去掩码步骤至关重要，因为它恢复了真实的梯度信息，这对于更新模型参数是必需的。只有在这些梯度成功去掩码后，B方和C方才会对基础估计器执行实际的参数更新，从而以同步和隐私保护的方式推进训练过程。
\end{itemize}

为了支持在VFL框架内的一般训练过程，已提出多种隐私保护的机器学习算法\cite{yang2019federated}。其中一些著名的例子包括逻辑回归（LR）\cite{he2021secure,yang2019parallel}、随机森林（RF）\cite{yao2022efficient}、梯度提升决策树（GBDT）\cite{he2021secure}、XGBoost（XGB）\cite{xu2021efficient,wang2022feverless}和LightGBM（LGB）\cite{feng2019securegbm}。这些算法旨在促进安全和高效的训练，同时在多个数据所有者之间保持数据隐私。在本文中，我们利用不同的基础估计器——每个算法对应其中之一——来全面评估推荐模型的整体性能。这种多估计器评估不仅突显了VFL框架的灵活性和广泛适用性，还提供了关于不同模型在隐私保护设置下行为的深入见解。包含多种模型架构强化了我们方法在处理复杂且敏感数据集时的鲁棒性和适应性，适用于跨不同数据源的应用。

通过仔细遵循上述四个步骤，并结合成熟的隐私保护技术，所提出的方法确保了模型性能与数据安全之间的强平衡。加密数据的交换、协作计算以及随后的解密和去掩码过程，展示了防止任何无意暴露敏感信息的严格措施。因此，这一过程促进了一个安全的训练环境，各方可以共同从集体数据洞察中受益，同时严格遵守隐私协议，使其特别适用于涉及敏感或受监管数据的应用。
第4部分
\item 确定可靠正样本

  在第 $m\text{-th}$ 次迭代中，采样、训练和预测的整体过程被重复执行 $T$ 轮。完成这 $T$ 轮后，会积累大量信息，从而形成一组概率，记为 ${{\mathsf{\mathcal{P}}}_{m}}$，它与 ${{U}_{m}}$ 中所有未标记样本相关联。这些概率反映了 ${{U}_{m}}$ 中每个样本属于正类的可能性或置信度。这些概率评分在后续决策过程中起着关键作用，例如识别一部分高度可靠的正样本，并迭代更新训练集以提升模型性能。

  为了计算完整的集合 ${{\mathsf{\mathcal{P}}}_{m}}$，有必要为每个未标记样本 $u$（其中 $u\in {{U}_{m}}$）确定概率 ${{\mathsf{\mathcal{P}}}_{m}}(u)$。该概率 ${{\mathsf{\mathcal{P}}}_{m}}(u)$ 是通过将样本 $u$ 在第 $m\text{-th}$ 次迭代中所有 $T$ 轮的袋外评分相加，然后除以 $u$ 在这些轮中作为袋外样本出现的总次数来归一化得到的。该过程在数学上可表示为以下公式：
\begin{equation}
	{{\mathsf{\mathcal{P}}}_{m}}(u)=\frac{\sum\nolimits_{t=1}^{T}{S_{m}^{t}}(u)}{\sum\nolimits_{t=1}^{T}{I(u\in O_{m}^{t})}}.
\end{equation}
  在该表达式中，$S_{m}^{t}(u)$ 表示在第 $m\text{-th}$ 次迭代中第 $t\text{-th}$ 轮为样本 $u$ 分配的袋外评分。值得注意的是，如果 $u$ 在某一轮中未作为袋外样本出现，则定义 $S_{m}^{t}(u)$ 为 0。指示函数 $I(u\in O_{m}^{t})$ 在样本 $u$ 包含在袋外集合 $O_{m}^{t}$ 中时取值为 1，否则取值为 0。因此，分母 $\sum\nolimits_{t=1}^{T}{I(u\in O_{m}^{t})}$ 有效地计数了 $u$ 参与袋外估计的轮数。此归一化过程确保分配给每个样本的概率反映了其在参与预测的各轮中的平均表现，从而提高了所得概率估计的鲁棒性和可靠性。

  基于计算得到的概率 ${{\mathsf{\mathcal{P}}}_{m}}(u)$，接下来对 ${{U}_{m}}$ 中的所有未标记样本进行排序。该排序以非递增顺序执行，因此具有较高概率的样本（即更可能为真正正样本的样本）会排在列表的顶部。利用这一排序好的列表，下一步便是选择一组可靠正样本。正式地，令 ${{R}_{m}}$ 表示在第 $m\text{-th}$ 次迭代中识别出的可靠正样本集合。在我们的方法中，通过选择排名前 $|{{U}_{m}}|\times \theta$ 的样本来进行选择，其中 $\theta$ 是手动设置的比例，代表可靠正样本的采样率。该选择过程可简洁地表述为：
\begin{equation}
	{{R}_{m}}=\{Chose\ Top\ |{{U}_{m}}|\times \theta \ IDs\ from\ {{\mathsf{\mathcal{P}}}_{m}}\}.
\end{equation}
  这一两步选择过程可以具体描述为：
	\begin{itemize}
		\item 第一步：将 ${{\mathsf{\mathcal{P}}}_{m}}$ 中的所有样本按照计算得到的概率以非递增顺序进行排序。此排序确保最有可能为正样本的样本获得优先考虑。

		\item 第二步：从排序结果中选择前 $|{{U}_{m}}|\times \theta$ 个样本，其中 $\theta$ 作为可调参数决定了未标记数据集中被视为可靠正样本的样本比例。
	\end{itemize}
  通过执行这一过程，最有信心且可能真正属于正类的样本便从其他样本中被区分出来。因此，集合 ${{R}_{m}}$ 包含了这些被选中的样本，并随后被用来更新由 Party C 维护的训练标签。

  在识别过程之后，这些新识别出的可靠正样本会被纳入 Party C 维护的训练集中。此更新过程包括为 ${{R}_{m}}$ 中的每个样本分配一个正标签，从而逐步减少未标记数据集 ${{U}_{m}}$ 的规模。从形式上表示，该更新过程表达为：
\begin{equation}
	\mathsf{\mathcal{Y}}_{r}^{C}=1,\ \ r\in {{R}_{m}},
\end{equation}
  其中集合 ${{R}_{m}}$ 中的每个样本 $r$ 被明确赋予标签 1，表明其被归类为正类。该标签更新在训练数据的迭代细化过程中至关重要，因为它利用了从袋外预测集合中获得的置信度评分来提高后续迭代中训练集的整体质量和可靠性。

  总之，识别可靠正样本的过程是一种精心设计的机制，它将概率预测转换为一组高置信度的正实例。该机制不仅提升了训练数据的质量，还为改进整体推荐模型性能提供了一个迭代途径。通过基于样本的袋外表现不断更新样本标签，算法有效地缓解了标签不确定性和数据稀疏性相关的问题。此外，这种丰富而系统的方法为后续的模型训练和预测任务奠定了坚实的基础，确保不断发展的数据集逐步趋向更高的准确性和一致性。
  第5部分
    \item 最终结果及其在推荐中的应用

完成算法的所有 $M$ 次迭代后，最终的可靠正样本集合 $R$ 是通过取每次迭代中所有 ${{R}_{m}}$ 集合的并集得到的，其中 $m = 1, 2, \dots, M$ 表示在整个过程中所执行的各个单独迭代。该迭代方法确保算法在多个轮次中系统地细化正样本的选择，逐步提升最终集合 $R$ 的质量和可靠性。具体来说，每个 ${{R}_{m}}$ 包含在第 $m$ 次迭代中识别出的正样本，而并集操作则将这些中间结果整合为一个全面的最终集合。该步骤在计算上虽简单但至关重要，因为它将所有迭代的结果聚合成一个统一的集合，反映出算法在从整个数据集中区分可靠正样本方面所做的累计努力。

  借助这一精心筛选出的可靠正样本集合 $R$，Party A（可能代表服务提供商或推荐系统运营者等相关方）现在可以利用这些信息为 $R$ 中的每个样本量身定制推荐。该个性化过程涉及对每个样本的特征或偏好进行分析，并设计与之匹配的推荐策略。通过这种方式，Party A 能显著提高推荐系统的准确性和相关性，确保向最终用户提供的建议——无论是产品推荐、内容建议还是其他个性化输出——既精准又符合情境。基于一组可靠正样本对推荐进行微调的能力，凸显了该算法的实际效用，将理论计算与实际应用相结合。

  利用 $R$ 来增强推荐系统的这一步骤不仅仅是一个程序上的形式问题，而是整个算法有效性的基石。推荐系统的成功取决于其识别和优先考虑最相关样本的能力，而这一任务正是该迭代算法通过其结构化设计所完成的。通过聚焦于可靠正样本，系统最大程度地减少了噪声或无关数据的引入，这些数据本可能降低推荐质量。此外，$R$ 的应用使得 Party A 能够优化资源分配——将计算和操作上的努力集中在最有可能带来高用户满意度和参与度的样本上。

  为说明这一过程的重要性，可以考虑推荐系统在各个领域的广泛应用，如电子商务平台、流媒体服务和社交网络，其中建议的准确性直接影响用户体验和业务成果。通过取 ${{R}_{m}}$ 集合的并集来创建 $R$，确保了这些应用的坚实基础，提供了一种可扩展且适应性强的解决方案，能够容纳不同规模和复杂度的数据集。此外，算法的迭代特性使其能够适应用户偏好或数据分布可能随时间变化的动态环境，从而成为长期部署的多功能工具。

  在实践中，可以通过精确度、召回率或用户满意度等指标来评估这一最终步骤的有效性，这些指标量化了由于精心筛选出的集合 $R$ 而提升的推荐质量。例如，更高的精确度表明推荐项中相关的比例更大，而召回率的提升则反映了系统从数据集中检索出更广泛相关项的能力。这些可衡量的结果突显了算法在提升推荐系统性能方面所作的贡献，验证了迭代过程及随后 $R$ 应用的重要性。因此，这一收尾阶段不仅完成了算法工作流程，也确立了其作为解决现实推荐挑战的实际方案的价值。  
\end{enumerate}
```

这是我用latex撰写的论文，仔细阅读并理解，在不修改原本格式和含义的基础上，尽可能地丰富内容，扩充文字、因为我的学术论文对字数有严格要求。