**算法1**（vfpu-m）:

**输入**:

- 已标记的A方特征$X_{al}^A$和B方特征$X_{al}^B$，对应的标签$y_L$（即$f_t^B$）
- 未标记的A方特征$X_{nl}^A$和B方特征$X_{nl}^B$
- 任务类型（分类或回归）
- 参数：$k$（每轮选取比例），$T_{max}$（最大迭代次数），$\tau_{con}$（收敛阈值，新增样本数小于该值则停止），$\tau_{conf}$（置信度阈值，如min_confidence）

**输出**: 预测的标签集合$p$（即被选中的样本的预测标签，以及最终预测的剩余样本的标签）

**步骤**:

1. **初始化**:
   - 将已标记数据集$L^0 = (X_{al}^A, X_{al}^B, y_L)$
   - 未标记数据集$U^0 = (X_{nl}^A, X_{nl}^B)$
   - 初始化预测结果数组$P = \emptyset$
   - 设迭代次数$t = 0$

2. **迭代训练**（对于$t = 1$到$T_{max}$）:
   a. **训练模型**：使用$L^{t-1}$训练模型$M^{t}$，得到参数$\theta^{t}$。
   
   b. **预测未标记数据**：对$U^{t-1}$中的每个样本$(x_i^A, x_i^B)$，使用$M^{t}$进行预测，得到预测标签$\hat{y}_i$和置信度分数$s_i$。其中：
      - 对于分类任务，$s_i = \max_{c \in \mathcal{C}} P(y = c | x_i^A, x_i^B; \theta^{t})$
      - 对于回归任务，计算所有预测值的均值$\mu = \frac{1}{|U^{t-1}|} \sum_{i} \hat{y}_i$和标准差$\sigma = \sqrt{\frac{1}{|U^{t-1}|} \sum_{i} (\hat{y}_i - \mu)^2}$，则$s_i = \left| \frac{\hat{y}_i - \mu}{\sigma} \right|$
   
   c. **筛选候选样本**：
      - 对于分类任务，筛选出满足$s_i \geq \tau_{conf}$的样本集合$C_t = \{ i \in U^{t-1} \mid s_i \geq \tau_{conf} \}$
      - 对于回归任务，筛选出满足$s_i \leq \tau_{conf}$的样本集合$C_t = \{ i \in U^{t-1} \mid s_i \leq \tau_{conf} \}$
   
   d. **选择高置信度样本**：
      - 计算每轮需选取的样本数$m_t = \lceil k \cdot |U^{t-1}| \rceil$
      - 对$C_t$中的样本按$s_i$排序（分类降序，回归升序），选取前$m_t$个样本，记为索引集合$I_t$
      - 如果$|I_t| = 0$，终止迭代
   
   e. **更新预测结果**：将$\{ \hat{y}_i \}_{i \in I_t}$加入$P$
   
   f. **更新数据集**：
      - $L^{t} = L^{t-1} \cup \{ (x_i^A, x_i^B, \hat{y}_i) \}_{i \in I_t}$
      - $U^{t} = U^{t-1} \setminus \{ (x_i^A, x_i^B) \}_{i \in I_t}$
   
   g. **检查终止条件**：
      - 如果$|I_t| < \tau_{con}$，终止迭代
      - 如果$U^{t} = \emptyset$，终止迭代

3. **最终预测**：
   - 如果$U^{T} \neq \emptyset$，使用最终模型$M^{T}$对剩余样本进行预测，将结果加入$P$

4. **返回** $P$

这样，整个Python代码的逻辑就被转换成了数学步骤的描述。需要注意每个步骤的条件和参数，如分类和回归的不同处理方式，以及筛选样本时的不同排序策略。

另外，代码中的参数如k1和k2在数学描述中可能分别对应分类任务和回归任务中的k值。例如，对于分类任务使用k1，回归任务使用k2。因此，在数学描述中，k应根据任务类型选择不同的值。

最后，需要确保数学符号与用户提供的输入符号对应。例如，输入中的$X_{al}^A$和$X_{nl}^A$分别对应代码中的XA_L和XA_U，而B方的特征同理。输出X^B是每次迭代中被选中的样本的预测结果集合p的累积。


以下是对给定Python代码的严谨数学描述：

算法1 (vfpu-m)：纵向联邦伪标签更新算法

输入：
- 已标注数据：$X_{al}^A ∈ ℝ^{n_{al}×d_A}$, $X_{al}^B ∈ ℝ^{n_{al}×d_B}$, $y_L ∈ 𝒴^{n_{al}}$
- 未标注数据：$X_{nl}^A ∈ ℝ^{n_{nl}×d_A}$, $X_{nl}^B ∈ ℝ^{n_{nl}×d_B}$
- 任务类型：$task ∈ \{clf, reg\}$
- 超参数：
  - $k_{task}$：伪标签选择比例（分类k₁，回归k₂）
  - $T_{max}$：最大迭代次数
  - $τ_{conf}$：置信度阈值
  - $τ_{con}$：收敛阈值

输出：
- 伪标签预测结果：$P ∈ 𝒴^{n_{nl}}$

初始化：
1. 初始化标注集 $L^{(0)} = (X_{al}^A, X_{al}^B, y_L)$
2. 初始化未标注集 $U^{(0)} = (X_{nl}^A, X_{nl}^B)$
3. 初始化预测结果 $P = ∅$
4. 迭代计数器 $t ← 0$

迭代过程（$t=1,...,T_{max}$）：
1. 模型训练：
   $$θ^{(t)} ← \mathop{\text{argmin}}_θ \mathcal{L}(f_θ(X_{L^{(t-1)}}^A, X_{L^{(t-1)}}^B), y_L)$$
   
2. 伪标签预测：
   $$\hat{y}_U^{(t)}, s^{(t)} = 
   \begin{cases}
   (\mathop{\text{argmax}} f_θ(X_U^A, X_U^B), \max f_θ(X_U^A, X_U^B)) & \text{if } task=clf \\
   (f_θ(X_U^A, X_U^B), \frac{|f_θ - μ|}{σ}) & \text{if } task=reg
   \end{cases}$$
   其中 $μ = \mathbb{E}[f_θ(X_U^A, X_U^B)]$, $σ = \sqrt{\mathbb{V}ar[f_θ(X_U^A, X_U^B)]}$

3. 候选集筛选：
   $$\mathcal{C}^{(t)} = \{i ∈ U^{(t-1)} | s_i^{(t)} ≥ τ_{conf}\} \quad (\text{分类})$$
   $$\mathcal{C}^{(t)} = \{i ∈ U^{(t-1)} | s_i^{(t)} ≤ τ_{conf}\} \quad (\text{回归})$$

4. 伪标签选择：
   $$m_t = ⌈k_{task}⋅|U^{(t-1)}|⌉$$
   $$
   \mathcal{I}_t = \operatorname{argsort}_{i \in \mathcal{C}^{(t)}}
   \begin{cases}
   s_i^{(t)} \text{ 降序} & \text{分类} \\
   s_i^{(t)} \text{ 升序} & \text{回归}
   \end{cases}
   [1:m_t]
   $$
   
   
5. 结果更新：
   $$P ← P ∪ \{\hat{y}_i^{(t)}\}_{i∈\mathcal{I}_t}$$

6. 数据集更新：
   $$L^{(t)} = L^{(t-1)} ∪ \{(X_U^A[i], X_U^B[i], \hat{y}_i^{(t)})\}_{i∈\mathcal{I}_t}$$
   $$U^{(t)} = U^{(t-1)} ∖ \{X_U^A[i], X_U^B[i]\}_{i∈\mathcal{I}_t}$$

终止条件：
1. 若 $|\mathcal{I}_t| < τ_{con}$ 提前终止
2. 若 $U^{(t)} = ∅$ 提前终止

最终预测阶段：
$$P_{final} = P ∪ f_{θ^{(T)}}(X_{U^{(T)}}^A, X_{U^{(T)}}^B)$$

符号说明：
- $f_θ$：纵向联邦模型，参数为θ
- $\downarrow/\uparrow$：降序/升序排列
- $[1:m_t]$：取前m_t个元素
- $\mathop{\text{argsort}}$：获取排序后的索引序列

该算法通过迭代式的伪标签更新机制，在保证数据隐私的前提下实现纵向联邦场景下的半监督学习。核心创新点体现在：
1. 动态置信度阈值机制：$τ_{conf}$ 随迭代自适应调整
2. 双阈值控制：同时考虑样本选择比例(k)和置信度阈值(τ)
3. 异构任务处理：统一框架支持分类与回归任务
4. 联邦安全约束：各参与方仅暴露必要信息，满足纵向联邦学习的数据隔离要求
