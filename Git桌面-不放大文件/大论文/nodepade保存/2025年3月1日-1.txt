### 问题设置

考虑一个两方纵向联邦学习（Vertical Federated Learning, VFL）的场景，这是参考文献[40]中定义的典型 VFL 设置。参与方包括 Party A 和 Party B，其中只有一方拥有标签。

首先，Party A 拥有数据集：

$$
\mathcal{D}^A := \{X^A_i\}_{i=1}^{n^A}
$$

其中，$X^A_i$ 是第 $i$ 个样本的特征向量，$n^A$ 是样本数量。Party A 的数据仅包含特征，不包含标签。

接着，Party B 拥有数据集：

$$
\mathcal{D}^B := \{(X^B_i, Y^B_i)\}_{i=1}^{n^B}
$$

其中，$X^B_i$ 是第 $i$ 个样本的特征向量，$Y^B_i \in \{0,1\}^C$ 是对应的独热编码（one-hot encoding）真实标签，$C$ 表示类别数，$n^B$ 是样本数量。Party B 拥有标签，这在 VFL 中至关重要，因为标签通常用于监督学习任务。然而，Party B 缺乏足够的特征来单独构建一个准确的模型，因此需要利用 Party A 提供的补充特征。

需要强调的是，$\mathcal{D}^A$ 和 $\mathcal{D}^B$ 分别由 Party A 和 Party B 私有保存，双方不能互相暴露其数据集。

在 VFL 中，Party A 和 Party B 的数据集 $\mathcal{D}^A$ 和 $\mathcal{D}^B$ 包含了不同样本的特征。为了进行联合学习，需要将具有相同身份的样本对齐。假设通过隐私保护的加密实体匹配技术[30]，双方已经完成了样本对齐，得到了对齐样本集：

$$
\mathcal{D}_{al} := \{X^A_{i_{al}}, X^B_{i_{al}}, Y^B_{i_{al}}\}_{i=1}^{n_{al}}
$$

其中，$n_{al}$ 是对齐样本的数量。Party A 拥有对齐样本的特征：

$$
\mathcal{D}^A_{al} := \{X^A_{i_{al}}\}_{i=1}^{n_{al}}
$$

Party B 拥有对齐样本的特征和标签：

$$
\mathcal{D}^B_{al} := \{X^B_{i_{al}}, Y^B_{i_{al}}\}_{i=1}^{n_{al}}
$$

如果将 $\mathcal{D}^A$ 和 $\mathcal{D}^B$ 连接起来，并使具有相同身份的样本对齐，我们将得到一个如图 1.b 所示的单一数据集。这个数据集是垂直分割的，每个方拥有该数据集的一个垂直分区（或部分视图），这正是“纵向联邦学习”一词的由来。然而，两方之间通常只存在有限数量的对齐样本。

除了对齐样本外，每个方还拥有一些非对齐样本，即没有来自另一方对应样本的数据。对于 Party A，非对齐样本表示为：

$$
\mathcal{D}^A_{nl} := \{X^A_{i_{nl}}\}_{i=1}^{n^A_{nl}}
$$

对于 Party B，非对齐样本表示为：

$$
\mathcal{D}^B_{nl} := \{X^B_{i_{nl}}, Y^B_{i_{nl}}\}_{i=1}^{n^B_{nl}}
$$

从单一表格数据集（见图 1.b）的角度来看，每个方对于另一方的非对齐样本都没有对应的特征（或标签）。我们将这些特征（或标签）视为“缺失”。

传统的 VFL 方法仅使用对齐样本 $\mathcal{D}_{al}$ 来构建联邦机器学习模型，而将非对齐样本 $\mathcal{D}^A_{nl}$ 和 $\mathcal{D}^B_{nl}$ 弃置不用。这种做法在对齐样本数量较少时，可能会限制模型的性能，因为大量潜在有用的数据被忽略。

为了提升 VFL 的性能，特别是在对齐样本有限的情况下，本文提出了VFPU-M-Syn方法，。该方法不仅利用对齐样本 $\mathcal{D}_{al}$，还充分利用非对齐样本 $\mathcal{D}^A_{nl}$ 和 $\mathcal{D}^B_{nl}$，旨在提高模型的准确性和泛化能力。




### 跨方特征相关性评估与排序机制

在纵向联邦学习框架中，为有效利用非对齐样本的特征信息，需量化跨参与方特征间的统计关联性。本节提出基于隐私保护的Spearman秩相关分析方法，构建跨方特征相关性排序体系。设协调方C作为可信第三方生成同态加密密钥对$\{\text{pk}, \text{sk}\}$，并向Party A、Party B分发公钥pk。具体计算流程如下：

**定义1（特征列秩向量）**：令$\mathcal{F}^A_{al} = \{X^A_{1_{al}},...,X^A_{{m_A}_{al}}\}$表示Party A对齐部分的$m_A$维特征空间，其中$X^A_p \in \mathbb{R}^{n_{al}}$为第$p$个特征在对齐样本集$\mathcal{D}^A_{al}$上的观测向量（$p=1,...,m_A$）。




后面的符号有一些问题，检查并修正：计算A方和B方对齐部分数据的特征相关性






同理，Party B的特征空间为$\mathcal{F}^B = \{X^B_1,...,X^B_{m_B}\}$，$X^B_q \in \mathbb{R}^{n_{al}}$（$q=1,...,m_B$）。对任意特征列$X^A_p$，计算其秩向量$R^A_p = [r^A_{p1},...,r^A_{pn_{al}}]$，其中$r^A_{pi}$为样本$i$在$X^A_p$上的秩次（采用平均秩处理同值情况）。

**步骤1（加密秩传输）**：Party A使用公钥pk对秩向量进行同态加密，生成$[R^A_p] = \{\text{Enc}(r^A_{p1}),...,\text{Enc}(r^A_{pn_{al}})\}$并发送至Party B。类似地，Party B生成加密秩向量$[R^B_q]$。

**步骤2（秩差计算）**：对于特征对$(X^A_p, X^B_q)$，Party B计算加密秩差向量：
$$
[D_{pq}] = \left[ \text{Enc}(r^A_{p1} - r^B_{q1}),...,\text{Enc}(r^A_{pn_{al}} - r^B_{qn_{al}}) \right]
$$

**步骤3（Spearman相关性计算）**：协调方C解密$[D_{pq}]$得到$d_{pq}^i = r^A_{pi} - r^B_{qi}$，计算特征对间的Spearman相关系数：
$$
\rho_{pq} = 1 - \frac{6\sum_{i=1}^{n_{al}} (d_{pq}^i)^2}{n_{al}(n_{al}^2 - 1)}
$$
其中$n_{al}$为对齐样本量。由此构建跨方相关性矩阵$\mathbf{M} \in \mathbb{R}^{m_A \times m_B}$，元素$\mathbf{M}(p,q) = \rho_{pq}$。

**定义2（特征关联强度）**：对Party B的每个特征$X^B_q$，计算其与Party A特征集的平均关联强度：
$$
\mu_q = \frac{1}{m_A} \sum_{p=1}^{m_A} \rho_{pq}, \quad q=1,...,m_B
$$
该指标量化了$X^B_q$对A方特征空间的综合依赖程度。

**步骤4（生成排序列表）**：构建特征重要性序列$\mathcal{L}_B = \{(\mu_q, X^B_q)\}_{q=1}^{m_B}$，按$\mu_q$升序排列得到$\mathcal{L}_B^{sorted}$。此列表将指导后续的非对齐样本特征生成，优先补充与对方特征关联性弱的维度。

---

**关键符号说明**  

- $m_A, m_B$: A/B方特征维度数  
- $n_{al}$: 对齐样本量（$\mathcal{D}_{al}$基数）  
- $R^A_p, R^B_q$: 特征列秩向量  
- $\rho_{pq}$: Spearman相关系数  
- $\mu_q$: B方特征$X^B_q$的跨方关联强度  
- $\mathcal{L}_B^{sorted}$: 按关联强度排序的特征列表  

该方法通过加密秩运算保护原始特征分布，利用统计相关性识别跨方特征依赖模式，为异构数据补全提供量化依据。排序机制可有效筛选出对方特征信息增益最大的维度进行优先生成，提升联邦学习效率。






